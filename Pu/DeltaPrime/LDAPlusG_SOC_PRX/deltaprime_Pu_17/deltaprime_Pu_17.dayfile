Calculating deltaprime_Pu_17 in /scratch/ykent33650/deltaprime_Pu_17
on node020 with PID 16284




   start        Wed Jan 29 14:26:02 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 14:26:02 2014 1000/0 to go

>lapw0      ( 14:26:02 ) starting parallel lapw0 at Wed Jan 29 14:26:04 CST 2014
-------- .machine0 : 2 processors
1.155u 0.186s 0:04.93 26.9%	0+0k 0+0io 74pf+0w
>lapw1      ( 14:26:09 ) starting parallel lapw1 at Wed Jan 29 14:26:09 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 14:26:09 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 17070
[2] 17151
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(363) 17.315u 0.346s 0:25.32 69.7%	0+0k 0+0io 4pf+0w
     node020(363) 17.245u 0.357s 0:29.15 60.3%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=726	 user=34.56	 wallclock=54.47
34.661u 0.874s 0:31.35 113.3%	0+0k 0+0io 4pf+0w
>lapwso     ( 14:26:41 ) running LAPWSO in parallel mode
[1] 17601
[2] 17624
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 10.136u 0.806s 1:02.29 17.5% 0+0k 0+0io 1pf+0w
      node020 10.225u 0.857s 1:03.34 17.4% 0+0k 0+0io 1pf+0w
   Summary of lapwsopara:
   node020	 user=20.361	 wallclock=125.63
20.421u 1.777s 1:08.30 32.4%	0+0k 0+0io 2pf+0w
>dmft1      ( 14:27:51 ) 7.29user 0.32system 0:29.46elapsed 25%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 14:28:20 ) 6496.56user 12.22system 1:49:23elapsed 99%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 16:17:43 ) 58.37user 0.32system 0:53.72elapsed 109%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 16:18:37 ) 0.010u 0.002s 0:00.05 20.0%	0+0k 0+0io 0pf+0w
>mixer      ( 16:18:40 ) 0.012u 0.011s 0:00.11 18.1%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0004127
>lapw0      ( 16:18:41 ) starting parallel lapw0 at Wed Jan 29 16:18:46 CST 2014
-------- .machine0 : 2 processors
2.215u 0.089s 0:13.08 17.5%	0+0k 0+0io 9pf+0w
>lapw1      ( 16:18:56 ) starting parallel lapw1 at Wed Jan 29 16:18:58 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 16:18:58 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 20931
[2] 20950
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(363) 17.885u 0.365s 0:25.02 72.9%	0+0k 0+0io 0pf+0w
     node020(363) 17.442u 0.355s 0:22.90 77.6%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=726	 user=35.327	 wallclock=47.92
35.401u 0.879s 0:27.74 130.7%	0+0k 0+0io 0pf+0w
>lapwso     ( 16:19:24 ) running LAPWSO in parallel mode
[1] 21108
[2] 21114
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 10.784u 0.791s 0:19.59 59.0% 0+0k 0+0io 0pf+0w
      node020 10.864u 0.789s 0:18.00 64.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=21.648	 wallclock=37.59
21.692u 1.765s 0:24.68 95.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 16:19:50 ) 7.60user 0.41system 0:08.78elapsed 91%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 16:19:59 ) 2606.65user 7.99system 43:34.55elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 17:03:33 ) 52.48user 0.30system 0:27.51elapsed 191%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 17:04:01 ) 0.013u 0.005s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 17:04:10 ) 0.023u 0.007s 0:00.03 66.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.20999936573e-06
:CHARGE convergence:  0.0009199
