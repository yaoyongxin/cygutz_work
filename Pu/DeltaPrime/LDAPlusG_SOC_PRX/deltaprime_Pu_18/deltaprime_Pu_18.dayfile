Calculating deltaprime_Pu_18 in /scratch/ykent33651/deltaprime_Pu_18
on node020 with PID 16286




   start        Wed Jan 29 14:26:02 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 14:26:02 2014 1000/0 to go

>lapw0      ( 14:26:02 ) starting parallel lapw0 at Wed Jan 29 14:26:04 CST 2014
-------- .machine0 : 2 processors
1.139u 0.184s 0:04.93 26.5%	0+0k 0+0io 68pf+0w
>lapw1      ( 14:26:09 ) starting parallel lapw1 at Wed Jan 29 14:26:09 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 14:26:09 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 17071
[2] 17145
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(363) 18.010u 0.323s 0:27.67 66.2%	0+0k 0+0io 4pf+0w
     node020(363) 18.090u 0.374s 0:29.68 62.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=726	 user=36.1	 wallclock=57.35
36.207u 0.901s 0:31.89 116.3%	0+0k 0+0io 4pf+0w
>lapwso     ( 14:26:41 ) running LAPWSO in parallel mode
[1] 17617
[2] 17632
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 10.650u 0.892s 1:02.24 18.5% 0+0k 0+0io 1pf+0w
      node020 10.747u 0.851s 1:02.14 18.6% 0+0k 0+0io 1pf+0w
   Summary of lapwsopara:
   node020	 user=21.397	 wallclock=124.38
21.452u 1.846s 1:03.34 36.7%	0+0k 0+0io 2pf+0w
>dmft1      ( 14:27:46 ) 7.52user 0.33system 0:33.72elapsed 23%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 14:28:20 ) 6385.87user 12.28system 1:47:33elapsed 99%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 16:15:53 ) 54.64user 0.31system 0:35.72elapsed 153%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 16:16:29 ) 0.016u 0.004s 0:01.44 0.6%	0+0k 0+0io 0pf+0w
>mixer      ( 16:16:35 ) 0.013u 0.014s 0:08.89 0.2%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0004434
>lapw0      ( 16:16:46 ) starting parallel lapw0 at Wed Jan 29 16:16:53 CST 2014
-------- .machine0 : 2 processors
0.999u 0.072s 0:05.74 18.4%	0+0k 0+0io 9pf+0w
>lapw1      ( 16:16:57 ) starting parallel lapw1 at Wed Jan 29 16:16:58 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 16:16:58 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 20005
[2] 20024
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(363) 17.970u 0.347s 0:18.44 99.2%	0+0k 0+0io 0pf+0w
     node020(363) 18.289u 0.364s 0:23.51 79.2%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=726	 user=36.259	 wallclock=41.95
36.334u 0.827s 0:25.65 144.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 16:17:24 ) running LAPWSO in parallel mode
[1] 20263
[2] 20270
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 10.793u 0.771s 0:21.19 54.5% 0+0k 0+0io 0pf+0w
      node020 10.702u 0.768s 0:20.13 56.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=21.495	 wallclock=41.32
21.535u 1.698s 0:23.18 100.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 16:17:52 ) 7.72user 0.44system 0:21.13elapsed 38%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 16:18:13 ) 2606.90user 7.28system 43:33.00elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 17:01:46 ) 54.17user 0.33system 1:13.32elapsed 74%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 17:02:59 ) 0.010u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 17:03:09 ) 0.012u 0.012s 0:00.04 50.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.05999788502e-06
:CHARGE convergence:  0.0009713
