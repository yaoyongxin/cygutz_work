Calculating alpha_Pu_5 in /scratch/ykent33896/alpha_Pu_5
on node022 with PID 4426




   start        Tue Feb  4 21:43:11 2014 with lapw0 (1/100 to go)

   cycle 0 	Tue Feb  4 21:43:11 2014 1000/0 to go

>lapw0      ( 21:43:11 ) starting parallel lapw0 at Tue Feb  4 21:43:14 CST 2014
-------- .machine0 : 8 processors
12.037u 0.461s 0:04.22 295.9%	0+0k 0+0io 104pf+0w
>lapw1      ( 21:43:18 ) starting parallel lapw1 at Tue Feb  4 21:43:18 CST 2014
->  starting parallel LAPW1 jobs at Tue Feb  4 21:43:18 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 4650
[2] 4669
[3] 4688
[4] 4707
[5] 4727
[6] 4746
[7] 4765
[8] 4784
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 931.467u 3.371s 15:35.71 99.9%	0+0k 0+0io 1pf+0w
     node022(34) 934.471u 4.262s 15:39.37 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 909.866u 3.496s 15:13.93 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 917.504u 3.458s 15:22.01 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 922.399u 3.465s 15:26.51 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 922.358u 3.532s 15:28.89 99.6%	0+0k 0+0io 0pf+0w
     node022(34) 910.267u 3.453s 15:15.14 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 912.334u 3.469s 15:16.93 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7360.67	 wallclock=7398.49
7361.106u 29.615s 15:41.70 784.8%	0+0k 0+0io 7pf+0w
>lapwso     ( 21:59:00 ) running LAPWSO in parallel mode
[1] 6099
[2] 6105
[3] 6111
[4] 6117
[5] 6124
[6] 6130
[7] 6136
[8] 6142
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 894.646u 7.302s 15:12.22 98.8% 0+0k 0+0io 1pf+0w
      node022 926.719u 7.154s 15:38.09 99.5% 0+0k 0+0io 0pf+0w
      node022 929.691u 7.844s 15:56.10 98.0% 0+0k 0+0io 0pf+0w
      node022 925.693u 7.183s 15:45.42 98.6% 0+0k 0+0io 0pf+0w
      node022 913.570u 7.472s 15:42.03 97.7% 0+0k 0+0io 0pf+0w
      node022 930.395u 6.933s 15:51.94 98.4% 0+0k 0+0io 0pf+0w
      node022 958.064u 7.352s 16:21.82 98.3% 0+0k 0+0io 0pf+0w
      node022 948.091u 6.657s 16:05.86 98.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7426.87	 wallclock=7593.48
7426.991u 58.183s 16:28.17 757.4%	0+0k 0+0io 1pf+0w
>dmft1      ( 22:15:28 ) 655.97user 8.63system 1:28.71elapsed 749%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:16:57 ) 75426.95user 109.09system 2:59:01elapsed 703%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:16:08 ) 11127.40user 11.22system 23:49.46elapsed 779%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:39:57 ) 0.133u 0.013s 0:02.39 5.8%	0+0k 0+0io 1pf+0w
>mixer      ( 01:40:11 ) 0.318u 0.108s 0:00.70 58.5%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0233164
>lapw0      ( 01:40:12 ) starting parallel lapw0 at Wed Feb  5 01:40:15 CST 2014
-------- .machine0 : 8 processors
12.269u 0.503s 0:06.36 200.6%	0+0k 0+0io 105pf+0w
>lapw1      ( 01:40:19 ) starting parallel lapw1 at Wed Feb  5 01:40:22 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 01:40:22 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 9270
[2] 9289
[3] 9308
[4] 9328
[5] 9347
[6] 9366
[7] 9385
[8] 9404
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 925.716u 3.493s 15:34.31 99.4%	0+0k 0+0io 0pf+0w
     node022(34) 929.508u 4.194s 15:38.11 99.5%	0+0k 0+0io 0pf+0w
     node022(34) 925.115u 3.599s 15:30.46 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 930.149u 3.411s 15:35.55 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 925.372u 3.589s 15:29.74 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 900.299u 3.759s 15:05.34 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 918.044u 3.661s 15:22.71 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 924.979u 3.474s 15:28.93 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7379.18	 wallclock=7425.15
7379.644u 30.321s 15:41.78 786.8%	0+0k 0+0io 9pf+0w
>lapwso     ( 01:56:02 ) running LAPWSO in parallel mode
[1] 10734
[2] 10740
[3] 10746
[4] 10752
[5] 10759
[6] 10765
[7] 10771
[8] 10777
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 949.294u 6.557s 16:05.20 99.0% 0+0k 0+0io 0pf+0w
      node022 944.964u 7.554s 16:11.10 98.0% 0+0k 0+0io 0pf+0w
      node022 934.876u 6.968s 15:48.50 99.2% 0+0k 0+0io 0pf+0w
      node022 934.762u 7.520s 15:55.36 98.6% 0+0k 0+0io 0pf+0w
      node022 932.301u 7.307s 15:54.70 98.4% 0+0k 0+0io 0pf+0w
      node022 925.108u 7.447s 15:45.65 98.6% 0+0k 0+0io 0pf+0w
      node022 939.642u 7.304s 16:02.15 98.4% 0+0k 0+0io 0pf+0w
      node022 959.137u 7.305s 16:20.99 98.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7520.08	 wallclock=7683.65
7520.219u 61.812s 16:33.06 763.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:12:38 ) 659.10user 9.19system 1:29.76elapsed 744%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:14:08 ) 57594.36user 90.00system 2:12:43elapsed 724%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:26:52 ) 10615.59user 11.15system 22:10.57elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:49:02 ) 0.138u 0.011s 0:00.19 73.6%	0+0k 0+0io 1pf+0w
>mixer      ( 04:49:02 ) 0.325u 0.113s 0:00.51 84.3%	0+0k 0+0io 2pf+0w
:ENERGY convergence:  0.000507069984451
:CHARGE convergence:  0.0230569
>lapw0      ( 04:49:03 ) starting parallel lapw0 at Wed Feb  5 04:49:03 CST 2014
-------- .machine0 : 8 processors
12.040u 0.455s 0:03.86 323.5%	0+0k 0+0io 90pf+0w
>lapw1      ( 04:49:07 ) starting parallel lapw1 at Wed Feb  5 04:49:07 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 04:49:08 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 13793
[2] 13812
[3] 13831
[4] 13850
[5] 13869
[6] 13889
[7] 13908
[8] 13927
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 921.336u 3.649s 15:26.34 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 929.138u 3.660s 15:33.92 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 926.646u 3.581s 15:32.19 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 918.212u 3.749s 15:23.61 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 925.588u 3.603s 15:33.87 99.4%	0+0k 0+0io 0pf+0w
     node022(34) 908.077u 3.937s 15:13.91 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 906.127u 4.094s 15:14.81 99.4%	0+0k 0+0io 0pf+0w
     node022(34) 921.031u 3.477s 15:27.58 99.6%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7356.15	 wallclock=7406.23
7356.574u 30.939s 15:40.09 785.8%	0+0k 0+0io 2pf+0w
>lapwso     ( 05:04:47 ) running LAPWSO in parallel mode
[1] 15291
[2] 15297
[3] 15303
[4] 15310
[5] 15316
[6] 15322
[7] 15328
[8] 15334
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 945.288u 7.532s 16:08.24 98.4% 0+0k 0+0io 0pf+0w
      node022 943.158u 7.083s 16:17.06 97.2% 0+0k 0+0io 0pf+0w
      node022 973.053u 6.642s 16:28.30 99.1% 0+0k 0+0io 0pf+0w
      node022 959.020u 7.631s 16:31.97 97.4% 0+0k 0+0io 0pf+0w
      node022 945.944u 7.563s 16:09.83 98.3% 0+0k 0+0io 0pf+0w
      node022 942.946u 6.817s 16:00.45 98.8% 0+0k 0+0io 0pf+0w
      node022 951.913u 7.573s 16:13.89 98.5% 0+0k 0+0io 0pf+0w
      node022 954.766u 7.011s 16:11.69 98.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7616.09	 wallclock=7801.43
7616.208u 61.605s 16:38.76 768.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 05:21:26 ) 657.64user 8.84system 1:29.57elapsed 744%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 05:22:56 ) 64465.17user 92.83system 2:29:31elapsed 719%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 07:52:27 ) 11046.10user 11.05system 23:11.23elapsed 794%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 08:15:39 ) 0.137u 0.021s 0:00.26 57.6%	0+0k 0+0io 1pf+0w
>mixer      ( 08:15:39 ) 0.338u 0.121s 0:00.92 48.9%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.00395687005948
:CHARGE convergence:  0.0149799
>lapw0      ( 08:15:40 ) starting parallel lapw0 at Wed Feb  5 08:15:40 CST 2014
-------- .machine0 : 8 processors
12.274u 0.445s 0:03.93 323.4%	0+0k 0+0io 93pf+0w
>lapw1      ( 08:15:44 ) starting parallel lapw1 at Wed Feb  5 08:15:44 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 08:15:45 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 18107
[2] 18127
[3] 18146
[4] 18165
[5] 18184
[6] 18203
[7] 18223
[8] 18242
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 918.719u 4.533s 15:25.11 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 931.902u 3.660s 15:36.40 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 915.217u 3.700s 15:19.16 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 929.878u 3.498s 15:35.63 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 930.286u 3.618s 15:34.57 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 922.320u 3.551s 15:27.12 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 911.311u 3.641s 15:18.91 99.5%	0+0k 0+0io 0pf+0w
     node022(34) 916.242u 3.517s 15:21.39 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7375.88	 wallclock=7418.29
7376.334u 30.872s 15:40.39 787.6%	0+0k 0+0io 8pf+0w
>lapwso     ( 08:31:25 ) running LAPWSO in parallel mode
[1] 19604
[2] 19610
[3] 19616
[4] 19622
[5] 19628
[6] 19635
[7] 19641
[8] 19647
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 899.180u 7.079s 15:12.74 99.2% 0+0k 0+0io 0pf+0w
      node022 879.910u 6.772s 14:52.98 99.2% 0+0k 0+0io 0pf+0w
      node022 930.583u 6.645s 15:42.40 99.4% 0+0k 0+0io 0pf+0w
      node022 926.407u 8.321s 15:44.76 98.9% 0+0k 0+0io 0pf+0w
      node022 917.935u 7.049s 15:36.36 98.7% 0+0k 0+0io 0pf+0w
      node022 936.039u 7.201s 15:55.09 98.7% 0+0k 0+0io 0pf+0w
      node022 899.130u 6.963s 15:17.12 98.7% 0+0k 0+0io 0pf+0w
      node022 935.530u 6.833s 15:50.39 99.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7324.71	 wallclock=7451.84
7324.842u 60.726s 16:04.40 765.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 08:48:14 ) 655.48user 9.06system 1:28.97elapsed 746%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 08:49:43 ) 64535.83user 99.05system 2:26:56elapsed 733%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 11:16:40 ) 10622.43user 10.90system 22:20.63elapsed 793%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 11:39:00 ) 0.133u 0.009s 0:00.18 72.2%	0+0k 0+0io 1pf+0w
>mixer      ( 11:39:02 ) 0.351u 0.112s 0:01.16 39.6%	0+0k 0+0io 3pf+0w
:ENERGY convergence:  0.00578463997226
:CHARGE convergence:  0.0042462
>lapw0      ( 11:39:04 ) starting parallel lapw0 at Wed Feb  5 11:39:05 CST 2014
-------- .machine0 : 8 processors
12.130u 0.436s 0:04.62 271.8%	0+0k 0+0io 92pf+0w
>lapw1      ( 11:39:10 ) starting parallel lapw1 at Wed Feb  5 11:39:10 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 11:39:10 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 22343
[2] 22362
[3] 22382
[4] 22401
[5] 22420
[6] 22439
[7] 22458
[8] 22478
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 900.912u 3.958s 15:06.04 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 907.437u 3.856s 15:11.40 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 916.958u 3.548s 15:22.55 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 917.016u 4.035s 15:22.67 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 920.492u 3.482s 15:26.62 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 896.796u 3.773s 15:01.30 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 914.463u 3.578s 15:19.38 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 916.104u 3.622s 15:20.83 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7290.18	 wallclock=7330.79
7290.587u 31.022s 15:31.95 785.6%	0+0k 0+0io 2pf+0w
>lapwso     ( 11:54:42 ) running LAPWSO in parallel mode
[1] 23806
[2] 23812
[3] 23818
[4] 23824
[5] 23830
[6] 23837
[7] 23843
[8] 23849
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 908.215u 7.245s 15:27.51 98.6% 0+0k 0+0io 0pf+0w
      node022 947.397u 7.124s 16:11.66 98.2% 0+0k 0+0io 0pf+0w
      node022 923.939u 6.738s 15:31.49 99.9% 0+0k 0+0io 0pf+0w
      node022 940.074u 7.715s 16:10.04 97.7% 0+0k 0+0io 0pf+0w
      node022 924.074u 6.713s 15:35.20 99.5% 0+0k 0+0io 0pf+0w
      node022 931.659u 7.368s 15:51.69 98.6% 0+0k 0+0io 0pf+0w
      node022 924.430u 7.258s 15:42.70 98.8% 0+0k 0+0io 0pf+0w
      node022 943.895u 7.322s 16:04.45 98.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7443.68	 wallclock=7594.74
7443.811u 61.279s 16:16.90 768.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 12:10:59 ) 654.44user 9.14system 1:30.59elapsed 732%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 12:12:30 ) 56714.18user 88.00system 2:11:30elapsed 719%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 14:24:00 ) 10942.05user 11.32system 22:59.68elapsed 793%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 14:47:00 ) 0.150u 0.014s 0:00.33 48.4%	0+0k 0+0io 1pf+0w
>mixer      ( 14:47:00 ) 0.368u 0.121s 0:01.16 41.3%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.00456107000355
:CHARGE convergence:  0.0127827
>lapw0      ( 14:47:02 ) starting parallel lapw0 at Wed Feb  5 14:47:02 CST 2014
-------- .machine0 : 8 processors
15.140u 0.422s 0:04.31 361.0%	0+0k 0+0io 101pf+0w
>lapw1      ( 14:47:06 ) starting parallel lapw1 at Wed Feb  5 14:47:06 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 14:47:07 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 26364
[2] 26384
[3] 26403
[4] 26422
[5] 26441
[6] 26460
[7] 26480
[8] 26499
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 901.571u 3.841s 15:05.93 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 924.140u 3.971s 15:32.44 99.5%	0+0k 0+0io 0pf+0w
     node022(34) 923.090u 3.575s 15:28.04 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 919.902u 3.553s 15:27.18 99.5%	0+0k 0+0io 0pf+0w
     node022(34) 922.980u 3.590s 15:27.83 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 914.520u 3.700s 15:18.58 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 916.409u 3.775s 15:21.89 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 911.101u 3.531s 15:15.85 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7333.71	 wallclock=7377.74
7334.164u 30.688s 15:35.13 787.5%	0+0k 0+0io 6pf+0w
>lapwso     ( 15:02:41 ) running LAPWSO in parallel mode
[1] 27847
[2] 27853
[3] 27859
[4] 27866
[5] 27872
[6] 27878
[7] 27884
[8] 27890
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 943.383u 7.062s 16:03.82 98.6% 0+0k 0+0io 0pf+0w
      node022 970.708u 7.446s 16:33.17 98.4% 0+0k 0+0io 0pf+0w
      node022 964.240u 7.293s 16:23.72 98.7% 0+0k 0+0io 0pf+0w
      node022 952.124u 7.652s 16:17.54 98.1% 0+0k 0+0io 0pf+0w
      node022 969.100u 6.848s 16:23.65 99.2% 0+0k 0+0io 0pf+0w
      node022 950.872u 7.276s 16:23.86 97.3% 0+0k 0+0io 0pf+0w
      node022 970.203u 7.878s 16:31.24 98.6% 0+0k 0+0io 0pf+0w
      node022 956.064u 6.547s 16:09.29 99.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7676.69	 wallclock=7846.29
7676.807u 61.904s 16:42.06 772.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 15:19:24 ) 655.68user 8.85system 1:32.34elapsed 719%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 15:20:56 ) 57086.55user 82.38system 2:10:03elapsed 732%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 17:30:59 ) 10617.21user 11.15system 22:10.78elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 17:53:10 ) 0.129u 0.013s 0:00.19 68.4%	0+0k 0+0io 1pf+0w
>mixer      ( 17:53:12 ) 0.372u 0.126s 0:03.11 15.7%	0+0k 0+0io 4pf+0w
:ENERGY convergence:  0.000887349946424
:CHARGE convergence:  0.0102684
>lapw0      ( 17:53:17 ) starting parallel lapw0 at Wed Feb  5 17:53:17 CST 2014
-------- .machine0 : 8 processors
12.262u 0.449s 0:03.84 330.7%	0+0k 0+0io 92pf+0w
>lapw1      ( 17:53:20 ) starting parallel lapw1 at Wed Feb  5 17:53:24 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 17:53:24 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 30408
[2] 30427
[3] 30446
[4] 30466
[5] 30485
[6] 30504
[7] 30523
[8] 30542
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 923.241u 3.627s 15:27.63 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 926.843u 3.652s 15:32.07 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 906.547u 3.771s 15:11.01 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 928.122u 3.471s 15:32.74 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 927.916u 3.690s 15:32.85 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 900.949u 3.506s 15:04.71 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 918.281u 3.762s 15:24.45 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 921.156u 3.766s 15:25.61 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7353.05	 wallclock=7391.07
7353.498u 30.390s 15:38.49 786.7%	0+0k 0+0io 2pf+0w
>lapwso     ( 18:09:02 ) running LAPWSO in parallel mode
[1] 31886
[2] 31892
[3] 31898
[4] 31904
[5] 31911
[6] 31917
[7] 31923
[8] 31929
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 901.630u 6.788s 15:24.32 98.2% 0+0k 0+0io 0pf+0w
      node022 948.230u 6.976s 16:08.57 98.6% 0+0k 0+0io 0pf+0w
      node022 909.936u 6.916s 15:29.90 98.5% 0+0k 0+0io 0pf+0w
      node022 907.031u 7.668s 15:34.53 97.8% 0+0k 0+0io 0pf+0w
      node022 918.472u 7.085s 15:36.13 98.8% 0+0k 0+0io 0pf+0w
      node022 969.888u 6.970s 16:34.10 98.2% 0+0k 0+0io 0pf+0w
      node022 954.961u 7.446s 16:12.81 98.9% 0+0k 0+0io 0pf+0w
      node022 960.084u 7.161s 16:16.91 99.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7470.23	 wallclock=7637.27
7470.358u 60.838s 16:42.99 750.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 18:25:48 ) 653.96user 8.80system 1:30.03elapsed 736%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 18:27:18 ) 59422.48user 86.89system 2:21:37elapsed 700%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 20:48:55 ) 11135.64user 11.20system 24:51.44elapsed 747%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 21:13:47 ) 0.139u 0.011s 0:00.26 53.8%	0+0k 0+0io 2pf+0w
>mixer      ( 21:13:54 ) 0.376u 0.142s 0:06.56 7.7%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.00146765005775
:CHARGE convergence:  0.0070068
>lapw0      ( 21:14:02 ) starting parallel lapw0 at Wed Feb  5 21:14:04 CST 2014
-------- .machine0 : 8 processors
12.312u 0.430s 0:06.42 198.4%	0+0k 0+0io 89pf+0w
>lapw1      ( 21:14:10 ) starting parallel lapw1 at Wed Feb  5 21:14:10 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 21:14:11 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 2199
[2] 2218
[3] 2237
[4] 2257
[5] 2276
[6] 2295
[7] 2314
[8] 2333
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 926.371u 3.527s 15:33.56 99.6%	0+0k 0+0io 0pf+0w
     node022(34) 942.942u 3.534s 15:47.78 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 920.708u 3.564s 15:24.52 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 926.101u 3.493s 15:30.61 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 940.810u 3.570s 15:45.70 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 916.090u 3.781s 15:22.65 99.6%	0+0k 0+0io 0pf+0w
     node022(34) 918.042u 4.142s 15:24.63 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 933.081u 3.553s 15:37.18 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7424.15	 wallclock=7466.63
7424.590u 30.354s 15:51.54 783.4%	0+0k 0+0io 6pf+0w
>lapwso     ( 21:30:02 ) running LAPWSO in parallel mode
[1] 3754
[2] 3760
[3] 3766
[4] 3772
[5] 3778
[6] 3787
[7] 3793
[8] 3799
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 888.985u 6.997s 15:01.59 99.3% 0+0k 0+0io 1pf+0w
      node022 897.292u 6.854s 15:18.41 98.4% 0+0k 0+0io 0pf+0w
      node022 922.772u 7.161s 15:43.23 98.5% 0+0k 0+0io 0pf+0w
      node022 916.961u 7.621s 15:46.77 97.6% 0+0k 0+0io 0pf+0w
      node022 918.316u 7.509s 15:42.45 98.2% 0+0k 0+0io 0pf+0w
      node022 895.619u 7.501s 15:09.69 99.2% 0+0k 0+0io 0pf+0w
      node022 913.104u 7.559s 15:39.47 97.9% 0+0k 0+0io 0pf+0w
      node022 908.131u 6.645s 15:21.66 99.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7261.18	 wallclock=7423.27
7261.307u 61.854s 15:55.30 766.5%	0+0k 0+0io 1pf+0w
>dmft1      ( 21:45:57 ) 661.09user 9.44system 1:27.90elapsed 762%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 21:47:25 ) 57140.93user 88.03system 2:10:36elapsed 730%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 23:58:02 ) 10885.52user 11.13system 22:51.16elapsed 794%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:20:54 ) 0.157u 0.013s 0:00.37 43.2%	0+0k 0+0io 1pf+0w
>mixer      ( 00:20:54 ) 0.403u 0.133s 0:01.52 34.8%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.000474330037832
:CHARGE convergence:  0.0078447
>lapw0      ( 00:20:56 ) starting parallel lapw0 at Thu Feb  6 00:20:56 CST 2014
-------- .machine0 : 8 processors
12.090u 0.506s 0:04.12 305.5%	0+0k 0+0io 109pf+0w
>lapw1      ( 00:21:00 ) starting parallel lapw1 at Thu Feb  6 00:21:00 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 00:21:01 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 6360
[2] 6379
[3] 6399
[4] 6418
[5] 6437
[6] 6456
[7] 6475
[8] 6495
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 917.796u 3.568s 15:22.59 99.8%	0+0k 0+0io 1pf+0w
     node022(34) 927.263u 3.945s 15:34.08 99.6%	0+0k 0+0io 0pf+0w
     node022(34) 931.179u 3.501s 15:36.82 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 928.254u 3.622s 15:36.17 99.5%	0+0k 0+0io 0pf+0w
     node022(34) 916.695u 3.518s 15:21.83 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 907.566u 4.136s 15:13.48 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 910.357u 3.952s 15:16.51 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 926.453u 3.469s 15:31.01 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7365.56	 wallclock=7412.49
7366.009u 30.893s 15:42.36 784.9%	0+0k 0+0io 18pf+0w
>lapwso     ( 00:36:43 ) running LAPWSO in parallel mode
[1] 7841
[2] 7848
[3] 7854
[4] 7860
[5] 7866
[6] 7872
[7] 7879
[8] 7885
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 912.099u 7.253s 15:24.89 99.3% 0+0k 0+0io 1pf+0w
      node022 941.682u 6.940s 15:56.36 99.1% 0+0k 0+0io 0pf+0w
      node022 906.693u 7.212s 15:38.50 97.3% 0+0k 0+0io 0pf+0w
      node022 930.566u 8.326s 16:04.18 97.3% 0+0k 0+0io 0pf+0w
      node022 969.133u 7.452s 16:23.36 99.3% 0+0k 0+0io 0pf+0w
      node022 938.992u 7.125s 16:01.53 98.3% 0+0k 0+0io 0pf+0w
      node022 914.559u 7.124s 15:25.85 99.5% 0+0k 0+0io 0pf+0w
      node022 978.107u 6.846s 16:44.31 98.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7491.83	 wallclock=7658.98
7491.951u 62.194s 16:55.69 743.7%	0+0k 0+0io 1pf+0w
>dmft1      ( 00:53:39 ) 655.86user 8.66system 1:30.41elapsed 734%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:55:09 ) 56580.08user 80.01system 2:07:30elapsed 740%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:02:40 ) 10603.27user 11.06system 22:17.28elapsed 793%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:24:57 ) 0.162u 0.011s 0:00.37 45.9%	0+0k 0+0io 1pf+0w
>mixer      ( 03:25:01 ) 0.398u 0.151s 0:02.22 24.3%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.000577670056373
:CHARGE convergence:  0.0066251
>lapw0      ( 03:25:03 ) starting parallel lapw0 at Thu Feb  6 03:25:04 CST 2014
-------- .machine0 : 8 processors
12.281u 0.410s 0:04.01 316.4%	0+0k 0+0io 97pf+0w
>lapw1      ( 03:25:07 ) starting parallel lapw1 at Thu Feb  6 03:25:08 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 03:25:08 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 10370
[2] 10389
[3] 10408
[4] 10427
[5] 10447
[6] 10466
[7] 10485
[8] 10504
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 901.644u 3.821s 15:06.38 99.8%	0+0k 0+0io 1pf+0w
     node022(34) 924.056u 3.643s 15:31.39 99.6%	0+0k 0+0io 0pf+0w
     node022(34) 920.599u 3.639s 15:24.57 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 922.500u 3.868s 15:27.52 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 923.889u 4.075s 15:29.62 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 899.043u 3.704s 15:03.99 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 913.776u 3.663s 15:19.44 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 916.262u 3.575s 15:20.05 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7321.77	 wallclock=7362.96
7322.223u 31.146s 15:35.78 785.8%	0+0k 0+0io 13pf+0w
>lapwso     ( 03:40:43 ) running LAPWSO in parallel mode
[1] 11875
[2] 11881
[3] 11887
[4] 11894
[5] 11900
[6] 11906
[7] 11912
[8] 11918
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 928.169u 6.511s 15:39.77 99.4% 0+0k 0+0io 0pf+0w
      node022 975.325u 8.337s 16:32.91 99.0% 0+0k 0+0io 0pf+0w
      node022 967.730u 6.873s 16:23.91 99.0% 0+0k 0+0io 0pf+0w
      node022 938.636u 7.009s 15:51.91 99.3% 0+0k 0+0io 0pf+0w
      node022 932.452u 6.901s 15:47.81 99.1% 0+0k 0+0io 0pf+0w
      node022 960.639u 7.461s 16:13.46 99.4% 0+0k 0+0io 0pf+0w
      node022 963.955u 7.223s 16:15.16 99.5% 0+0k 0+0io 0pf+0w
      node022 955.705u 6.709s 16:10.36 99.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7622.61	 wallclock=7735.29
7622.743u 60.801s 16:38.83 769.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:59:43 ) 659.64user 9.38system 1:28.95elapsed 752%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:01:12 ) 56709.77user 84.08system 2:07:15elapsed 743%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:08:28 ) 11121.94user 11.41system 23:14.40elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:31:43 ) 0.143u 0.012s 0:00.27 55.5%	0+0k 0+0io 1pf+0w
>mixer      ( 06:31:43 ) 0.398u 0.153s 0:01.78 30.3%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  0.00139816990122
:CHARGE convergence:  0.0027946
>lapw0      ( 06:31:45 ) starting parallel lapw0 at Thu Feb  6 06:31:45 CST 2014
-------- .machine0 : 8 processors
12.290u 0.428s 0:04.02 316.1%	0+0k 0+0io 94pf+0w
>lapw1      ( 06:31:49 ) starting parallel lapw1 at Thu Feb  6 06:31:49 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 06:31:50 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 14846
[2] 14865
[3] 14884
[4] 14904
[5] 14923
[6] 14942
[7] 14961
[8] 14980
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 910.940u 3.749s 15:15.74 99.8%	0+0k 0+0io 1pf+0w
     node022(34) 924.466u 3.805s 15:28.70 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 918.118u 4.026s 15:23.02 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 927.473u 3.458s 15:31.53 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 926.862u 3.586s 15:32.20 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 917.668u 3.802s 15:24.21 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 922.458u 3.655s 15:26.56 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 919.752u 3.759s 15:24.91 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7367.74	 wallclock=7406.87
7368.170u 31.031s 15:38.20 788.6%	0+0k 0+0io 11pf+0w
>lapwso     ( 06:47:28 ) running LAPWSO in parallel mode
[1] 16331
[2] 16337
[3] 16344
[4] 16350
[5] 16356
[6] 16362
[7] 16368
[8] 16375
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 946.551u 7.285s 16:01.44 99.2% 0+0k 0+0io 0pf+0w
      node022 950.476u 7.121s 16:08.56 98.8% 0+0k 0+0io 0pf+0w
      node022 967.056u 7.834s 16:32.79 98.1% 0+0k 0+0io 0pf+0w
      node022 976.295u 7.470s 16:35.50 98.8% 0+0k 0+0io 0pf+0w
      node022 996.742u 7.478s 16:53.40 99.0% 0+0k 0+0io 0pf+0w
      node022 988.077u 6.992s 16:51.22 98.4% 0+0k 0+0io 0pf+0w
      node022 939.049u 7.144s 15:56.78 98.8% 0+0k 0+0io 0pf+0w
      node022 970.599u 7.140s 16:35.48 98.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7734.85	 wallclock=7895.17
7734.974u 62.298s 17:01.46 763.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 07:04:29 ) 655.69user 8.81system 1:30.81elapsed 731%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 07:06:00 ) 77551.01user 124.78system 2:57:42elapsed 728%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 10:03:43 ) 11004.53user 11.45system 22:59.57elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 10:26:42 ) 0.130u 0.014s 0:00.19 73.6%	0+0k 0+0io 1pf+0w
>mixer      ( 10:26:44 ) 0.394u 0.135s 0:14.85 3.5%	0+0k 0+0io 3pf+0w
:ENERGY convergence:  0.000716770067811
:CHARGE convergence:  0.000652
>lapw0      ( 10:26:59 ) starting parallel lapw0 at Thu Feb  6 10:26:59 CST 2014
-------- .machine0 : 8 processors
12.284u 0.445s 0:06.38 199.3%	0+0k 0+0io 88pf+0w
>lapw1      ( 10:27:05 ) starting parallel lapw1 at Thu Feb  6 10:27:09 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 10:27:09 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 19493
[2] 19512
[3] 19531
[4] 19550
[5] 19569
[6] 19589
[7] 19608
[8] 19627
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 906.201u 4.065s 15:11.08 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 931.713u 3.722s 15:37.34 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 911.509u 3.693s 15:17.10 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 916.766u 3.499s 15:20.39 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 918.881u 3.834s 15:25.14 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 920.856u 4.037s 15:25.47 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 917.320u 3.768s 15:22.13 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 921.806u 3.476s 15:26.45 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7345.05	 wallclock=7385.1
7345.508u 31.270s 15:41.45 783.5%	0+0k 0+0io 2pf+0w
>lapwso     ( 10:42:48 ) running LAPWSO in parallel mode
[1] 20980
[2] 20986
[3] 20992
[4] 20998
[5] 21005
[6] 21011
[7] 21017
[8] 21023
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 928.847u 7.039s 15:50.65 98.4% 0+0k 0+0io 0pf+0w
      node022 926.421u 6.998s 15:48.84 98.3% 0+0k 0+0io 0pf+0w
      node022 940.204u 7.393s 16:01.03 98.6% 0+0k 0+0io 0pf+0w
      node022 943.683u 7.407s 16:06.46 98.4% 0+0k 0+0io 0pf+0w
      node022 922.094u 7.455s 15:38.27 99.0% 0+0k 0+0io 0pf+0w
      node022 929.501u 7.076s 15:47.42 98.8% 0+0k 0+0io 0pf+0w
      node022 935.204u 7.925s 16:00.38 98.2% 0+0k 0+0io 0pf+0w
      node022 923.029u 6.939s 15:50.35 97.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7448.98	 wallclock=7623.4
7449.103u 62.036s 16:13.33 771.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 10:59:02 ) 657.28user 9.59system 1:31.14elapsed 731%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 11:00:33 ) 48385.11user 84.23system 1:49:43elapsed 736%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 12:50:17 ) 10636.71user 11.04system 22:13.48elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 13:12:31 ) 0.143u 0.008s 0:00.27 51.8%	0+0k 0+0io 1pf+0w
>mixer      ( 13:12:31 ) 0.401u 0.142s 0:01.76 30.6%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.000166949932463
:CHARGE convergence:  0.0004942
>lapw0      ( 13:12:42 ) starting parallel lapw0 at Thu Feb  6 13:12:42 CST 2014
-------- .machine0 : 8 processors
12.304u 0.452s 0:06.91 184.5%	0+0k 0+0io 96pf+0w
>lapw1      ( 13:12:49 ) starting parallel lapw1 at Thu Feb  6 13:12:49 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 13:12:50 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 23282
[2] 23301
[3] 23320
[4] 23339
[5] 23359
[6] 23378
[7] 23397
[8] 23416
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 912.441u 3.851s 15:17.56 99.8%	0+0k 0+0io 1pf+0w
     node022(34) 921.339u 4.588s 15:27.75 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 925.583u 3.530s 15:33.70 99.5%	0+0k 0+0io 0pf+0w
     node022(34) 918.531u 3.512s 15:23.05 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 924.297u 3.835s 15:30.51 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 919.654u 3.691s 15:24.75 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 912.306u 3.575s 15:16.97 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 921.858u 3.458s 15:25.67 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7356.01	 wallclock=7399.96
7356.437u 31.233s 15:37.77 787.7%	0+0k 0+0io 7pf+0w
>lapwso     ( 13:28:27 ) running LAPWSO in parallel mode
[1] 24767
[2] 24773
[3] 24779
[4] 24785
[5] 24791
[6] 24798
[7] 24804
[8] 24810
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 947.907u 7.024s 16:09.71 98.4% 0+0k 0+0io 0pf+0w
      node022 948.039u 7.514s 16:09.96 98.5% 0+0k 0+0io 0pf+0w
      node022 935.896u 7.256s 15:55.40 98.7% 0+0k 0+0io 0pf+0w
      node022 969.198u 7.206s 16:28.30 98.7% 0+0k 0+0io 0pf+0w
      node022 953.455u 7.513s 16:09.10 99.1% 0+0k 0+0io 0pf+0w
      node022 970.875u 6.802s 16:24.29 99.3% 0+0k 0+0io 0pf+0w
      node022 949.202u 8.127s 16:09.73 98.7% 0+0k 0+0io 0pf+0w
      node022 936.783u 7.127s 16:07.75 97.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7611.36	 wallclock=7774.24
7611.484u 62.423s 16:35.38 770.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 13:45:03 ) 658.79user 9.10system 1:29.35elapsed 747%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 13:46:32 ) 47707.15user 73.46system 1:51:44elapsed 712%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 15:38:17 ) 10931.62user 10.99system 22:50.36elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 16:01:07 ) 0.142u 0.016s 0:00.28 53.5%	0+0k 0+0io 1pf+0w
>mixer      ( 16:01:08 ) 0.398u 0.147s 0:01.81 29.2%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.000193200074136
:CHARGE convergence:  0.0001399
>lapw0      ( 16:01:10 ) starting parallel lapw0 at Thu Feb  6 16:01:10 CST 2014
-------- .machine0 : 8 processors
12.128u 0.449s 0:03.94 318.7%	0+0k 0+0io 92pf+0w
>lapw1      ( 16:01:14 ) starting parallel lapw1 at Thu Feb  6 16:01:59 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 16:02:00 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 27194
[2] 27213
[3] 27232
[4] 27251
[5] 27270
[6] 27290
[7] 27309
[8] 27328
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 897.338u 3.775s 15:02.57 99.8%	0+0k 0+0io 1pf+0w
     node022(34) 927.349u 3.766s 15:32.93 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 923.963u 3.676s 15:29.65 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 915.185u 3.428s 15:19.94 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 922.696u 3.700s 15:28.20 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 920.958u 3.527s 15:26.75 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 915.277u 4.131s 15:24.95 99.3%	0+0k 0+0io 0pf+0w
     node022(34) 921.179u 3.419s 15:25.26 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7343.94	 wallclock=7390.25
7344.402u 30.576s 15:38.65 785.6%	0+0k 0+0io 7pf+0w
>lapwso     ( 16:17:38 ) running LAPWSO in parallel mode
[1] 28660
[2] 28666
[3] 28673
[4] 28679
[5] 28685
[6] 28691
[7] 28697
[8] 28704
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 918.612u 6.846s 15:30.32 99.4% 0+0k 0+0io 0pf+0w
      node022 936.518u 7.217s 15:53.24 99.0% 0+0k 0+0io 0pf+0w
      node022 910.435u 7.023s 15:37.55 97.8% 0+0k 0+0io 0pf+0w
      node022 942.373u 8.743s 16:12.71 97.7% 0+0k 0+0io 0pf+0w
      node022 914.197u 6.866s 15:34.50 98.5% 0+0k 0+0io 0pf+0w
      node022 909.668u 6.824s 15:39.33 97.5% 0+0k 0+0io 0pf+0w
      node022 926.720u 7.420s 15:47.92 98.5% 0+0k 0+0io 0pf+0w
      node022 927.529u 6.804s 15:41.98 99.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7386.05	 wallclock=7557.55
7386.182u 61.638s 16:20.05 759.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 16:33:58 ) 653.34user 8.89system 2:21.15elapsed 469%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 16:36:19 ) 50803.16user 69.48system 2:00:32elapsed 703%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 18:36:52 ) 11091.59user 11.29system 23:10.44elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 19:00:02 ) 0.154u 0.014s 0:00.30 53.3%	0+0k 0+0io 1pf+0w
>mixer      ( 19:00:03 ) 0.408u 0.144s 0:01.84 29.3%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  1.87699915841e-05
:CHARGE convergence:  0.0002007
>lapw0      ( 19:00:05 ) starting parallel lapw0 at Thu Feb  6 19:00:05 CST 2014
-------- .machine0 : 8 processors
12.622u 0.449s 0:03.98 328.1%	0+0k 0+0io 96pf+0w
>lapw1      ( 19:00:09 ) starting parallel lapw1 at Thu Feb  6 19:00:09 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 19:00:10 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 31111
[2] 31130
[3] 31149
[4] 31169
[5] 31188
[6] 31207
[7] 31226
[8] 31245
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 924.275u 3.812s 15:29.82 99.8%	0+0k 0+0io 1pf+0w
     node022(34) 926.913u 4.271s 15:33.80 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 922.263u 3.520s 15:32.13 99.3%	0+0k 0+0io 0pf+0w
     node022(34) 925.066u 3.544s 15:31.24 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 926.213u 3.584s 15:30.23 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 910.105u 3.986s 15:15.42 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 918.557u 3.596s 15:23.09 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 921.131u 3.506s 15:25.01 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7374.52	 wallclock=7420.74
7374.956u 31.011s 15:36.74 790.6%	0+0k 0+0io 5pf+0w
>lapwso     ( 19:15:46 ) running LAPWSO in parallel mode
[1] 32607
[2] 32613
[3] 32620
[4] 32626
[5] 32632
[6] 32638
[7] 32644
[8] 32651
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 895.915u 7.331s 15:16.43 98.5% 0+0k 0+0io 0pf+0w
      node022 900.470u 7.788s 15:20.37 98.6% 0+0k 0+0io 0pf+0w
      node022 900.308u 7.034s 15:23.07 98.2% 0+0k 0+0io 0pf+0w
      node022 933.724u 7.160s 15:55.82 98.4% 0+0k 0+0io 0pf+0w
      node022 892.942u 6.775s 15:12.50 98.5% 0+0k 0+0io 0pf+0w
      node022 920.857u 7.511s 15:46.84 98.0% 0+0k 0+0io 0pf+0w
      node022 907.719u 7.096s 15:25.70 98.8% 0+0k 0+0io 0pf+0w
      node022 911.561u 7.004s 15:34.85 98.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7263.5	 wallclock=7435.58
7263.618u 61.610s 16:04.45 759.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 19:31:53 ) 655.41user 8.92system 1:31.12elapsed 729%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 19:33:25 ) 67115.60user 99.03system 2:38:42elapsed 705%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 22:12:07 ) 11099.53user 11.05system 23:19.67elapsed 793%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 22:35:27 ) 0.148u 0.022s 0:00.31 51.6%	0+0k 0+0io 1pf+0w
>mixer      ( 22:35:30 ) 0.401u 0.158s 0:02.14 25.7%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  4.03899466619e-05
:CHARGE convergence:  0.00025
>lapw0      ( 22:35:33 ) starting parallel lapw0 at Thu Feb  6 22:36:18 CST 2014
-------- .machine0 : 8 processors
12.582u 0.451s 0:03.94 330.7%	0+0k 0+0io 95pf+0w
>lapw1      ( 22:36:22 ) starting parallel lapw1 at Thu Feb  6 22:36:22 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 22:36:23 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 3156
[2] 3179
[3] 3198
[4] 3217
[5] 3236
[6] 3256
[7] 3275
[8] 3294
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 899.566u 4.580s 15:05.07 99.8%	0+0k 0+0io 1pf+0w
     node022(34) 924.006u 3.504s 15:29.64 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 913.944u 3.786s 15:20.39 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 918.837u 3.577s 15:25.10 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 918.149u 3.495s 15:23.63 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 911.293u 3.708s 15:17.07 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 910.511u 3.611s 15:14.55 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 909.346u 3.527s 15:14.36 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7305.65	 wallclock=7349.81
7306.077u 30.960s 15:32.54 786.7%	0+0k 0+0io 4pf+0w
>lapwso     ( 22:51:55 ) running LAPWSO in parallel mode
[1] 4691
[2] 4697
[3] 4703
[4] 4709
[5] 4716
[6] 4722
[7] 4728
[8] 4734
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 927.273u 6.765s 15:43.61 98.9% 0+0k 0+0io 1pf+0w
      node022 968.382u 7.290s 16:18.91 99.6% 0+0k 0+0io 0pf+0w
      node022 936.912u 7.139s 16:00.79 98.2% 0+0k 0+0io 0pf+0w
      node022 931.279u 7.167s 15:41.71 99.6% 0+0k 0+0io 0pf+0w
      node022 969.135u 7.279s 16:37.89 97.8% 0+0k 0+0io 0pf+0w
      node022 919.886u 7.347s 15:49.94 97.6% 0+0k 0+0io 0pf+0w
      node022 947.551u 7.822s 16:09.61 98.5% 0+0k 0+0io 0pf+0w
      node022 957.463u 6.734s 16:18.93 98.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7557.88	 wallclock=7721.39
7558.021u 61.581s 16:48.26 755.7%	0+0k 0+0io 1pf+0w
>dmft1      ( 23:08:43 ) 665.98user 9.10system 1:28.75elapsed 760%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 23:10:12 ) 48073.25user 80.93system 1:48:16elapsed 741%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:58:29 ) 11086.21user 11.16system 23:17.52elapsed 794%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:21:46 ) 0.130u 0.018s 0:00.22 63.6%	0+0k 0+0io 1pf+0w
>mixer      ( 01:21:46 ) 0.418u 0.130s 0:01.52 35.5%	0+0k 0+0io 3pf+0w
:ENERGY convergence:  0.000184400007129
:CHARGE convergence:  0.0002416
>lapw0      ( 01:21:48 ) starting parallel lapw0 at Fri Feb  7 01:21:48 CST 2014
-------- .machine0 : 8 processors
12.709u 0.521s 0:04.21 314.0%	0+0k 0+0io 103pf+0w
>lapw1      ( 01:21:52 ) starting parallel lapw1 at Fri Feb  7 01:21:53 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 01:21:53 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 6998
[2] 7017
[3] 7037
[4] 7056
[5] 7075
[6] 7094
[7] 7113
[8] 7133
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 922.369u 4.448s 15:28.33 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 929.065u 3.742s 15:32.98 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 898.558u 3.607s 15:03.66 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 921.214u 3.548s 15:25.54 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 908.511u 3.757s 15:12.50 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 921.579u 3.480s 15:31.49 99.3%	0+0k 0+0io 0pf+0w
     node022(34) 920.623u 3.618s 15:27.60 99.6%	0+0k 0+0io 0pf+0w
     node022(34) 922.630u 3.338s 15:28.18 99.7%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7344.55	 wallclock=7390.28
7344.990u 30.700s 15:38.25 786.1%	0+0k 0+0io 14pf+0w
>lapwso     ( 01:37:31 ) running LAPWSO in parallel mode
[1] 8467
[2] 8473
[3] 8480
[4] 8486
[5] 8492
[6] 8498
[7] 8504
[8] 8511
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 943.307u 7.139s 16:06.47 98.3% 0+0k 0+0io 1pf+0w
      node022 942.164u 7.011s 15:53.33 99.5% 0+0k 0+0io 0pf+0w
      node022 949.824u 7.398s 16:07.51 98.9% 0+0k 0+0io 0pf+0w
      node022 959.264u 7.518s 16:21.54 98.4% 0+0k 0+0io 0pf+0w
      node022 948.238u 7.500s 16:13.45 98.1% 0+0k 0+0io 0pf+0w
      node022 949.003u 7.122s 16:04.55 99.1% 0+0k 0+0io 0pf+0w
      node022 937.311u 7.719s 16:03.54 98.0% 0+0k 0+0io 0pf+0w
      node022 967.260u 7.112s 16:27.05 98.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7596.37	 wallclock=7757.44
7596.503u 62.456s 16:38.87 766.7%	0+0k 0+0io 1pf+0w
>dmft1      ( 01:54:13 ) 658.26user 9.29system 1:39.82elapsed 668%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:55:53 ) 48816.77user 75.85system 1:52:01elapsed 727%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:47:54 ) 11126.88user 11.19system 23:27.46elapsed 791%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:11:22 ) 0.127u 0.014s 0:00.18 72.2%	0+0k 0+0io 1pf+0w
>mixer      ( 04:11:22 ) 0.414u 0.128s 0:01.46 36.3%	0+0k 0+0io 3pf+0w
:ENERGY convergence:  0.000119579955935
:CHARGE convergence:  0.0002912
>lapw0      ( 04:11:24 ) starting parallel lapw0 at Fri Feb  7 04:11:24 CST 2014
-------- .machine0 : 8 processors
12.065u 0.430s 0:03.78 330.4%	0+0k 0+0io 88pf+0w
>lapw1      ( 04:11:28 ) starting parallel lapw1 at Fri Feb  7 04:11:28 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 04:11:28 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 11311
[2] 11330
[3] 11349
[4] 11368
[5] 11387
[6] 11407
[7] 11426
[8] 11445
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 918.187u 3.693s 15:22.63 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 924.213u 3.557s 15:28.37 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 894.811u 3.856s 15:01.27 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 918.233u 3.578s 15:23.91 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 921.308u 4.208s 15:27.63 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 915.326u 3.718s 15:19.52 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 908.807u 3.595s 15:13.16 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 917.426u 3.541s 15:21.73 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7318.31	 wallclock=7358.22
7318.787u 30.874s 15:32.96 787.7%	0+0k 0+0io 2pf+0w
>lapwso     ( 04:27:01 ) running LAPWSO in parallel mode
[1] 12778
[2] 12784
[3] 12790
[4] 12797
[5] 12803
[6] 12809
[7] 12815
[8] 12821
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 907.892u 7.712s 15:39.78 97.4% 0+0k 0+0io 0pf+0w
      node022 907.678u 8.340s 15:33.36 98.1% 0+0k 0+0io 0pf+0w
      node022 895.711u 7.265s 15:17.81 98.3% 0+0k 0+0io 0pf+0w
      node022 952.261u 6.654s 16:09.66 98.8% 0+0k 0+0io 0pf+0w
      node022 956.633u 6.882s 16:14.72 98.8% 0+0k 0+0io 0pf+0w
      node022 927.436u 6.845s 15:54.97 97.8% 0+0k 0+0io 0pf+0w
      node022 891.510u 7.102s 15:07.39 99.0% 0+0k 0+0io 0pf+0w
      node022 941.137u 6.433s 15:56.94 99.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7380.26	 wallclock=7554.63
7380.374u 61.032s 16:22.60 757.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:43:24 ) 658.50user 8.89system 1:29.25elapsed 747%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:44:53 ) 56673.95user 78.78system 2:09:05elapsed 732%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:53:59 ) 11047.17user 11.17system 23:04.93elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 07:17:04 ) 0.134u 0.009s 0:00.18 72.2%	0+0k 0+0io 1pf+0w
>mixer      ( 07:17:05 ) 0.413u 0.136s 0:01.48 36.4%	0+0k 0+0io 3pf+0w
:ENERGY convergence:  0.00029918004293
:CHARGE convergence:  0.0004336
>lapw0      ( 07:17:06 ) starting parallel lapw0 at Fri Feb  7 07:17:06 CST 2014
-------- .machine0 : 8 processors
12.227u 0.440s 0:03.82 331.4%	0+0k 0+0io 92pf+0w
>lapw1      ( 07:17:10 ) starting parallel lapw1 at Fri Feb  7 07:17:10 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 07:17:10 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 15324
[2] 15343
[3] 15362
[4] 15382
[5] 15401
[6] 15420
[7] 15439
[8] 15458
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 931.966u 4.194s 15:37.15 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 935.160u 3.685s 15:42.08 99.6%	0+0k 0+0io 0pf+0w
     node022(34) 924.288u 3.528s 15:28.34 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 930.666u 3.549s 15:36.89 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 928.017u 4.105s 15:33.06 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 906.417u 3.678s 15:11.14 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 921.445u 3.671s 15:25.91 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 927.747u 3.492s 15:31.73 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7405.71	 wallclock=7446.3
7406.168u 31.060s 15:44.44 787.4%	0+0k 0+0io 4pf+0w
>lapwso     ( 07:32:55 ) running LAPWSO in parallel mode
[1] 16808
[2] 16814
[3] 16820
[4] 16827
[5] 16833
[6] 16839
[7] 16845
[8] 16851
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 927.690u 6.959s 15:54.21 97.9% 0+0k 0+0io 0pf+0w
      node022 954.210u 7.684s 16:18.78 98.2% 0+0k 0+0io 0pf+0w
      node022 962.165u 7.034s 16:17.41 99.1% 0+0k 0+0io 0pf+0w
      node022 946.868u 7.642s 16:15.48 97.8% 0+0k 0+0io 0pf+0w
      node022 956.147u 7.078s 16:18.04 98.4% 0+0k 0+0io 0pf+0w
      node022 896.875u 6.974s 15:20.83 98.1% 0+0k 0+0io 0pf+0w
      node022 936.285u 7.607s 16:03.58 97.9% 0+0k 0+0io 0pf+0w
      node022 975.103u 6.493s 16:31.58 98.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7555.34	 wallclock=7739.91
7555.450u 61.317s 16:42.48 759.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 07:49:37 ) 655.76user 8.91system 1:29.69elapsed 741%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 07:51:07 ) 47750.40user 75.87system 1:48:43elapsed 733%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 09:39:50 ) 11098.39user 11.03system 23:30.10elapsed 787%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 10:03:20 ) 0.129u 0.011s 0:00.15 86.6%	0+0k 0+0io 1pf+0w
>mixer      ( 10:03:21 ) 0.403u 0.142s 0:01.42 38.0%	0+0k 0+0io 3pf+0w
:ENERGY convergence:  9.07001085579e-05
:CHARGE convergence:  9.37e-05
>lapw0      ( 10:03:22 ) starting parallel lapw0 at Fri Feb  7 10:03:22 CST 2014
-------- .machine0 : 8 processors
11.912u 0.452s 0:03.79 326.1%	0+0k 0+0io 89pf+0w
>lapw1      ( 10:03:26 ) starting parallel lapw1 at Fri Feb  7 10:03:26 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 10:03:26 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 19148
[2] 19168
[3] 19187
[4] 19206
[5] 19225
[6] 19245
[7] 19264
[8] 19283
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 915.853u 3.891s 15:19.93 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 933.699u 3.672s 15:39.03 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 917.501u 3.693s 15:22.29 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 929.207u 4.062s 15:36.94 99.6%	0+0k 0+0io 0pf+0w
     node022(34) 930.406u 3.800s 15:35.40 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 910.280u 3.734s 15:14.25 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 925.895u 3.511s 15:32.36 99.6%	0+0k 0+0io 0pf+0w
     node022(34) 911.561u 3.620s 15:16.03 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7374.4	 wallclock=7416.23
7374.830u 31.170s 15:41.42 786.6%	0+0k 0+0io 2pf+0w
>lapwso     ( 10:19:08 ) running LAPWSO in parallel mode
[1] 20630
[2] 20636
[3] 20642
[4] 20648
[5] 20654
[6] 20661
[7] 20667
[8] 20673
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 878.520u 7.015s 15:03.00 98.0% 0+0k 0+0io 0pf+0w
      node022 882.656u 7.651s 15:05.07 98.3% 0+0k 0+0io 0pf+0w
      node022 902.451u 6.719s 15:21.46 98.6% 0+0k 0+0io 0pf+0w
      node022 936.392u 7.227s 15:54.47 98.8% 0+0k 0+0io 0pf+0w
      node022 881.113u 6.889s 14:57.27 98.9% 0+0k 0+0io 0pf+0w
      node022 911.927u 7.320s 15:37.69 98.0% 0+0k 0+0io 0pf+0w
      node022 916.542u 8.050s 15:38.10 98.5% 0+0k 0+0io 0pf+0w
      node022 899.149u 7.048s 15:24.50 98.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7208.75	 wallclock=7381.56
7208.882u 61.747s 16:01.41 756.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 10:35:09 ) 653.68user 9.22system 1:31.31elapsed 725%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 10:36:40 ) 47312.20user 71.94system 1:48:12elapsed 729%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 12:24:54 ) 10596.04user 11.13system 22:08.36elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 12:47:02 ) 0.129u 0.009s 0:00.15 80.0%	0+0k 0+0io 1pf+0w
>mixer      ( 12:47:23 ) 0.423u 0.112s 0:01.38 38.4%	0+0k 0+0io 3pf+0w
:ENERGY convergence:  1.78999034688e-05
:CHARGE convergence:  0.0001157
>lapw0      ( 12:47:25 ) starting parallel lapw0 at Fri Feb  7 12:47:25 CST 2014
-------- .machine0 : 8 processors
11.853u 0.428s 0:03.76 326.3%	0+0k 0+0io 89pf+0w
>lapw1      ( 12:47:29 ) starting parallel lapw1 at Fri Feb  7 12:47:32 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 12:47:32 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 22909
[2] 22929
[3] 22948
[4] 22967
[5] 22986
[6] 23005
[7] 23025
[8] 23044
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 937.186u 3.575s 15:43.41 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 937.274u 3.576s 15:43.00 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 931.122u 4.232s 15:36.98 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 920.956u 3.518s 15:25.63 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 927.902u 3.768s 15:34.43 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 909.217u 3.676s 15:14.82 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 913.271u 3.648s 15:17.12 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 928.355u 3.446s 15:32.37 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7405.28	 wallclock=7447.76
7405.756u 30.588s 15:45.27 786.6%	0+0k 0+0io 2pf+0w
>lapwso     ( 13:03:17 ) running LAPWSO in parallel mode
[1] 24399
[2] 24405
[3] 24411
[4] 24417
[5] 24424
[6] 24430
[7] 24436
[8] 24442
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 898.230u 6.723s 15:11.26 99.3% 0+0k 0+0io 0pf+0w
      node022 903.249u 7.253s 15:25.58 98.3% 0+0k 0+0io 0pf+0w
      node022 911.742u 7.148s 15:29.87 98.8% 0+0k 0+0io 0pf+0w
      node022 906.614u 7.321s 15:23.08 99.0% 0+0k 0+0io 0pf+0w
      node022 924.273u 7.154s 15:43.33 98.7% 0+0k 0+0io 0pf+0w
      node022 955.972u 7.909s 16:17.71 98.5% 0+0k 0+0io 0pf+0w
      node022 946.201u 7.587s 16:05.18 98.8% 0+0k 0+0io 0pf+0w
      node022 936.260u 6.838s 15:57.07 98.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7382.54	 wallclock=7533.08
7382.673u 61.750s 16:26.60 754.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 13:19:44 ) 654.66user 8.85system 1:30.01elapsed 737%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 13:21:14 ) 49314.36user 74.94system 1:58:56elapsed 692%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 15:20:10 ) 11150.28user 11.18system 23:29.08elapsed 792%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 15:43:39 ) 0.155u 0.015s 0:00.28 57.1%	0+0k 0+0io 1pf+0w
>mixer      ( 15:43:40 ) 0.425u 0.144s 0:01.75 32.0%	0+0k 0+0io 7pf+0w
:ENERGY convergence:  0.000141419935971
:CHARGE convergence:  0.0001851
>lapw0      ( 15:47:42 ) starting parallel lapw0 at Fri Feb  7 15:49:45 CST 2014
-------- .machine0 : 8 processors
12.472u 0.449s 6:03.98 3.5%	0+0k 0+0io 104pf+0w
>lapw1      ( 15:55:49 ) starting parallel lapw1 at Fri Feb  7 15:59:49 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 15:59:50 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 27032
[2] 27051
[3] 27070
[4] 27089
[5] 27109
[6] 27128
[7] 27147
[8] 27166
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 922.217u 4.193s 15:29.56 99.6%	0+0k 0+0io 1pf+0w
     node022(34) 933.719u 3.735s 15:39.42 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 931.205u 3.508s 15:36.02 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 923.644u 3.542s 15:27.56 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 928.270u 3.721s 15:33.01 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 921.206u 4.038s 15:27.04 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 918.078u 3.502s 15:24.17 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 925.601u 3.408s 15:30.86 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7403.94	 wallclock=7447.64
7404.387u 30.825s 15:44.18 787.4%	0+0k 0+0io 12pf+0w
>lapwso     ( 16:15:33 ) running LAPWSO in parallel mode
[1] 28546
[2] 28553
[3] 28559
[4] 28565
[5] 28571
[6] 28577
[7] 28584
[8] 28590
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 905.985u 6.872s 15:19.95 99.2% 0+0k 0+0io 0pf+0w
      node022 952.996u 7.486s 16:12.73 98.7% 0+0k 0+0io 0pf+0w
      node022 945.793u 6.922s 16:05.87 98.6% 0+0k 0+0io 0pf+0w
      node022 942.997u 7.189s 16:01.71 98.8% 0+0k 0+0io 0pf+0w
      node022 939.078u 6.957s 15:57.00 98.8% 0+0k 0+0io 0pf+0w
      node022 946.409u 6.866s 16:00.50 99.2% 0+0k 0+0io 0pf+0w
      node022 949.369u 7.747s 16:03.70 99.3% 0+0k 0+0io 0pf+0w
      node022 949.664u 7.114s 16:11.93 98.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7532.29	 wallclock=7673.39
7532.418u 61.201s 16:23.79 771.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 16:32:42 ) 653.89user 9.19system 5:27.49elapsed 202%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 16:38:09 ) 48074.63user 76.65system 1:49:39elapsed 731%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 18:27:49 ) 11262.46user 11.06system 24:26.76elapsed 768%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 18:52:16 ) 0.131u 0.016s 0:00.22 63.6%	0+0k 0+0io 1pf+0w
>mixer      ( 18:52:17 ) 0.431u 0.143s 0:01.38 41.3%	0+0k 0+0io 3pf+0w
:ENERGY convergence:  9.45499632508e-05
:CHARGE convergence:  0.0001854
>lapw0      ( 18:52:18 ) starting parallel lapw0 at Fri Feb  7 18:54:27 CST 2014
-------- .machine0 : 8 processors
12.233u 0.477s 3:47.67 5.5%	0+0k 0+0io 98pf+0w
>lapw1      ( 18:58:15 ) starting parallel lapw1 at Fri Feb  7 19:00:15 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 19:00:15 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 31008
[2] 31027
[3] 31046
[4] 31065
[5] 31084
[6] 31104
[7] 31123
[8] 31142
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 908.678u 4.235s 15:15.59 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 926.728u 3.786s 15:34.39 99.5%	0+0k 0+0io 0pf+0w
     node022(34) 914.364u 3.595s 15:19.46 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 911.239u 3.885s 15:16.89 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 927.029u 3.602s 15:31.94 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 907.933u 3.704s 15:12.76 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 916.114u 3.640s 15:22.12 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 922.256u 3.563s 15:27.14 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7334.34	 wallclock=7380.29
7334.776u 31.209s 15:37.54 785.6%	0+0k 0+0io 9pf+0w
>lapwso     ( 19:15:53 ) running LAPWSO in parallel mode
[1] 32499
[2] 32505
[3] 32511
[4] 32517
[5] 32523
[6] 32530
[7] 32536
[8] 32542
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 944.355u 7.061s 16:10.85 97.9% 0+0k 0+0io 1pf+0w
      node022 922.485u 7.086s 15:37.93 99.1% 0+0k 0+0io 0pf+0w
      node022 950.787u 7.278s 16:06.89 99.0% 0+0k 0+0io 0pf+0w
      node022 963.606u 6.906s 16:16.38 99.3% 0+0k 0+0io 0pf+0w
      node022 965.631u 7.239s 16:19.39 99.3% 0+0k 0+0io 0pf+0w
      node022 933.887u 7.668s 16:14.94 96.5% 0+0k 0+0io 0pf+0w
      node022 953.125u 7.516s 16:22.61 97.7% 0+0k 0+0io 0pf+0w
      node022 953.389u 6.950s 16:25.49 97.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7587.27	 wallclock=7774.48
7587.398u 61.567s 16:36.88 767.2%	0+0k 0+0io 1pf+0w
>dmft1      ( 19:32:30 ) 651.98user 9.02system 1:28.94elapsed 743%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 19:33:59 ) 48522.99user 79.21system 1:52:16elapsed 721%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 21:26:15 ) 10989.71user 10.87system 23:00.56elapsed 796%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 21:49:16 ) 0.136u 0.017s 0:00.31 45.1%	0+0k 0+0io 1pf+0w
>mixer      ( 21:49:37 ) 0.418u 0.149s 0:01.79 30.7%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  6.76099443808e-05
:CHARGE convergence:  0.0001851
>lapw0      ( 21:49:39 ) starting parallel lapw0 at Fri Feb  7 21:49:40 CST 2014
-------- .machine0 : 8 processors
12.275u 0.410s 0:03.96 320.2%	0+0k 0+0io 96pf+0w
>lapw1      ( 21:49:44 ) starting parallel lapw1 at Fri Feb  7 21:49:44 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 21:49:44 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 2451
[2] 2470
[3] 2499
[4] 2518
[5] 2537
[6] 2556
[7] 2576
[8] 2599
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 899.990u 3.850s 15:05.40 99.8%	0+0k 0+0io 1pf+0w
     node022(34) 917.166u 3.686s 15:23.22 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 929.878u 3.849s 15:39.42 99.3%	0+0k 0+0io 0pf+0w
     node022(34) 931.394u 3.597s 15:37.78 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 910.822u 3.737s 15:14.67 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 908.869u 4.323s 15:17.20 99.5%	0+0k 0+0io 0pf+0w
     node022(34) 925.518u 3.591s 15:29.58 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 925.265u 3.584s 15:29.69 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7348.9	 wallclock=7396.96
7349.352u 31.395s 15:43.66 782.1%	0+0k 0+0io 15pf+0w
>lapwso     ( 22:05:27 ) running LAPWSO in parallel mode
[1] 4009
[2] 4015
[3] 4022
[4] 4029
[5] 4037
[6] 4043
[7] 4049
[8] 4056
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 899.822u 6.736s 15:18.56 98.6% 0+0k 0+0io 0pf+0w
      node022 922.470u 6.968s 15:38.48 99.0% 0+0k 0+0io 0pf+0w
      node022 916.050u 7.587s 15:44.14 97.8% 0+0k 0+0io 0pf+0w
      node022 913.317u 8.025s 15:32.09 98.8% 0+0k 0+0io 0pf+0w
      node022 924.897u 7.590s 15:53.22 97.8% 0+0k 0+0io 0pf+0w
      node022 938.881u 7.467s 15:59.63 98.6% 0+0k 0+0io 0pf+0w
      node022 942.507u 6.725s 15:58.03 99.0% 0+0k 0+0io 0pf+0w
      node022 947.454u 7.209s 16:19.18 97.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7405.4	 wallclock=7583.33
7405.520u 62.248s 16:30.59 753.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:21:58 ) 661.88user 9.14system 1:29.29elapsed 751%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:23:27 ) 49151.37user 75.33system 1:53:51elapsed 720%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:17:19 ) 11131.65user 11.39system 23:15.57elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:40:34 ) 0.137u 0.008s 0:00.16 81.2%	0+0k 0+0io 1pf+0w
>mixer      ( 00:40:44 ) 0.331u 0.125s 0:00.51 88.2%	0+0k 0+0io 2pf+0w
:ENERGY convergence:  1.22600467876e-05
:CHARGE convergence:  0.000242
>lapw0      ( 00:44:18 ) starting parallel lapw0 at Sat Feb  8 00:45:05 CST 2014
-------- .machine0 : 8 processors
11.964u 0.442s 1:39.32 12.4%	0+0k 0+0io 92pf+0w
>lapw1      ( 00:46:43 ) starting parallel lapw1 at Sat Feb  8 00:46:43 CST 2014
->  starting parallel LAPW1 jobs at Sat Feb  8 00:46:43 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 6566
[2] 6586
[3] 6605
[4] 6624
[5] 6643
[6] 6662
[7] 6682
[8] 6701
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(34) 921.623u 3.586s 15:27.55 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 915.648u 3.702s 15:20.72 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 933.936u 3.578s 15:38.78 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 918.314u 4.543s 15:24.18 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 918.885u 3.658s 15:22.78 99.9%	0+0k 0+0io 0pf+0w
     node022(34) 928.895u 3.630s 15:34.89 99.7%	0+0k 0+0io 0pf+0w
     node022(34) 924.049u 3.623s 15:28.73 99.8%	0+0k 0+0io 0pf+0w
     node022(34) 926.386u 3.571s 15:30.82 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=272	 user=7387.74	 wallclock=7428.45
7388.165u 31.067s 15:42.06 787.5%	0+0k 0+0io 2pf+0w
>lapwso     ( 01:02:25 ) running LAPWSO in parallel mode
[1] 8061
[2] 8067
[3] 8073
[4] 8079
[5] 8085
[6] 8092
[7] 8098
[8] 8104
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 912.663u 7.450s 15:30.78 98.8% 0+0k 0+0io 0pf+0w
      node022 914.429u 7.039s 15:30.71 99.0% 0+0k 0+0io 0pf+0w
      node022 941.133u 7.446s 15:59.44 98.8% 0+0k 0+0io 0pf+0w
      node022 958.412u 7.154s 16:17.66 98.7% 0+0k 0+0io 0pf+0w
      node022 908.767u 7.272s 15:35.49 97.9% 0+0k 0+0io 0pf+0w
      node022 932.501u 6.915s 16:00.83 97.7% 0+0k 0+0io 0pf+0w
      node022 944.994u 7.700s 16:07.56 98.4% 0+0k 0+0io 0pf+0w
      node022 922.723u 7.172s 15:49.97 97.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=7435.62	 wallclock=7612.44
7435.753u 61.947s 16:24.51 761.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:18:50 ) 653.95user 9.01system 1:27.67elapsed 756%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:20:18 ) 49141.40user 71.43system 1:54:51elapsed 714%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:15:10 ) 11074.23user 11.03system 23:08.39elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:38:18 ) 0.143u 0.008s 0:00.27 51.8%	0+0k 0+0io 1pf+0w
>mixer      ( 03:38:19 ) 0.371u 0.124s 0:01.34 36.5%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  7.29993917048e-06
:CHARGE convergence:  0.0003175
