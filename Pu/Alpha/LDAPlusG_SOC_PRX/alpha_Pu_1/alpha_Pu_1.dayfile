Calculating alpha_Pu_1 in /scratch/ykent33892/alpha_Pu_1
on node023 with PID 8938




   start        Tue Feb  4 21:15:31 2014 with lapw0 (1/100 to go)

   cycle 0 	Tue Feb  4 21:15:31 2014 1000/0 to go

>lapw0      ( 21:15:31 ) starting parallel lapw0 at Tue Feb  4 21:15:31 CST 2014
-------- .machine0 : 8 processors
10.260u 0.420s 0:06.68 159.8%	0+0k 0+0io 97pf+0w
>lapw1      ( 21:15:38 ) starting parallel lapw1 at Tue Feb  4 21:15:47 CST 2014
->  starting parallel LAPW1 jobs at Tue Feb  4 21:15:47 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 9163
[2] 9183
[3] 9202
[4] 9221
[5] 9240
[6] 9259
[7] 9279
[8] 9298
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 536.699u 2.685s 9:00.21 99.8%	0+0k 0+0io 1pf+0w
     node023(34) 517.684u 2.790s 8:45.68 99.0%	0+0k 0+0io 0pf+0w
     node023(34) 535.510u 3.357s 8:59.23 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 528.213u 2.780s 8:55.40 99.1%	0+0k 0+0io 0pf+0w
     node023(34) 534.262u 2.560s 8:56.98 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 529.994u 2.776s 8:53.39 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 531.897u 2.607s 8:54.98 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 525.921u 2.728s 8:53.89 99.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4240.18	 wallclock=4279.76
4240.463u 23.060s 9:02.49 785.9%	0+0k 0+0io 1pf+0w
>lapwso     ( 21:24:49 ) running LAPWSO in parallel mode
[1] 10134
[2] 10140
[3] 10146
[4] 10152
[5] 10159
[6] 10165
[7] 10171
[8] 10177
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 533.904u 4.118s 11:21.28 78.9% 0+0k 0+0io 1pf+0w
      node023 530.890u 4.194s 11:32.04 77.3% 0+0k 0+0io 0pf+0w
      node023 536.407u 4.446s 11:41.13 77.1% 0+0k 0+0io 0pf+0w
      node023 543.031u 4.116s 11:25.64 79.7% 0+0k 0+0io 0pf+0w
      node023 546.439u 4.205s 11:33.48 79.4% 0+0k 0+0io 0pf+0w
      node023 535.690u 5.115s 11:31.04 78.2% 0+0k 0+0io 0pf+0w
      node023 548.905u 4.757s 11:45.45 78.4% 0+0k 0+0io 0pf+0w
      node023 533.980u 4.266s 11:50.13 75.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4309.25	 wallclock=5560.19
4309.363u 35.509s 11:59.28 604.0%	0+0k 0+0io 1pf+0w
>dmft1      ( 21:36:49 ) 502.58user 7.11system 1:37.50elapsed 522%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 21:38:30 ) 66788.99user 94.48system 2:33:35elapsed 725%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:12:05 ) 9337.55user 10.08system 19:35.25elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:31:40 ) 0.132u 0.011s 0:00.15 93.3%	0+0k 0+0io 1pf+0w
>mixer      ( 00:31:41 ) 0.284u 0.104s 0:00.50 76.0%	0+0k 0+0io 3pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0261557
>lapw0      ( 00:31:41 ) starting parallel lapw0 at Wed Feb  5 00:31:41 CST 2014
-------- .machine0 : 8 processors
10.361u 0.421s 0:03.56 302.8%	0+0k 0+0io 85pf+0w
>lapw1      ( 00:31:45 ) starting parallel lapw1 at Wed Feb  5 00:31:45 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 00:31:46 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 12837
[2] 12857
[3] 12876
[4] 12895
[5] 12914
[6] 12933
[7] 12953
[8] 12972
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 512.886u 3.053s 8:38.37 99.5%	0+0k 0+0io 0pf+0w
     node023(34) 520.185u 2.972s 8:43.86 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 528.007u 2.844s 8:53.49 99.5%	0+0k 0+0io 0pf+0w
     node023(34) 530.102u 3.057s 8:56.59 99.3%	0+0k 0+0io 0pf+0w
     node023(34) 521.294u 2.973s 8:45.23 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 533.804u 2.748s 8:57.22 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 529.046u 2.864s 8:56.61 99.1%	0+0k 0+0io 0pf+0w
     node023(34) 520.146u 3.082s 8:43.70 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4195.47	 wallclock=4235.07
4195.771u 24.377s 9:04.50 775.0%	0+0k 0+0io 2pf+0w
>lapwso     ( 00:40:50 ) running LAPWSO in parallel mode
[1] 13818
[2] 13825
[3] 13831
[4] 13837
[5] 13843
[6] 13850
[7] 13856
[8] 13862
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 527.019u 4.221s 12:47.24 69.2% 0+0k 0+0io 1pf+0w
      node023 547.567u 4.315s 13:21.88 68.8% 0+0k 0+0io 0pf+0w
      node023 531.629u 4.231s 13:09.75 67.8% 0+0k 0+0io 0pf+0w
      node023 534.338u 4.280s 12:37.55 71.0% 0+0k 0+0io 0pf+0w
      node023 536.840u 4.326s 13:02.30 69.1% 0+0k 0+0io 0pf+0w
      node023 528.742u 5.224s 13:08.33 67.7% 0+0k 0+0io 0pf+0w
      node023 535.406u 5.145s 13:45.00 65.5% 0+0k 0+0io 0pf+0w
      node023 528.384u 4.364s 12:59.14 68.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4269.93	 wallclock=6291.19
4270.054u 38.890s 14:01.26 512.2%	0+0k 0+0io 1pf+0w
>dmft1      ( 00:54:51 ) 496.26user 8.05system 3:34.18elapsed 235%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:58:25 ) 51954.58user 79.48system 2:04:47elapsed 694%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:03:13 ) 9166.35user 10.31system 19:17.08elapsed 793%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:22:30 ) 0.124u 0.014s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 03:22:30 ) 0.303u 0.092s 0:00.39 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000235100043938
:CHARGE convergence:  0.0261614
>lapw0      ( 03:22:31 ) starting parallel lapw0 at Wed Feb  5 03:22:31 CST 2014
-------- .machine0 : 8 processors
10.236u 0.406s 0:03.56 298.5%	0+0k 0+0io 88pf+0w
>lapw1      ( 03:22:34 ) starting parallel lapw1 at Wed Feb  5 03:22:34 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 03:22:34 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 16187
[2] 16206
[3] 16226
[4] 16245
[5] 16264
[6] 16283
[7] 16302
[8] 16322
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 531.035u 2.942s 8:54.11 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 540.993u 3.167s 9:05.67 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 539.132u 2.812s 9:02.59 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 534.229u 2.979s 8:59.07 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 539.681u 2.733s 9:02.56 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 538.745u 2.750s 9:01.88 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 532.560u 2.929s 8:55.70 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 527.864u 2.823s 8:50.86 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4284.24	 wallclock=4312.44
4284.548u 23.950s 9:09.60 783.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:31:44 ) running LAPWSO in parallel mode
[1] 17197
[2] 17203
[3] 17210
[4] 17216
[5] 17222
[6] 17228
[7] 17234
[8] 17241
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 518.119u 4.409s 13:52.84 62.7% 0+0k 0+0io 0pf+0w
      node023 524.363u 4.283s 13:33.14 65.0% 0+0k 0+0io 0pf+0w
      node023 534.603u 4.269s 14:05.07 63.7% 0+0k 0+0io 0pf+0w
      node023 533.831u 4.195s 13:53.27 64.5% 0+0k 0+0io 0pf+0w
      node023 524.781u 4.190s 13:16.01 66.4% 0+0k 0+0io 0pf+0w
      node023 534.847u 5.355s 13:01.24 69.1% 0+0k 0+0io 0pf+0w
      node023 537.282u 5.146s 13:32.34 66.7% 0+0k 0+0io 0pf+0w
      node023 527.569u 4.367s 13:53.67 63.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4235.4	 wallclock=6547.58
4235.530u 39.141s 14:10.98 502.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:45:55 ) 500.04user 7.95system 3:57.21elapsed 214%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:49:52 ) 59108.30user 96.48system 2:16:03elapsed 725%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:06:00 ) 9148.51user 10.11system 19:15.82elapsed 792%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:25:16 ) 0.126u 0.012s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 06:25:16 ) 0.308u 0.098s 0:00.41 95.1%	0+0k 0+0io 3pf+0w
:ENERGY convergence:  0.00461925996933
:CHARGE convergence:  0.0376538
>lapw0      ( 06:25:16 ) starting parallel lapw0 at Wed Feb  5 06:25:16 CST 2014
-------- .machine0 : 8 processors
10.179u 0.433s 0:03.53 300.2%	0+0k 0+0io 86pf+0w
>lapw1      ( 06:25:20 ) starting parallel lapw1 at Wed Feb  5 06:25:20 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 06:25:20 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 20172
[2] 20191
[3] 20210
[4] 20229
[5] 20248
[6] 20268
[7] 20287
[8] 20306
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 523.771u 3.116s 8:49.40 99.5%	0+0k 0+0io 0pf+0w
     node023(34) 539.807u 2.773s 9:02.71 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 537.977u 3.244s 9:02.62 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 528.234u 2.961s 8:53.09 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 531.296u 2.822s 8:59.20 99.0%	0+0k 0+0io 0pf+0w
     node023(34) 534.968u 2.768s 8:58.61 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 532.677u 2.877s 8:56.09 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 529.140u 2.867s 8:52.08 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4257.87	 wallclock=4293.8
4258.168u 24.244s 9:05.90 784.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 06:34:26 ) running LAPWSO in parallel mode
[1] 21181
[2] 21187
[3] 21193
[4] 21199
[5] 21205
[6] 21212
[7] 21218
[8] 21224
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 528.423u 4.224s 11:32.36 76.9% 0+0k 0+0io 0pf+0w
      node023 543.081u 4.351s 12:08.01 75.1% 0+0k 0+0io 0pf+0w
      node023 556.836u 4.175s 12:08.03 77.0% 0+0k 0+0io 0pf+0w
      node023 551.698u 4.501s 12:15.36 75.6% 0+0k 0+0io 0pf+0w
      node023 561.163u 4.330s 12:15.94 76.8% 0+0k 0+0io 0pf+0w
      node023 532.632u 5.428s 11:54.47 75.3% 0+0k 0+0io 0pf+0w
      node023 538.451u 5.350s 12:41.02 71.4% 0+0k 0+0io 0pf+0w
      node023 531.239u 4.254s 12:10.32 73.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4343.52	 wallclock=5825.51
4343.643u 39.498s 12:51.01 568.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 06:47:17 ) 500.35user 8.15system 3:14.70elapsed 261%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 06:50:32 ) 59590.68user 102.53system 2:12:40elapsed 749%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 09:03:13 ) 9176.25user 9.85system 19:18.60elapsed 792%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 09:22:31 ) 0.135u 0.007s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 09:22:32 ) 0.304u 0.105s 0:00.41 97.5%	0+0k 0+0io 1pf+0w
:ENERGY convergence:  0.00754230993334
:CHARGE convergence:  0.016914
>lapw0      ( 09:22:32 ) starting parallel lapw0 at Wed Feb  5 09:22:32 CST 2014
-------- .machine0 : 8 processors
10.368u 0.403s 0:03.64 295.6%	0+0k 0+0io 89pf+0w
>lapw1      ( 09:22:36 ) starting parallel lapw1 at Wed Feb  5 09:23:21 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 09:23:21 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 23657
[2] 23676
[3] 23695
[4] 23715
[5] 23734
[6] 23753
[7] 23772
[8] 23791
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 527.477u 2.895s 8:50.44 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 527.119u 2.868s 8:51.28 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 537.601u 2.784s 9:01.35 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 534.077u 2.934s 8:57.52 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 534.116u 2.935s 8:58.91 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 537.339u 3.033s 9:01.08 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 534.502u 2.951s 8:58.75 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 531.327u 3.078s 8:55.02 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4263.56	 wallclock=4294.35
4263.873u 24.244s 9:09.83 779.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 09:32:31 ) running LAPWSO in parallel mode
[1] 24648
[2] 24654
[3] 24660
[4] 24666
[5] 24672
[6] 24679
[7] 24685
[8] 24691
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 529.359u 3.992s 13:04.28 68.0% 0+0k 0+0io 0pf+0w
      node023 528.888u 4.298s 12:29.09 71.1% 0+0k 0+0io 0pf+0w
      node023 529.890u 4.041s 12:57.75 68.6% 0+0k 0+0io 0pf+0w
      node023 530.657u 4.175s 13:13.68 67.3% 0+0k 0+0io 0pf+0w
      node023 547.433u 4.068s 12:54.96 71.1% 0+0k 0+0io 0pf+0w
      node023 528.715u 5.131s 12:51.31 69.2% 0+0k 0+0io 0pf+0w
      node023 548.342u 5.162s 13:27.59 68.5% 0+0k 0+0io 0pf+0w
      node023 538.007u 4.226s 12:44.79 70.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4281.29	 wallclock=6223.45
4281.415u 38.019s 13:36.59 528.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 09:47:41 ) 492.99user 8.21system 1:57.03elapsed 428%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 09:49:38 ) 61311.99user 108.32system 2:21:44elapsed 722%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 12:11:23 ) 9157.11user 9.39system 19:15.40elapsed 793%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 12:30:38 ) 0.128u 0.015s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 12:30:39 ) 0.323u 0.103s 0:00.43 97.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00374320999254
:CHARGE convergence:  0.0281332
>lapw0      ( 12:30:39 ) starting parallel lapw0 at Wed Feb  5 12:30:39 CST 2014
-------- .machine0 : 8 processors
10.365u 0.394s 0:03.54 303.6%	0+0k 0+0io 84pf+0w
>lapw1      ( 12:30:43 ) starting parallel lapw1 at Wed Feb  5 12:30:44 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 12:30:44 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 27195
[2] 27214
[3] 27233
[4] 27252
[5] 27272
[6] 27291
[7] 27310
[8] 27329
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 537.673u 3.420s 9:04.43 99.3%	0+0k 0+0io 0pf+0w
     node023(34) 541.523u 2.891s 9:06.48 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 539.260u 2.849s 9:02.87 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 533.574u 2.859s 8:59.82 99.3%	0+0k 0+0io 0pf+0w
     node023(34) 538.642u 2.766s 9:03.59 99.5%	0+0k 0+0io 0pf+0w
     node023(34) 536.682u 2.809s 9:03.26 99.3%	0+0k 0+0io 0pf+0w
     node023(34) 539.318u 2.708s 9:02.12 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 532.962u 2.895s 8:56.56 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4299.63	 wallclock=4339.13
4299.925u 24.013s 9:10.85 784.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 12:39:54 ) running LAPWSO in parallel mode
[1] 28176
[2] 28183
[3] 28189
[4] 28197
[5] 28203
[6] 28209
[7] 28216
[8] 28222
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 532.439u 4.165s 12:28.07 71.7% 0+0k 0+0io 0pf+0w
      node023 529.593u 4.439s 12:23.26 71.8% 0+0k 0+0io 0pf+0w
      node023 529.395u 4.337s 13:03.64 68.1% 0+0k 0+0io 0pf+0w
      node023 531.360u 4.377s 12:13.60 73.0% 0+0k 0+0io 0pf+0w
      node023 536.577u 4.240s 12:35.04 71.6% 0+0k 0+0io 0pf+0w
      node023 535.256u 5.394s 12:47.40 70.4% 0+0k 0+0io 0pf+0w
      node023 536.209u 5.144s 12:37.66 71.4% 0+0k 0+0io 0pf+0w
      node023 538.405u 4.421s 12:28.10 72.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4269.23	 wallclock=6036.77
4269.341u 39.561s 13:12.39 543.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 12:53:07 ) 504.72user 8.01system 2:47.27elapsed 306%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 12:55:54 ) 59547.28user 102.70system 2:13:20elapsed 745%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 15:09:15 ) 9139.07user 9.92system 19:18.06elapsed 790%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 15:28:33 ) 0.131u 0.011s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 15:28:33 ) 0.320u 0.109s 0:00.43 97.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000459869974293
:CHARGE convergence:  0.0296181
>lapw0      ( 15:28:33 ) starting parallel lapw0 at Wed Feb  5 15:28:34 CST 2014
-------- .machine0 : 8 processors
10.327u 0.429s 0:03.54 303.3%	0+0k 0+0io 86pf+0w
>lapw1      ( 15:28:37 ) starting parallel lapw1 at Wed Feb  5 15:28:37 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 15:28:37 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 30636
[2] 30655
[3] 30674
[4] 30694
[5] 30713
[6] 30732
[7] 30751
[8] 30770
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 531.757u 2.910s 8:55.12 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 538.379u 3.502s 9:02.48 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 537.913u 2.893s 9:02.28 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 536.996u 2.905s 9:00.05 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 535.968u 2.730s 8:59.07 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 531.486u 2.719s 8:58.98 99.1%	0+0k 0+0io 0pf+0w
     node023(34) 534.428u 2.834s 8:58.66 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 532.168u 2.836s 8:55.48 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4279.09	 wallclock=4312.12
4279.412u 24.134s 9:06.99 786.7%	0+0k 0+0io 0pf+0w
>lapwso     ( 15:37:44 ) running LAPWSO in parallel mode
[1] 31636
[2] 31642
[3] 31648
[4] 31654
[5] 31660
[6] 31667
[7] 31673
[8] 31679
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 537.392u 4.327s 12:31.54 72.0% 0+0k 0+0io 0pf+0w
      node023 544.591u 4.178s 12:48.91 71.3% 0+0k 0+0io 0pf+0w
      node023 538.231u 4.396s 12:44.52 70.9% 0+0k 0+0io 0pf+0w
      node023 541.208u 4.140s 12:47.04 71.0% 0+0k 0+0io 0pf+0w
      node023 553.655u 4.492s 13:15.03 70.2% 0+0k 0+0io 0pf+0w
      node023 555.886u 5.296s 13:37.82 68.6% 0+0k 0+0io 0pf+0w
      node023 545.662u 5.186s 13:08.24 69.8% 0+0k 0+0io 0pf+0w
      node023 533.171u 4.395s 12:58.66 69.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4349.8	 wallclock=6231.76
4349.923u 39.419s 13:56.22 524.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 15:51:40 ) 500.80user 8.01system 2:29.58elapsed 340%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 15:54:10 ) 59971.19user 99.01system 2:15:40elapsed 737%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 18:09:51 ) 9174.82user 9.77system 19:19.80elapsed 791%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 18:29:10 ) 0.129u 0.010s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 18:29:11 ) 0.341u 0.104s 0:00.45 97.7%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000186449964531
:CHARGE convergence:  0.0293548
>lapw0      ( 18:29:11 ) starting parallel lapw0 at Wed Feb  5 18:29:11 CST 2014
-------- .machine0 : 8 processors
10.362u 0.423s 0:03.66 294.5%	0+0k 0+0io 82pf+0w
>lapw1      ( 18:29:15 ) starting parallel lapw1 at Wed Feb  5 18:29:15 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 18:29:15 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 1711
[2] 1731
[3] 1750
[4] 1770
[5] 1789
[6] 1808
[7] 1828
[8] 1847
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 535.701u 2.934s 8:58.77 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 542.130u 2.842s 9:05.15 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 538.349u 2.737s 9:01.68 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 535.716u 3.536s 9:00.56 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 534.688u 2.784s 8:58.04 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 538.093u 2.882s 9:03.01 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 538.406u 2.877s 9:02.18 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 535.388u 2.955s 8:58.52 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4298.47	 wallclock=4327.91
4298.781u 24.376s 9:11.72 783.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 18:38:27 ) running LAPWSO in parallel mode
[1] 2746
[2] 2752
[3] 2758
[4] 2764
[5] 2771
[6] 2777
[7] 2783
[8] 2789
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 536.054u 4.196s 13:25.47 67.0% 0+0k 0+0io 0pf+0w
      node023 539.422u 4.188s 13:13.89 68.4% 0+0k 0+0io 0pf+0w
      node023 534.825u 4.380s 13:07.10 68.5% 0+0k 0+0io 0pf+0w
      node023 536.524u 4.370s 13:02.29 69.1% 0+0k 0+0io 0pf+0w
      node023 537.675u 4.383s 13:34.72 66.5% 0+0k 0+0io 0pf+0w
      node023 535.788u 5.540s 13:26.30 67.1% 0+0k 0+0io 0pf+0w
      node023 542.061u 5.368s 13:08.82 69.3% 0+0k 0+0io 0pf+0w
      node023 539.359u 4.440s 14:25.31 62.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4301.71	 wallclock=6443.9
4301.836u 39.755s 14:35.37 495.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 18:53:02 ) 501.61user 8.20system 2:03.66elapsed 412%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 18:55:06 ) 59385.43user 98.83system 2:14:57elapsed 734%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 21:10:05 ) 9162.18user 10.09system 19:18.12elapsed 791%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 21:29:23 ) 0.128u 0.010s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 21:29:24 ) 0.340u 0.114s 0:00.45 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00205074006226
:CHARGE convergence:  0.0227168
>lapw0      ( 21:29:24 ) starting parallel lapw0 at Wed Feb  5 21:29:24 CST 2014
-------- .machine0 : 8 processors
10.347u 0.417s 0:03.54 303.6%	0+0k 0+0io 85pf+0w
>lapw1      ( 21:29:28 ) starting parallel lapw1 at Wed Feb  5 21:29:28 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 21:29:28 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 5308
[2] 5327
[3] 5346
[4] 5365
[5] 5384
[6] 5404
[7] 5423
[8] 5442
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 527.989u 2.963s 8:51.37 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 535.304u 2.758s 8:58.46 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 528.463u 2.881s 8:51.57 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 527.587u 2.888s 8:51.14 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 531.709u 3.113s 8:57.55 99.4%	0+0k 0+0io 0pf+0w
     node023(34) 531.894u 3.028s 8:55.90 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 533.750u 2.926s 8:59.02 99.5%	0+0k 0+0io 0pf+0w
     node023(34) 532.160u 2.947s 8:55.41 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4248.86	 wallclock=4280.42
4249.149u 24.320s 9:07.31 780.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 21:38:35 ) running LAPWSO in parallel mode
[1] 6307
[2] 6314
[3] 6320
[4] 6326
[5] 6332
[6] 6338
[7] 6345
[8] 6351
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 547.860u 4.289s 11:16.58 81.6% 0+0k 0+0io 0pf+0w
      node023 547.231u 4.200s 11:14.50 81.7% 0+0k 0+0io 0pf+0w
      node023 550.893u 4.253s 11:41.84 79.0% 0+0k 0+0io 0pf+0w
      node023 537.219u 4.228s 11:15.23 80.1% 0+0k 0+0io 0pf+0w
      node023 550.980u 4.170s 11:27.95 80.6% 0+0k 0+0io 0pf+0w
      node023 542.558u 5.360s 11:22.80 80.2% 0+0k 0+0io 0pf+0w
      node023 556.673u 5.170s 11:33.85 80.9% 0+0k 0+0io 0pf+0w
      node023 554.803u 4.430s 11:59.61 77.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4388.22	 wallclock=5512.36
4388.334u 39.050s 12:09.64 606.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 21:50:45 ) 503.71user 8.48system 1:28.96elapsed 575%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 21:52:14 ) 58951.81user 98.11system 2:12:43elapsed 741%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:05:02 ) 9162.10user 9.85system 19:53.77elapsed 768%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:24:55 ) 0.132u 0.009s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 00:25:41 ) 0.341u 0.119s 0:00.46 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00465974991675
:CHARGE convergence:  0.0054495
>lapw0      ( 00:25:41 ) starting parallel lapw0 at Thu Feb  6 00:25:41 CST 2014
-------- .machine0 : 8 processors
10.367u 0.425s 0:03.54 304.5%	0+0k 0+0io 86pf+0w
>lapw1      ( 00:25:45 ) starting parallel lapw1 at Thu Feb  6 00:25:45 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 00:25:45 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 8772
[2] 8791
[3] 8810
[4] 8830
[5] 8850
[6] 8870
[7] 8889
[8] 8908
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 525.039u 2.900s 8:48.70 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 538.280u 2.841s 9:01.51 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 526.477u 2.899s 8:50.03 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 531.988u 3.478s 8:55.94 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 536.295u 2.898s 9:00.51 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 530.430u 2.886s 8:54.20 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 531.391u 2.893s 8:54.68 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 531.106u 2.891s 8:54.34 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4251.01	 wallclock=4279.91
4251.320u 24.487s 9:05.82 783.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 00:34:51 ) running LAPWSO in parallel mode
[1] 9774
[2] 9780
[3] 9786
[4] 9792
[5] 9798
[6] 9805
[7] 9811
[8] 9817
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 531.989u 4.293s 12:26.97 71.7% 0+0k 0+0io 0pf+0w
      node023 556.933u 4.155s 12:51.46 72.7% 0+0k 0+0io 0pf+0w
      node023 531.373u 4.398s 12:30.30 71.4% 0+0k 0+0io 0pf+0w
      node023 548.483u 4.449s 12:56.54 71.2% 0+0k 0+0io 0pf+0w
      node023 548.611u 4.251s 12:31.27 73.5% 0+0k 0+0io 0pf+0w
      node023 530.558u 5.477s 11:57.37 74.7% 0+0k 0+0io 0pf+0w
      node023 549.427u 5.329s 12:30.67 73.8% 0+0k 0+0io 0pf+0w
      node023 534.646u 4.583s 12:32.05 71.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4332.02	 wallclock=6016.63
4332.148u 39.882s 13:02.60 558.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:47:53 ) 504.33user 7.99system 2:31.68elapsed 337%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:50:25 ) 51669.13user 86.03system 1:54:10elapsed 755%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:44:36 ) 9166.92user 9.87system 19:18.19elapsed 792%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:03:54 ) 0.129u 0.012s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 03:03:54 ) 0.353u 0.109s 0:00.46 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000739810056984
:CHARGE convergence:  0.0031684
>lapw0      ( 03:03:55 ) starting parallel lapw0 at Thu Feb  6 03:03:55 CST 2014
-------- .machine0 : 8 processors
10.263u 0.405s 0:03.53 301.9%	0+0k 0+0io 84pf+0w
>lapw1      ( 03:03:58 ) starting parallel lapw1 at Thu Feb  6 03:03:58 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 03:03:58 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 11994
[2] 12013
[3] 12033
[4] 12052
[5] 12071
[6] 12090
[7] 12109
[8] 12129
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 535.588u 2.936s 8:58.61 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 535.668u 2.959s 8:59.11 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 536.859u 3.583s 9:00.51 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 533.732u 2.793s 8:58.08 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 534.698u 2.756s 8:57.94 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 533.014u 2.947s 8:57.46 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 530.730u 2.777s 8:57.43 99.2%	0+0k 0+0io 0pf+0w
     node023(34) 528.946u 2.887s 8:54.62 99.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4269.23	 wallclock=4303.76
4269.552u 24.428s 9:04.79 788.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:13:03 ) running LAPWSO in parallel mode
[1] 12998
[2] 13005
[3] 13011
[4] 13017
[5] 13023
[6] 13029
[7] 13036
[8] 13042
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 534.429u 4.264s 13:14.43 67.8% 0+0k 0+0io 0pf+0w
      node023 529.901u 4.253s 13:38.01 65.2% 0+0k 0+0io 0pf+0w
      node023 537.298u 4.311s 13:28.61 66.9% 0+0k 0+0io 0pf+0w
      node023 537.774u 4.161s 13:42.14 65.9% 0+0k 0+0io 0pf+0w
      node023 540.137u 4.179s 13:41.03 66.2% 0+0k 0+0io 0pf+0w
      node023 536.913u 5.439s 13:58.14 64.7% 0+0k 0+0io 0pf+0w
      node023 542.670u 5.032s 13:59.33 65.2% 0+0k 0+0io 0pf+0w
      node023 537.428u 4.312s 14:11.41 63.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4296.55	 wallclock=6593.1
4296.680u 38.933s 14:23.25 502.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:27:26 ) 501.12user 8.00system 1:37.30elapsed 523%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:29:04 ) 61475.26user 97.51system 2:23:10elapsed 716%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:52:16 ) 9162.97user 9.68system 19:13.48elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:11:29 ) 0.127u 0.015s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 06:11:29 ) 0.345u 0.119s 0:00.46 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000150450039655
:CHARGE convergence:  0.0046751
>lapw0      ( 06:11:30 ) starting parallel lapw0 at Thu Feb  6 06:11:30 CST 2014
-------- .machine0 : 8 processors
10.237u 0.427s 0:03.52 302.5%	0+0k 0+0io 86pf+0w
>lapw1      ( 06:11:34 ) starting parallel lapw1 at Thu Feb  6 06:11:34 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 06:11:34 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 16050
[2] 16069
[3] 16089
[4] 16108
[5] 16127
[6] 16146
[7] 16165
[8] 16185
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 532.020u 2.952s 8:55.17 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 534.232u 3.199s 8:58.40 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 527.829u 2.867s 8:50.81 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 532.478u 2.895s 8:56.77 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 533.443u 2.791s 8:56.68 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 537.133u 3.095s 9:00.95 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 531.284u 2.945s 8:56.04 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 530.205u 2.914s 8:56.08 99.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4258.62	 wallclock=4290.9
4258.946u 24.443s 9:07.55 782.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 06:20:41 ) running LAPWSO in parallel mode
[1] 17042
[2] 17049
[3] 17055
[4] 17061
[5] 17067
[6] 17073
[7] 17080
[8] 17086
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 518.671u 4.332s 12:24.83 70.2% 0+0k 0+0io 0pf+0w
      node023 532.843u 4.233s 12:44.81 70.2% 0+0k 0+0io 0pf+0w
      node023 534.289u 4.338s 13:02.73 68.8% 0+0k 0+0io 0pf+0w
      node023 521.415u 4.169s 12:43.63 68.8% 0+0k 0+0io 0pf+0w
      node023 524.053u 4.421s 13:36.12 64.7% 0+0k 0+0io 0pf+0w
      node023 528.244u 5.281s 13:13.38 67.2% 0+0k 0+0io 0pf+0w
      node023 517.884u 5.141s 12:42.64 68.5% 0+0k 0+0io 0pf+0w
      node023 519.022u 4.361s 12:23.54 70.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4196.42	 wallclock=6171.68
4196.553u 39.250s 13:45.19 513.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 06:34:27 ) 503.97user 8.43system 2:10.27elapsed 393%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 06:36:37 ) 51045.11user 84.30system 1:56:15elapsed 732%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 08:32:53 ) 9154.38user 9.50system 20:06.18elapsed 759%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 08:52:59 ) 0.129u 0.012s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 08:52:59 ) 0.342u 0.116s 0:00.46 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000866040005349
:CHARGE convergence:  0.0010164
>lapw0      ( 08:53:00 ) starting parallel lapw0 at Thu Feb  6 08:53:00 CST 2014
-------- .machine0 : 8 processors
10.221u 0.401s 0:03.52 301.7%	0+0k 0+0io 85pf+0w
>lapw1      ( 08:53:03 ) starting parallel lapw1 at Thu Feb  6 08:53:03 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 08:53:04 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 19297
[2] 19317
[3] 19336
[4] 19355
[5] 19374
[6] 19393
[7] 19413
[8] 19432
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 520.069u 3.339s 8:43.97 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 522.081u 3.082s 8:45.95 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 521.920u 2.876s 8:44.91 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 527.450u 2.947s 8:51.85 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 525.139u 2.962s 8:49.00 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 527.548u 2.996s 8:51.90 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 517.783u 3.102s 8:43.23 99.5%	0+0k 0+0io 0pf+0w
     node023(34) 521.755u 2.941s 8:45.28 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4183.74	 wallclock=4216.09
4184.051u 25.049s 8:58.23 782.0%	0+0k 0+0io 0pf+0w
>lapwso     ( 09:02:02 ) running LAPWSO in parallel mode
[1] 20299
[2] 20305
[3] 20311
[4] 20317
[5] 20323
[6] 20330
[7] 20336
[8] 20342
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 526.226u 4.476s 12:54.89 68.4% 0+0k 0+0io 0pf+0w
      node023 536.413u 4.331s 13:22.20 67.4% 0+0k 0+0io 0pf+0w
      node023 544.768u 4.230s 13:40.24 66.9% 0+0k 0+0io 0pf+0w
      node023 531.961u 4.247s 13:13.02 67.6% 0+0k 0+0io 0pf+0w
      node023 538.848u 4.481s 13:55.21 65.0% 0+0k 0+0io 0pf+0w
      node023 538.169u 5.331s 13:54.19 65.1% 0+0k 0+0io 0pf+0w
      node023 531.969u 5.298s 13:35.95 65.8% 0+0k 0+0io 0pf+0w
      node023 544.625u 4.205s 13:29.65 67.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4292.98	 wallclock=6485.35
4293.114u 39.529s 14:06.49 511.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 09:16:09 ) 499.33user 8.21system 1:32.82elapsed 546%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 09:17:42 ) 51066.43user 96.64system 1:58:58elapsed 716%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 11:16:42 ) 9175.53user 9.75system 19:20.92elapsed 791%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 11:36:03 ) 0.131u 0.011s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 11:36:04 ) 0.341u 0.126s 0:00.47 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000344939995557
:CHARGE convergence:  0.0009595
>lapw0      ( 11:36:04 ) starting parallel lapw0 at Thu Feb  6 11:36:04 CST 2014
-------- .machine0 : 8 processors
10.179u 0.391s 0:03.51 300.8%	0+0k 0+0io 84pf+0w
>lapw1      ( 11:36:08 ) starting parallel lapw1 at Thu Feb  6 11:36:08 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 11:36:08 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 22576
[2] 22595
[3] 22614
[4] 22633
[5] 22653
[6] 22672
[7] 22691
[8] 22710
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 519.858u 3.070s 8:43.01 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 539.252u 2.794s 9:03.01 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 540.082u 2.771s 9:05.17 99.5%	0+0k 0+0io 0pf+0w
     node023(34) 526.438u 3.073s 8:50.07 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 536.759u 2.942s 9:00.42 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 519.166u 3.035s 8:42.98 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 529.910u 3.187s 8:54.24 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 527.481u 2.895s 8:50.65 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4238.95	 wallclock=4269.55
4239.248u 24.564s 9:08.45 777.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 11:45:16 ) running LAPWSO in parallel mode
[1] 23567
[2] 23574
[3] 23580
[4] 23586
[5] 23592
[6] 23598
[7] 23605
[8] 23611
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 530.770u 4.415s 10:03.56 88.6% 0+0k 0+0io 0pf+0w
      node023 563.329u 4.452s 10:42.81 88.3% 0+0k 0+0io 0pf+0w
      node023 550.674u 4.444s 10:20.69 89.4% 0+0k 0+0io 0pf+0w
      node023 536.848u 4.518s 10:06.41 89.2% 0+0k 0+0io 0pf+0w
      node023 571.382u 4.183s 10:48.75 88.7% 0+0k 0+0io 0pf+0w
      node023 550.616u 5.141s 10:36.70 87.2% 0+0k 0+0io 0pf+0w
      node023 561.609u 5.467s 10:42.74 88.2% 0+0k 0+0io 0pf+0w
      node023 543.137u 3.987s 10:27.61 87.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4408.36	 wallclock=5029.27
4408.492u 39.518s 10:55.71 678.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 11:56:12 ) 504.45user 8.00system 1:23.42elapsed 614%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 11:57:36 ) 52717.52user 86.65system 2:02:13elapsed 719%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 13:59:52 ) 9177.20user 10.49system 19:16.51elapsed 794%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 14:19:08 ) 0.130u 0.009s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 14:19:09 ) 0.350u 0.116s 0:00.47 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  9.53399576247e-05
:CHARGE convergence:  0.0001411
>lapw0      ( 14:19:09 ) starting parallel lapw0 at Thu Feb  6 14:19:09 CST 2014
-------- .machine0 : 8 processors
10.340u 0.418s 0:03.88 277.0%	0+0k 0+0io 84pf+0w
>lapw1      ( 14:19:13 ) starting parallel lapw1 at Thu Feb  6 14:19:13 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 14:19:13 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 25892
[2] 25911
[3] 25930
[4] 25949
[5] 25969
[6] 25988
[7] 26007
[8] 26026
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 533.999u 2.948s 8:57.05 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 535.850u 2.981s 8:58.92 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 527.034u 2.881s 8:50.52 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 537.214u 3.237s 9:01.10 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 532.021u 2.803s 8:56.82 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 534.145u 2.943s 8:59.64 99.5%	0+0k 0+0io 0pf+0w
     node023(34) 535.260u 2.896s 9:00.14 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 528.179u 2.863s 8:52.48 99.7%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4263.7	 wallclock=4296.67
4264.023u 24.369s 9:07.50 783.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 14:28:21 ) running LAPWSO in parallel mode
[1] 26904
[2] 26910
[3] 26916
[4] 26922
[5] 26929
[6] 26935
[7] 26941
[8] 26947
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 569.656u 4.313s 11:13.63 85.2% 0+0k 0+0io 0pf+0w
      node023 552.188u 4.466s 10:49.70 85.6% 0+0k 0+0io 0pf+0w
      node023 547.758u 4.146s 11:02.63 83.2% 0+0k 0+0io 0pf+0w
      node023 548.437u 4.439s 10:48.08 85.3% 0+0k 0+0io 0pf+0w
      node023 553.945u 4.599s 11:21.24 81.9% 0+0k 0+0io 0pf+0w
      node023 568.571u 5.484s 11:22.25 84.1% 0+0k 0+0io 0pf+0w
      node023 553.897u 5.268s 10:44.66 86.7% 0+0k 0+0io 0pf+0w
      node023 570.462u 4.267s 11:05.15 86.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4464.91	 wallclock=5307.34
4465.034u 39.929s 11:36.19 647.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 14:39:58 ) 502.38user 7.97system 1:30.72elapsed 562%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 14:41:29 ) 49132.73user 89.36system 1:53:46elapsed 721%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 16:35:17 ) 9178.21user 9.99system 19:18.22elapsed 793%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 16:54:36 ) 0.130u 0.010s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 16:54:36 ) 0.361u 0.107s 0:00.47 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.79300147668e-05
:CHARGE convergence:  0.0002676
>lapw0      ( 16:54:37 ) starting parallel lapw0 at Thu Feb  6 16:54:37 CST 2014
-------- .machine0 : 8 processors
10.312u 0.420s 0:03.54 303.1%	0+0k 0+0io 85pf+0w
>lapw1      ( 16:54:40 ) starting parallel lapw1 at Thu Feb  6 16:54:40 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 16:54:40 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 29114
[2] 29133
[3] 29152
[4] 29171
[5] 29190
[6] 29210
[7] 29229
[8] 29248
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 537.419u 2.841s 9:00.78 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 528.491u 2.927s 8:52.31 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 539.116u 2.720s 9:02.18 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 535.346u 2.788s 8:58.64 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 535.465u 2.902s 8:59.90 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 534.384u 3.515s 8:59.08 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 524.647u 3.007s 8:47.76 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 523.058u 2.957s 8:46.16 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4257.93	 wallclock=4286.81
4258.248u 24.470s 9:05.47 785.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 17:03:46 ) running LAPWSO in parallel mode
[1] 30144
[2] 30151
[3] 30157
[4] 30163
[5] 30169
[6] 30176
[7] 30182
[8] 30188
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 552.660u 4.301s 9:55.15 93.5% 0+0k 0+0io 0pf+0w
      node023 562.402u 4.213s 9:49.32 96.1% 0+0k 0+0io 0pf+0w
      node023 578.831u 4.552s 10:12.26 95.2% 0+0k 0+0io 0pf+0w
      node023 562.224u 4.154s 9:54.71 95.2% 0+0k 0+0io 0pf+0w
      node023 580.464u 4.125s 10:10.28 95.7% 0+0k 0+0io 0pf+0w
      node023 561.348u 5.050s 9:56.92 94.8% 0+0k 0+0io 0pf+0w
      node023 584.017u 5.522s 10:17.46 95.4% 0+0k 0+0io 0pf+0w
      node023 560.426u 4.507s 9:50.68 95.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4542.37	 wallclock=4806.78
4542.489u 39.364s 10:26.46 731.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 17:14:13 ) 498.79user 7.92system 1:25.34elapsed 593%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 17:15:38 ) 55281.04user 86.01system 2:09:04elapsed 714%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 19:24:43 ) 9181.48user 9.93system 19:16.39elapsed 794%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 19:43:59 ) 0.133u 0.009s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 19:43:59 ) 0.358u 0.107s 0:00.46 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000186049961485
:CHARGE convergence:  0.0003943
>lapw0      ( 19:44:00 ) starting parallel lapw0 at Thu Feb  6 19:44:00 CST 2014
-------- .machine0 : 8 processors
10.255u 0.443s 0:03.53 302.8%	0+0k 0+0io 83pf+0w
>lapw1      ( 19:44:04 ) starting parallel lapw1 at Thu Feb  6 19:44:04 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 19:44:04 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 32577
[2] 32596
[3] 32615
[4] 32634
[5] 32654
[6] 32673
[7] 32692
[8] 32711
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 523.979u 3.089s 8:47.65 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 537.047u 2.753s 9:00.48 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 540.871u 2.777s 9:05.38 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 531.252u 2.875s 8:54.50 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 533.738u 3.326s 8:57.99 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 538.756u 2.812s 9:02.18 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 535.770u 3.165s 8:59.76 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 534.138u 2.897s 8:57.09 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4275.55	 wallclock=4305.03
4275.867u 24.516s 9:09.43 782.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 19:53:13 ) running LAPWSO in parallel mode
[1] 1169
[2] 1176
[3] 1182
[4] 1188
[5] 1194
[6] 1200
[7] 1207
[8] 1213
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 553.667u 4.185s 9:52.90 94.0% 0+0k 0+0io 0pf+0w
      node023 563.462u 4.366s 10:08.43 93.3% 0+0k 0+0io 0pf+0w
      node023 545.328u 4.607s 9:32.95 95.9% 0+0k 0+0io 0pf+0w
      node023 565.057u 4.336s 9:49.53 96.5% 0+0k 0+0io 0pf+0w
      node023 557.593u 4.670s 10:04.95 92.9% 0+0k 0+0io 0pf+0w
      node023 581.311u 5.076s 10:41.20 91.4% 0+0k 0+0io 0pf+0w
      node023 587.545u 4.990s 10:33.28 93.5% 0+0k 0+0io 0pf+0w
      node023 556.911u 4.597s 10:00.04 93.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4510.87	 wallclock=4843.28
4510.999u 39.799s 10:49.23 700.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 20:04:02 ) 501.78user 7.94system 3:16.81elapsed 258%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 20:07:19 ) 55442.72user 95.43system 2:09:07elapsed 716%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 22:16:27 ) 9183.03user 9.89system 19:20.99elapsed 791%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 22:35:48 ) 0.132u 0.009s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 22:36:09 ) 0.356u 0.113s 0:00.47 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  6.51699956506e-05
:CHARGE convergence:  0.0001645
>lapw0      ( 22:36:10 ) starting parallel lapw0 at Thu Feb  6 22:36:19 CST 2014
-------- .machine0 : 8 processors
10.226u 0.406s 0:03.51 302.5%	0+0k 0+0io 84pf+0w
>lapw1      ( 22:36:22 ) starting parallel lapw1 at Thu Feb  6 22:36:22 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 22:36:23 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 3685
[2] 3705
[3] 3725
[4] 3744
[5] 3763
[6] 3783
[7] 3804
[8] 3823
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 525.822u 3.027s 8:50.76 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 538.074u 3.678s 9:02.13 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 529.766u 2.809s 8:52.72 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 540.067u 2.777s 9:03.40 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 537.039u 2.762s 8:59.92 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 535.981u 2.750s 8:59.83 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 526.014u 2.977s 8:49.65 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 523.199u 2.884s 8:46.85 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4255.96	 wallclock=4285.26
4256.269u 24.473s 9:07.69 781.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:45:30 ) running LAPWSO in parallel mode
[1] 4724
[2] 4730
[3] 4737
[4] 4743
[5] 4749
[6] 4755
[7] 4761
[8] 4768
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 548.323u 4.138s 9:49.10 93.7% 0+0k 0+0io 0pf+0w
      node023 586.619u 4.299s 10:26.53 94.3% 0+0k 0+0io 0pf+0w
      node023 546.610u 4.241s 9:57.67 92.1% 0+0k 0+0io 0pf+0w
      node023 564.997u 4.210s 10:03.96 94.2% 0+0k 0+0io 0pf+0w
      node023 560.131u 4.482s 10:04.14 93.4% 0+0k 0+0io 0pf+0w
      node023 570.646u 5.297s 10:24.00 92.2% 0+0k 0+0io 0pf+0w
      node023 563.163u 5.086s 10:15.03 92.3% 0+0k 0+0io 0pf+0w
      node023 562.793u 4.179s 10:14.63 92.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4503.28	 wallclock=4875.06
4503.405u 38.939s 10:32.07 718.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:56:05 ) 500.37user 8.13system 2:04.63elapsed 407%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:58:10 ) 45453.10user 76.23system 1:44:27elapsed 726%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:42:37 ) 9153.20user 9.93system 19:20.47elapsed 789%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:01:58 ) 0.131u 0.012s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 01:01:58 ) 0.345u 0.124s 0:00.47 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  3.71000496671e-05
:CHARGE convergence:  0.0001232
>lapw0      ( 01:01:59 ) starting parallel lapw0 at Fri Feb  7 01:02:02 CST 2014
-------- .machine0 : 8 processors
10.425u 0.422s 0:03.55 305.3%	0+0k 0+0io 83pf+0w
>lapw1      ( 01:02:05 ) starting parallel lapw1 at Fri Feb  7 01:02:05 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 01:02:05 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 6863
[2] 6882
[3] 6901
[4] 6920
[5] 6940
[6] 6959
[7] 6978
[8] 6997
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 530.745u 2.942s 8:54.63 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 545.978u 2.717s 9:08.76 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 544.118u 3.365s 9:08.08 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 542.341u 2.892s 9:05.37 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 540.049u 2.820s 9:03.36 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 540.371u 2.955s 9:06.15 99.4%	0+0k 0+0io 0pf+0w
     node023(34) 541.850u 2.959s 9:05.63 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 537.659u 2.890s 9:00.85 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4323.11	 wallclock=4352.83
4323.423u 24.370s 9:15.41 782.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:11:21 ) running LAPWSO in parallel mode
[1] 7884
[2] 7890
[3] 7896
[4] 7903
[5] 7909
[6] 7915
[7] 7921
[8] 7927
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 539.083u 4.218s 9:33.76 94.6% 0+0k 0+0io 0pf+0w
      node023 557.932u 4.337s 10:03.77 93.1% 0+0k 0+0io 0pf+0w
      node023 564.450u 4.154s 10:07.49 93.5% 0+0k 0+0io 0pf+0w
      node023 573.395u 4.289s 10:01.30 96.0% 0+0k 0+0io 0pf+0w
      node023 576.288u 4.439s 10:09.24 95.3% 0+0k 0+0io 0pf+0w
      node023 585.574u 5.256s 10:02.59 98.0% 0+0k 0+0io 0pf+0w
      node023 548.943u 5.004s 9:48.18 94.1% 0+0k 0+0io 0pf+0w
      node023 567.642u 4.506s 10:03.68 94.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4513.31	 wallclock=4790.01
4513.441u 39.132s 10:16.23 738.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:21:37 ) 503.93user 8.23system 1:31.47elapsed 559%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:23:09 ) 54649.52user 87.50system 2:06:10elapsed 722%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:29:22 ) 9705.57user 9.53system 20:23.39elapsed 794%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:49:45 ) 0.133u 0.008s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 03:49:45 ) 0.350u 0.124s 0:00.47 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000103230006061
:CHARGE convergence:  0.0003526
>lapw0      ( 03:49:46 ) starting parallel lapw0 at Fri Feb  7 03:49:46 CST 2014
-------- .machine0 : 8 processors
10.462u 0.404s 0:03.55 305.9%	0+0k 0+0io 84pf+0w
>lapw1      ( 03:49:49 ) starting parallel lapw1 at Fri Feb  7 03:49:50 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 03:49:50 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 10278
[2] 10297
[3] 10316
[4] 10335
[5] 10355
[6] 10374
[7] 10393
[8] 10412
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 526.605u 3.064s 8:51.78 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 539.982u 2.797s 9:03.22 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 535.500u 2.869s 8:59.18 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 534.466u 3.254s 8:58.55 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 539.996u 2.893s 9:05.14 99.5%	0+0k 0+0io 0pf+0w
     node023(34) 528.820u 2.894s 8:51.88 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 533.138u 3.156s 8:58.28 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 534.764u 2.924s 8:59.39 99.6%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4273.27	 wallclock=4307.42
4273.600u 24.644s 9:10.45 780.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:59:00 ) running LAPWSO in parallel mode
[1] 11293
[2] 11299
[3] 11306
[4] 11312
[5] 11318
[6] 11324
[7] 11330
[8] 11337
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 530.924u 4.098s 11:09.73 79.8% 0+0k 0+0io 0pf+0w
      node023 531.435u 4.516s 10:56.24 81.6% 0+0k 0+0io 0pf+0w
      node023 527.909u 4.506s 11:30.69 77.0% 0+0k 0+0io 0pf+0w
      node023 538.950u 4.111s 11:10.98 80.9% 0+0k 0+0io 0pf+0w
      node023 534.796u 4.269s 11:20.33 79.2% 0+0k 0+0io 0pf+0w
      node023 529.635u 5.175s 11:25.06 78.0% 0+0k 0+0io 0pf+0w
      node023 532.660u 4.981s 11:14.18 79.7% 0+0k 0+0io 0pf+0w
      node023 535.962u 4.036s 11:23.99 78.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4262.27	 wallclock=5411.2
4262.376u 38.690s 11:36.50 617.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:10:37 ) 503.24user 7.94system 1:46.82elapsed 478%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:12:23 ) 49402.25user 89.07system 1:50:39elapsed 745%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:03:04 ) 9152.26user 9.84system 19:21.33elapsed 788%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:22:25 ) 0.128u 0.014s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 06:22:25 ) 0.355u 0.117s 0:00.47 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  5.284009967e-05
:CHARGE convergence:  0.0001306
>lapw0      ( 06:22:26 ) starting parallel lapw0 at Fri Feb  7 06:22:27 CST 2014
-------- .machine0 : 8 processors
10.453u 0.452s 0:08.21 132.7%	0+0k 0+0io 83pf+0w
>lapw1      ( 06:22:35 ) starting parallel lapw1 at Fri Feb  7 06:22:35 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 06:22:35 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 13933
[2] 13952
[3] 13971
[4] 13991
[5] 14010
[6] 14029
[7] 14048
[8] 14067
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 525.827u 2.763s 8:49.12 99.8%	0+0k 0+0io 0pf+0w
     node023(34) 536.494u 2.984s 8:59.84 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 535.582u 2.786s 9:06.66 98.4%	0+0k 0+0io 0pf+0w
     node023(34) 536.521u 2.892s 9:01.05 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 532.442u 2.906s 8:59.10 99.3%	0+0k 0+0io 0pf+0w
     node023(34) 530.500u 2.980s 8:58.05 99.1%	0+0k 0+0io 0pf+0w
     node023(34) 520.224u 3.565s 8:46.09 99.5%	0+0k 0+0io 0pf+0w
     node023(34) 532.260u 2.831s 8:59.03 99.2%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4249.85	 wallclock=4298.94
4250.156u 24.513s 9:10.71 776.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 06:31:45 ) running LAPWSO in parallel mode
[1] 14937
[2] 14943
[3] 14949
[4] 14955
[5] 14962
[6] 14968
[7] 14974
[8] 14980
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 536.852u 4.099s 11:51.84 75.9% 0+0k 0+0io 0pf+0w
      node023 551.555u 4.467s 12:05.06 76.6% 0+0k 0+0io 0pf+0w
      node023 534.856u 4.342s 12:05.39 74.3% 0+0k 0+0io 0pf+0w
      node023 556.457u 4.251s 12:29.94 74.7% 0+0k 0+0io 0pf+0w
      node023 539.823u 4.358s 11:46.93 76.9% 0+0k 0+0io 0pf+0w
      node023 560.894u 5.556s 12:51.95 73.3% 0+0k 0+0io 0pf+0w
      node023 555.729u 5.257s 12:31.67 74.6% 0+0k 0+0io 0pf+0w
      node023 567.607u 4.485s 12:15.52 77.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4403.77	 wallclock=5878.3
4403.912u 39.717s 12:59.93 569.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 06:44:45 ) 501.39user 8.23system 1:35.78elapsed 532%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 06:46:21 ) 43225.48user 82.88system 1:36:11elapsed 750%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 08:22:33 ) 9170.52user 9.90system 19:22.67elapsed 789%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 08:41:56 ) 0.135u 0.009s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 08:41:59 ) 0.353u 0.119s 0:00.47 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.4130102247e-05
:CHARGE convergence:  7.53e-05
>lapw0      ( 08:42:00 ) starting parallel lapw0 at Fri Feb  7 08:42:00 CST 2014
-------- .machine0 : 8 processors
10.406u 0.407s 0:03.54 305.0%	0+0k 0+0io 86pf+0w
>lapw1      ( 08:42:03 ) starting parallel lapw1 at Fri Feb  7 08:42:03 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 08:42:03 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 16951
[2] 16970
[3] 16989
[4] 17008
[5] 17028
[6] 17047
[7] 17066
[8] 17085
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node023(34) 521.304u 2.990s 8:46.52 99.5%	0+0k 0+0io 0pf+0w
     node023(34) 526.349u 3.404s 8:51.41 99.6%	0+0k 0+0io 0pf+0w
     node023(34) 537.948u 2.751s 9:01.06 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 534.630u 2.768s 8:57.56 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 532.534u 2.871s 8:56.78 99.7%	0+0k 0+0io 0pf+0w
     node023(34) 536.307u 2.713s 8:59.37 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 523.228u 2.940s 8:46.26 99.9%	0+0k 0+0io 0pf+0w
     node023(34) 532.177u 3.180s 8:56.31 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node023	 k=272	 user=4244.48	 wallclock=4275.27
4244.783u 24.435s 9:06.49 781.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 08:51:10 ) running LAPWSO in parallel mode
[1] 17961
[2] 17967
[3] 17973
[4] 17979
[5] 17985
[6] 17992
[7] 17998
[8] 18004
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node023 526.398u 4.090s 12:40.90 69.7% 0+0k 0+0io 0pf+0w
      node023 532.900u 4.276s 12:56.89 69.1% 0+0k 0+0io 0pf+0w
      node023 544.492u 4.413s 12:57.15 70.6% 0+0k 0+0io 0pf+0w
      node023 552.653u 4.276s 12:48.26 72.4% 0+0k 0+0io 0pf+0w
      node023 541.040u 4.209s 12:55.18 70.3% 0+0k 0+0io 0pf+0w
      node023 537.917u 5.356s 13:23.21 67.6% 0+0k 0+0io 0pf+0w
      node023 540.618u 5.329s 12:45.21 71.3% 0+0k 0+0io 0pf+0w
      node023 543.990u 4.212s 12:43.29 71.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node023	 user=4320.01	 wallclock=6190.09
4320.131u 39.127s 13:31.81 536.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 09:04:42 ) 498.14user 8.42system 2:21.16elapsed 358%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 09:07:03 ) 49953.88user 85.75system 1:54:51elapsed 726%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 11:01:56 ) 9165.89user 10.13system 19:17.35elapsed 792%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 11:21:13 ) 0.133u 0.012s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 11:23:13 ) 0.363u 0.107s 0:00.47 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  4.09898348153e-07
:CHARGE convergence:  0.0002301
