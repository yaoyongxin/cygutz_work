Calculating alpha_Pu_6 in /scratch/ykent33901/alpha_Pu_6
on node013 with PID 16712




   start        Wed Feb  5 07:36:16 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Feb  5 07:36:16 2014 1000/0 to go

>lapw0      ( 07:36:16 ) starting parallel lapw0 at Wed Feb  5 07:36:16 CST 2014
-------- .machine0 : 8 processors
11.996u 0.399s 0:04.21 294.0%	0+0k 0+0io 87pf+0w
>lapw1      ( 07:36:21 ) starting parallel lapw1 at Wed Feb  5 07:37:06 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 07:37:06 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 16943
[2] 16962
[3] 16982
[4] 17001
[5] 17020
[6] 17039
[7] 17058
[8] 17078
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1040.761u 4.271s 17:27.35 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1048.489u 3.339s 17:33.05 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1036.362u 3.438s 17:20.40 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1035.908u 3.413s 17:23.56 99.5%	0+0k 0+0io 0pf+0w
     node013(34) 1044.007u 3.321s 17:27.54 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1017.225u 3.593s 17:01.08 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1029.896u 2.913s 17:13.55 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1036.279u 3.030s 17:20.22 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8288.93	 wallclock=8326.75
8289.401u 28.594s 17:35.31 788.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 07:54:41 ) running LAPWSO in parallel mode
[1] 18565
[2] 18571
[3] 18577
[4] 18584
[5] 18590
[6] 18596
[7] 18602
[8] 18608
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1033.763u 8.745s 17:45.28 97.8% 0+0k 0+0io 0pf+0w
      node013 1019.706u 7.779s 17:25.41 98.2% 0+0k 0+0io 3pf+0w
      node013 1040.014u 8.123s 17:57.17 97.3% 0+0k 0+0io 0pf+0w
      node013 1071.616u 8.054s 18:35.06 96.8% 0+0k 0+0io 0pf+0w
      node013 1074.076u 8.965s 18:18.73 98.5% 0+0k 0+0io 0pf+0w
      node013 1055.027u 7.926s 18:18.95 96.7% 0+0k 0+0io 0pf+0w
      node013 1047.567u 7.775s 18:00.03 97.7% 0+0k 0+0io 0pf+0w
      node013 1065.317u 9.016s 18:19.22 97.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8407.09	 wallclock=8679.85
8407.221u 66.653s 18:38.67 757.4%	0+0k 0+0io 22pf+0w
>dmft1      ( 08:13:20 ) 653.10user 13.22system 6:53.44elapsed 161%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 08:20:13 ) 65802.09user 113.38system 2:29:59elapsed 732%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 10:50:13 ) 12197.69user 15.63system 27:17.59elapsed 745%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 11:17:30 ) 0.136u 0.012s 0:00.21 66.6%	0+0k 0+0io 1pf+0w
>mixer      ( 11:17:31 ) 0.315u 0.110s 0:00.59 71.1%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0230574
>lapw0      ( 11:17:32 ) starting parallel lapw0 at Wed Feb  5 11:17:32 CST 2014
-------- .machine0 : 8 processors
12.026u 0.442s 0:03.94 316.2%	0+0k 0+0io 110pf+0w
>lapw1      ( 11:17:36 ) starting parallel lapw1 at Wed Feb  5 11:17:36 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 11:17:36 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 21515
[2] 21535
[3] 21554
[4] 21573
[5] 21592
[6] 21612
[7] 21631
[8] 21650
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1044.408u 3.875s 17:29.29 99.9%	0+0k 0+0io 1pf+0w
     node013(34) 1039.499u 3.726s 17:23.46 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1043.519u 3.622s 17:30.24 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1039.481u 3.486s 17:24.54 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1042.636u 4.121s 17:28.50 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1037.691u 3.578s 17:21.40 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1037.190u 3.060s 17:20.62 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1039.039u 3.142s 17:23.85 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8323.46	 wallclock=8361.9
8323.951u 29.899s 17:34.41 792.2%	0+0k 0+0io 18pf+0w
>lapwso     ( 11:35:10 ) running LAPWSO in parallel mode
[1] 23143
[2] 23149
[3] 23155
[4] 23161
[5] 23168
[6] 23174
[7] 23180
[8] 23186
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1040.196u 7.670s 17:31.14 99.6% 0+0k 0+0io 1pf+0w
      node013 1040.153u 8.648s 17:40.68 98.8% 0+0k 0+0io 0pf+0w
      node013 1087.268u 8.208s 18:28.18 98.8% 0+0k 0+0io 0pf+0w
      node013 1061.640u 7.682s 18:03.65 98.6% 0+0k 0+0io 0pf+0w
      node013 1031.378u 7.580s 17:19.45 99.9% 0+0k 0+0io 0pf+0w
      node013 1049.914u 7.713s 17:47.13 99.1% 0+0k 0+0io 0pf+0w
      node013 1068.679u 7.888s 18:07.66 98.9% 0+0k 0+0io 0pf+0w
      node013 1087.925u 8.764s 18:23.26 99.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8467.15	 wallclock=8601.15
8467.280u 67.776s 18:38.28 763.2%	0+0k 0+0io 1pf+0w
>dmft1      ( 11:53:48 ) 705.47user 10.51system 1:47.97elapsed 663%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 11:55:36 ) 52762.63user 82.80system 2:01:21elapsed 725%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 13:56:58 ) 12011.66user 13.53system 26:43.81elapsed 749%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 14:23:42 ) 0.137u 0.012s 0:00.36 38.8%	0+0k 0+0io 1pf+0w
>mixer      ( 14:23:42 ) 0.335u 0.126s 0:00.83 54.2%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.000561829889193
:CHARGE convergence:  0.0228526
>lapw0      ( 14:23:43 ) starting parallel lapw0 at Wed Feb  5 14:23:43 CST 2014
-------- .machine0 : 8 processors
16.041u 0.515s 0:04.60 359.7%	0+0k 0+0io 111pf+0w
>lapw1      ( 14:23:48 ) starting parallel lapw1 at Wed Feb  5 14:23:48 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 14:23:49 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 25686
[2] 25705
[3] 25724
[4] 25744
[5] 25763
[6] 25782
[7] 25801
[8] 25821
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1047.864u 3.654s 17:35.79 99.5%	0+0k 0+0io 1pf+0w
     node013(34) 1037.845u 3.641s 17:23.33 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1021.331u 4.103s 17:08.01 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1045.180u 3.532s 17:29.75 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1046.730u 3.607s 17:32.53 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1039.914u 3.905s 17:25.99 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1037.127u 3.010s 17:22.26 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1042.783u 3.349s 17:27.80 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8318.77	 wallclock=8365.46
8319.259u 30.078s 17:39.42 788.1%	0+0k 0+0io 18pf+0w
>lapwso     ( 14:41:27 ) running LAPWSO in parallel mode
[1] 27307
[2] 27313
[3] 27319
[4] 27326
[5] 27332
[6] 27338
[7] 27344
[8] 27350
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1040.458u 7.163s 17:28.40 99.9% 0+0k 0+0io 1pf+0w
      node013 1027.134u 8.173s 17:23.89 99.1% 0+0k 0+0io 0pf+0w
      node013 1047.613u 8.339s 17:41.20 99.5% 0+0k 0+0io 0pf+0w
      node013 997.547u 7.247s 16:48.23 99.6% 0+0k 0+0io 0pf+0w
      node013 1047.967u 9.231s 17:51.49 98.6% 0+0k 0+0io 0pf+0w
      node013 1042.210u 8.018s 17:34.46 99.5% 0+0k 0+0io 0pf+0w
      node013 1041.111u 7.972s 17:36.48 99.2% 0+0k 0+0io 0pf+0w
      node013 1039.912u 8.188s 17:41.29 98.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8283.95	 wallclock=8405.44
8284.076u 68.674s 18:01.38 772.4%	0+0k 0+0io 1pf+0w
>dmft1      ( 14:59:29 ) 708.62user 10.48system 1:34.23elapsed 763%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 15:01:03 ) 55913.48user 82.00system 2:10:08elapsed 717%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 17:11:12 ) 12086.22user 12.50system 25:33.80elapsed 788%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 17:36:46 ) 0.146u 0.017s 0:00.33 45.4%	0+0k 0+0io 1pf+0w
>mixer      ( 17:36:46 ) 0.337u 0.112s 0:00.63 69.8%	0+0k 0+0io 2pf+0w
:ENERGY convergence:  0.00363555003423
:CHARGE convergence:  0.014598
>lapw0      ( 17:36:47 ) starting parallel lapw0 at Wed Feb  5 17:36:47 CST 2014
-------- .machine0 : 8 processors
13.311u 0.438s 0:04.20 327.1%	0+0k 0+0io 95pf+0w
>lapw1      ( 17:36:51 ) starting parallel lapw1 at Wed Feb  5 17:36:51 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 17:36:52 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 29903
[2] 29923
[3] 29942
[4] 29961
[5] 29980
[6] 29999
[7] 30019
[8] 30038
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1047.413u 3.706s 17:32.26 99.8%	0+0k 0+0io 1pf+0w
     node013(34) 1022.857u 3.932s 17:07.76 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1025.538u 3.712s 17:10.32 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1023.162u 3.587s 17:08.09 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1042.288u 4.189s 17:29.94 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1027.336u 3.882s 17:11.80 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1049.522u 3.516s 17:34.24 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1045.074u 3.370s 17:31.04 99.7%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8283.19	 wallclock=8325.45
8283.709u 31.148s 17:41.82 783.0%	0+0k 0+0io 6pf+0w
>lapwso     ( 17:54:33 ) running LAPWSO in parallel mode
[1] 31524
[2] 31530
[3] 31536
[4] 31542
[5] 31548
[6] 31555
[7] 31561
[8] 31567
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1050.516u 8.044s 17:52.12 98.7% 0+0k 0+0io 1pf+0w
      node013 1062.178u 7.879s 17:52.54 99.7% 0+0k 0+0io 0pf+0w
      node013 1040.654u 7.778s 17:33.88 99.4% 0+0k 0+0io 0pf+0w
      node013 1049.046u 8.094s 17:53.59 98.4% 0+0k 0+0io 0pf+0w
      node013 1070.716u 8.724s 18:11.75 98.8% 0+0k 0+0io 0pf+0w
      node013 1029.889u 7.686s 17:28.73 98.9% 0+0k 0+0io 0pf+0w
      node013 1050.314u 8.346s 17:56.46 98.3% 0+0k 0+0io 0pf+0w
      node013 1076.222u 7.960s 18:12.40 99.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8429.54	 wallclock=8581.47
8429.655u 68.735s 18:23.73 769.9%	0+0k 0+0io 1pf+0w
>dmft1      ( 18:12:57 ) 705.03user 10.45system 3:33.33elapsed 335%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 18:16:30 ) 65364.60user 100.44system 2:32:42elapsed 714%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 20:49:13 ) 12081.69user 12.70system 27:04.17elapsed 744%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 21:16:17 ) 0.153u 0.013s 0:00.40 40.0%	0+0k 0+0io 1pf+0w
>mixer      ( 21:16:21 ) 0.376u 0.119s 0:01.24 38.7%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  0.00524699001107
:CHARGE convergence:  0.0039892
>lapw0      ( 21:16:22 ) starting parallel lapw0 at Wed Feb  5 21:16:22 CST 2014
-------- .machine0 : 8 processors
13.153u 0.434s 0:04.26 318.7%	0+0k 0+0io 105pf+0w
>lapw1      ( 21:16:27 ) starting parallel lapw1 at Wed Feb  5 21:16:27 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 21:16:28 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 2042
[2] 2061
[3] 2080
[4] 2099
[5] 2118
[6] 2138
[7] 2157
[8] 2176
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1029.857u 3.708s 17:14.01 99.9%	0+0k 0+0io 1pf+0w
     node013(34) 1011.071u 4.046s 17:03.23 99.2%	0+0k 0+0io 0pf+0w
     node013(34) 1013.322u 4.471s 17:12.19 98.6%	0+0k 0+0io 0pf+0w
     node013(34) 1027.280u 3.594s 17:30.48 98.1%	0+0k 0+0io 0pf+0w
     node013(34) 1027.449u 3.865s 17:29.11 98.3%	0+0k 0+0io 0pf+0w
     node013(34) 1012.833u 3.979s 17:15.96 98.1%	0+0k 0+0io 0pf+0w
     node013(34) 1005.784u 3.147s 17:04.15 98.5%	0+0k 0+0io 0pf+0w
     node013(34) 1015.934u 3.783s 17:14.21 98.5%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8143.53	 wallclock=8283.34
8144.001u 31.881s 17:36.51 773.8%	0+0k 0+0io 17pf+0w
>lapwso     ( 21:34:03 ) running LAPWSO in parallel mode
[1] 3713
[2] 3720
[3] 3726
[4] 3732
[5] 3739
[6] 3745
[7] 3751
[8] 3757
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1027.321u 7.858s 17:19.40 99.5% 0+0k 0+0io 0pf+0w
      node013 1050.632u 8.357s 17:49.87 98.9% 0+0k 0+0io 0pf+0w
      node013 1051.505u 8.156s 17:48.37 99.1% 0+0k 0+0io 0pf+0w
      node013 1059.841u 7.461s 17:55.37 99.2% 0+0k 0+0io 0pf+0w
      node013 1032.162u 7.915s 17:28.36 99.2% 0+0k 0+0io 0pf+0w
      node013 1064.958u 8.071s 18:02.26 99.1% 0+0k 0+0io 0pf+0w
      node013 1043.347u 8.033s 17:36.80 99.4% 0+0k 0+0io 0pf+0w
      node013 1090.713u 8.435s 18:30.76 98.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8420.48	 wallclock=8551.19
8420.619u 68.615s 18:43.41 755.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 21:52:49 ) 704.80user 10.34system 1:34.18elapsed 759%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 21:54:23 ) 55621.57user 91.30system 2:11:21elapsed 706%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:05:45 ) 11975.21user 12.19system 25:23.37elapsed 786%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:31:09 ) 0.167u 0.019s 0:00.60 28.3%	0+0k 0+0io 1pf+0w
>mixer      ( 00:31:10 ) 0.369u 0.134s 0:01.27 38.5%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.00372545002028
:CHARGE convergence:  0.0117239
>lapw0      ( 00:31:11 ) starting parallel lapw0 at Thu Feb  6 00:31:11 CST 2014
-------- .machine0 : 8 processors
13.341u 0.478s 0:04.40 313.8%	0+0k 0+0io 107pf+0w
>lapw1      ( 00:31:16 ) starting parallel lapw1 at Thu Feb  6 00:31:16 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 00:31:17 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 6379
[2] 6398
[3] 6418
[4] 6437
[5] 6456
[6] 6475
[7] 6494
[8] 6514
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1054.964u 3.667s 17:40.61 99.8%	0+0k 0+0io 1pf+0w
     node013(34) 1051.367u 3.865s 17:36.32 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1034.118u 4.293s 17:20.72 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1040.385u 3.972s 17:26.08 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1044.463u 3.723s 17:29.90 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1045.802u 3.735s 17:33.87 99.5%	0+0k 0+0io 0pf+0w
     node013(34) 1028.359u 3.207s 17:23.38 98.8%	0+0k 0+0io 0pf+0w
     node013(34) 1042.913u 3.368s 17:33.29 99.3%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8342.37	 wallclock=8404.17
8342.903u 31.078s 17:43.18 787.6%	0+0k 0+0io 16pf+0w
>lapwso     ( 00:48:59 ) running LAPWSO in parallel mode
[1] 7989
[2] 7995
[3] 8002
[4] 8008
[5] 8014
[6] 8020
[7] 8026
[8] 8033
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1063.410u 7.903s 17:55.82 99.5% 0+0k 0+0io 1pf+0w
      node013 1044.086u 7.634s 17:33.06 99.8% 0+0k 0+0io 0pf+0w
      node013 1060.652u 9.216s 17:59.37 99.1% 0+0k 0+0io 0pf+0w
      node013 1082.178u 7.605s 18:20.01 99.0% 0+0k 0+0io 0pf+0w
      node013 1040.129u 8.162s 17:35.44 99.3% 0+0k 0+0io 0pf+0w
      node013 1022.874u 7.450s 17:19.21 99.1% 0+0k 0+0io 0pf+0w
      node013 1069.403u 7.728s 18:10.24 98.7% 0+0k 0+0io 0pf+0w
      node013 1054.311u 8.591s 17:51.40 99.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8437.04	 wallclock=8564.55
8437.155u 68.684s 18:38.11 760.7%	0+0k 0+0io 1pf+0w
>dmft1      ( 01:07:37 ) 703.11user 10.28system 1:35.31elapsed 748%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:09:13 ) 62694.77user 88.83system 2:26:19elapsed 715%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:35:43 ) 12075.83user 12.75system 27:11.72elapsed 740%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:02:54 ) 0.170u 0.014s 0:00.55 32.7%	0+0k 0+0io 1pf+0w
>mixer      ( 04:02:56 ) 0.381u 0.141s 0:01.49 34.8%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  0.000374690047465
:CHARGE convergence:  0.0103128
>lapw0      ( 04:02:58 ) starting parallel lapw0 at Thu Feb  6 04:02:58 CST 2014
-------- .machine0 : 8 processors
12.997u 0.498s 0:04.95 272.3%	0+0k 0+0io 102pf+0w
>lapw1      ( 04:03:03 ) starting parallel lapw1 at Thu Feb  6 04:03:03 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 04:03:04 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 11176
[2] 11195
[3] 11214
[4] 11233
[5] 11253
[6] 11278
[7] 11319
[8] 11338
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1048.372u 3.586s 17:34.12 99.7%	0+0k 0+0io 1pf+0w
     node013(34) 1044.912u 3.804s 17:30.74 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1023.306u 3.814s 17:08.04 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1042.647u 3.697s 17:29.00 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1044.827u 3.700s 17:36.60 99.2%	0+0k 0+0io 0pf+0w
     node013(34) 1036.217u 4.599s 17:25.45 99.5%	0+0k 0+0io 0pf+0w
     node013(34) 1030.255u 3.137s 17:16.53 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1039.367u 3.367s 17:24.32 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8309.9	 wallclock=8364.8
8310.406u 30.940s 17:43.35 784.4%	0+0k 0+0io 12pf+0w
>lapwso     ( 04:20:46 ) running LAPWSO in parallel mode
[1] 12948
[2] 12955
[3] 12961
[4] 12967
[5] 12973
[6] 12979
[7] 12986
[8] 12992
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1031.178u 8.252s 17:25.77 99.3% 0+0k 0+0io 0pf+0w
      node013 1054.212u 7.789s 17:45.65 99.6% 0+0k 0+0io 0pf+0w
      node013 1035.223u 7.748s 17:31.82 99.1% 0+0k 0+0io 0pf+0w
      node013 1053.649u 8.050s 17:46.02 99.5% 0+0k 0+0io 0pf+0w
      node013 1054.635u 7.882s 17:50.57 99.2% 0+0k 0+0io 0pf+0w
      node013 1057.979u 7.790s 17:56.08 99.0% 0+0k 0+0io 0pf+0w
      node013 1042.217u 8.050s 17:33.99 99.6% 0+0k 0+0io 0pf+0w
      node013 1048.472u 9.109s 17:50.34 98.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8377.57	 wallclock=8500.24
8377.689u 69.027s 18:07.25 776.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:38:54 ) 703.28user 10.36system 1:35.91elapsed 744%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:40:30 ) 56685.05user 81.16system 2:13:58elapsed 706%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:54:29 ) 12008.67user 12.55system 25:27.50elapsed 786%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 07:19:57 ) 0.130u 0.018s 0:00.36 38.8%	0+0k 0+0io 1pf+0w
>mixer      ( 07:20:01 ) 0.381u 0.131s 0:01.85 27.5%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  0.00161569996271
:CHARGE convergence:  0.0056497
>lapw0      ( 07:20:02 ) starting parallel lapw0 at Thu Feb  6 07:20:03 CST 2014
-------- .machine0 : 8 processors
13.149u 0.425s 0:04.16 325.9%	0+0k 0+0io 100pf+0w
>lapw1      ( 07:20:07 ) starting parallel lapw1 at Thu Feb  6 07:20:07 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 07:20:08 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 15596
[2] 15615
[3] 15634
[4] 15654
[5] 15673
[6] 15692
[7] 15711
[8] 15730
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1043.291u 3.524s 17:32.10 99.4%	0+0k 0+0io 0pf+0w
     node013(34) 1006.860u 4.058s 16:52.37 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1043.150u 3.870s 17:29.03 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1018.282u 3.691s 17:05.11 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1043.573u 3.708s 17:27.84 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1016.334u 3.904s 17:01.85 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1035.409u 3.782s 17:21.28 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1019.503u 3.227s 17:04.37 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8226.4	 wallclock=8273.95
8226.902u 31.010s 17:34.68 782.9%	0+0k 0+0io 13pf+0w
>lapwso     ( 07:37:42 ) running LAPWSO in parallel mode
[1] 17199
[2] 17205
[3] 17211
[4] 17218
[5] 17224
[6] 17230
[7] 17236
[8] 17242
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1034.318u 8.426s 17:33.65 98.9% 0+0k 0+0io 0pf+0w
      node013 1115.856u 7.880s 18:55.72 98.9% 0+0k 0+0io 0pf+0w
      node013 1020.502u 7.572s 17:13.72 99.4% 0+0k 0+0io 0pf+0w
      node013 1108.515u 8.562s 18:48.42 98.9% 0+0k 0+0io 0pf+0w
      node013 1023.121u 7.528s 17:12.44 99.8% 0+0k 0+0io 0pf+0w
      node013 1115.757u 7.630s 18:52.36 99.2% 0+0k 0+0io 0pf+0w
      node013 1041.972u 8.050s 17:41.97 98.8% 0+0k 0+0io 0pf+0w
      node013 1031.152u 8.495s 17:33.88 98.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8491.19	 wallclock=8632.16
8491.309u 68.534s 19:03.53 748.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 07:56:49 ) 703.97user 9.95system 1:34.45elapsed 755%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 07:58:23 ) 56676.59user 80.10system 2:12:26elapsed 714%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 10:10:51 ) 12087.82user 12.52system 25:34.82elapsed 788%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 10:36:25 ) 0.161u 0.012s 0:00.34 50.0%	0+0k 0+0io 1pf+0w
>mixer      ( 10:36:26 ) 0.389u 0.147s 0:01.68 30.9%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.000737159978598
:CHARGE convergence:  0.0078209
>lapw0      ( 10:36:28 ) starting parallel lapw0 at Thu Feb  6 10:36:28 CST 2014
-------- .machine0 : 8 processors
15.112u 0.427s 0:04.37 355.3%	0+0k 0+0io 94pf+0w
>lapw1      ( 10:36:33 ) starting parallel lapw1 at Thu Feb  6 10:36:33 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 10:36:34 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 19849
[2] 19868
[3] 19887
[4] 19906
[5] 19925
[6] 19945
[7] 19964
[8] 19983
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1014.759u 4.063s 17:00.69 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1039.273u 4.123s 17:25.40 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1044.483u 3.658s 17:29.59 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1041.515u 3.670s 17:29.99 99.5%	0+0k 0+0io 0pf+0w
     node013(34) 1044.773u 4.079s 17:30.50 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1033.844u 3.683s 17:20.65 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1036.367u 3.058s 17:22.81 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1025.643u 3.241s 17:09.05 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8280.66	 wallclock=8328.68
8281.116u 30.889s 17:38.16 785.5%	0+0k 0+0io 9pf+0w
>lapwso     ( 10:54:11 ) running LAPWSO in parallel mode
[1] 21459
[2] 21465
[3] 21471
[4] 21477
[5] 21483
[6] 21490
[7] 21496
[8] 21502
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1087.936u 7.248s 18:35.44 98.1% 0+0k 0+0io 0pf+0w
      node013 1054.710u 7.908s 18:00.46 98.3% 0+0k 0+0io 0pf+0w
      node013 1075.092u 8.474s 18:27.21 97.8% 0+0k 0+0io 0pf+0w
      node013 1080.919u 9.126s 18:34.51 97.8% 0+0k 0+0io 0pf+0w
      node013 1033.033u 7.894s 17:34.59 98.7% 0+0k 0+0io 0pf+0w
      node013 1090.087u 7.515s 18:33.87 98.5% 0+0k 0+0io 0pf+0w
      node013 1082.015u 8.496s 18:34.14 97.8% 0+0k 0+0io 0pf+0w
      node013 1082.737u 8.642s 18:29.24 98.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8586.53	 wallclock=8809.46
8586.666u 69.622s 18:46.40 768.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 11:12:57 ) 703.25user 10.30system 2:22.08elapsed 502%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 11:15:19 ) 57519.95user 81.87system 2:16:13elapsed 704%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 13:31:35 ) 12176.92user 12.51system 25:55.20elapsed 783%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 13:57:30 ) 0.147u 0.019s 0:00.43 34.8%	0+0k 0+0io 1pf+0w
>mixer      ( 13:57:31 ) 0.411u 0.145s 0:01.83 30.0%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.000445869984105
:CHARGE convergence:  0.0069558
>lapw0      ( 13:57:33 ) starting parallel lapw0 at Thu Feb  6 13:57:33 CST 2014
-------- .machine0 : 8 processors
13.447u 0.440s 0:04.20 330.4%	0+0k 0+0io 91pf+0w
>lapw1      ( 13:57:37 ) starting parallel lapw1 at Thu Feb  6 13:57:37 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 13:57:39 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 24167
[2] 24186
[3] 24205
[4] 24225
[5] 24244
[6] 24263
[7] 24282
[8] 24301
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1032.829u 3.705s 17:18.24 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1048.870u 3.888s 17:34.04 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1012.417u 4.011s 16:57.79 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1037.517u 3.892s 17:22.59 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1047.926u 3.628s 17:34.95 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1018.277u 3.697s 17:03.69 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1030.497u 3.062s 17:14.89 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1040.303u 3.380s 17:28.70 99.5%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8268.64	 wallclock=8314.89
8269.099u 30.555s 17:41.56 781.8%	0+0k 0+0io 9pf+0w
>lapwso     ( 14:15:20 ) running LAPWSO in parallel mode
[1] 25786
[2] 25792
[3] 25799
[4] 25805
[5] 25811
[6] 25817
[7] 25823
[8] 25830
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1036.221u 8.105s 17:31.59 99.3% 0+0k 0+0io 0pf+0w
      node013 1100.205u 7.948s 18:38.21 99.0% 0+0k 0+0io 0pf+0w
      node013 1119.956u 7.477s 18:54.53 99.3% 0+0k 0+0io 0pf+0w
      node013 1046.682u 7.449s 17:39.12 99.5% 0+0k 0+0io 0pf+0w
      node013 1039.703u 8.180s 17:43.08 98.5% 0+0k 0+0io 0pf+0w
      node013 1073.264u 8.254s 18:17.00 98.5% 0+0k 0+0io 0pf+0w
      node013 1069.691u 8.060s 18:05.62 99.2% 0+0k 0+0io 0pf+0w
      node013 1072.644u 8.270s 18:13.53 98.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8558.37	 wallclock=8702.68
8558.490u 68.075s 19:02.21 755.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 14:34:23 ) 708.76user 10.13system 1:38.86elapsed 727%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 14:36:02 ) 64333.99user 98.97system 2:28:59elapsed 720%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 17:05:02 ) 11938.60user 12.51system 25:17.99elapsed 787%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 17:30:20 ) 0.161u 0.017s 0:00.61 27.8%	0+0k 0+0io 1pf+0w
>mixer      ( 17:30:24 ) 0.406u 0.144s 0:04.02 13.4%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.0014890700113
:CHARGE convergence:  0.0028709
>lapw0      ( 17:30:31 ) starting parallel lapw0 at Thu Feb  6 17:30:32 CST 2014
-------- .machine0 : 8 processors
12.576u 0.451s 0:06.22 209.3%	0+0k 0+0io 95pf+0w
>lapw1      ( 17:30:38 ) starting parallel lapw1 at Thu Feb  6 17:30:39 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 17:30:40 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 28662
[2] 28681
[3] 28700
[4] 28719
[5] 28739
[6] 28758
[7] 28777
[8] 28796
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1039.483u 3.851s 17:26.01 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1041.115u 4.173s 17:28.39 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1030.851u 3.630s 17:15.81 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1035.049u 3.692s 17:20.94 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1040.260u 3.648s 17:24.76 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1017.528u 3.773s 17:02.31 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1027.382u 3.215s 17:13.85 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1032.938u 3.326s 17:18.39 99.7%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8264.61	 wallclock=8310.46
8265.105u 30.528s 17:32.77 787.9%	0+0k 0+0io 6pf+0w
>lapwso     ( 17:48:11 ) running LAPWSO in parallel mode
[1] 30238
[2] 30244
[3] 30250
[4] 30256
[5] 30262
[6] 30269
[7] 30275
[8] 30281
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1038.574u 8.584s 17:33.23 99.4% 0+0k 0+0io 0pf+0w
      node013 1047.567u 8.318s 17:40.98 99.5% 0+0k 0+0io 0pf+0w
      node013 1039.272u 7.600s 17:38.19 98.9% 0+0k 0+0io 0pf+0w
      node013 1030.463u 7.662s 17:21.91 99.6% 0+0k 0+0io 0pf+0w
      node013 1052.797u 8.002s 17:53.11 98.8% 0+0k 0+0io 0pf+0w
      node013 1019.846u 7.102s 17:12.22 99.4% 0+0k 0+0io 0pf+0w
      node013 1054.240u 8.606s 17:51.09 99.2% 0+0k 0+0io 0pf+0w
      node013 1060.155u 8.086s 17:53.43 99.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8342.91	 wallclock=8464.16
8343.045u 68.301s 18:06.31 774.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 18:06:17 ) 710.89user 9.70system 1:34.20elapsed 764%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 18:07:52 ) 56965.64user 81.26system 2:13:20elapsed 713%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 20:21:20 ) 11918.99user 12.51system 25:10.61elapsed 789%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 20:46:31 ) 0.158u 0.018s 0:00.41 39.0%	0+0k 0+0io 1pf+0w
>mixer      ( 20:46:33 ) 0.413u 0.123s 0:02.05 25.8%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  0.000342839979567
:CHARGE convergence:  0.0020948
>lapw0      ( 20:46:35 ) starting parallel lapw0 at Thu Feb  6 20:46:35 CST 2014
-------- .machine0 : 8 processors
12.385u 0.471s 0:11.63 110.4%	0+0k 0+0io 93pf+0w
>lapw1      ( 20:46:47 ) starting parallel lapw1 at Thu Feb  6 20:46:48 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 20:46:50 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 404
[2] 423
[3] 453
[4] 472
[5] 491
[6] 510
[7] 529
[8] 549
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1042.415u 4.129s 17:34.51 99.2%	0+0k 0+0io 0pf+0w
     node013(34) 1042.385u 3.668s 17:30.25 99.5%	0+0k 0+0io 0pf+0w
     node013(34) 1017.704u 3.990s 17:06.67 99.5%	0+0k 0+0io 0pf+0w
     node013(34) 1044.446u 3.802s 17:29.15 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1046.494u 3.561s 17:32.39 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1041.293u 3.800s 17:26.60 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1025.762u 3.185s 17:11.68 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1032.895u 3.220s 17:19.03 99.7%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8293.39	 wallclock=8350.28
8293.884u 30.614s 17:38.78 786.2%	0+0k 0+0io 7pf+0w
>lapwso     ( 21:04:27 ) running LAPWSO in parallel mode
[1] 2058
[2] 2064
[3] 2070
[4] 2077
[5] 2083
[6] 2089
[7] 2095
[8] 2101
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1042.270u 8.314s 17:37.82 99.3% 0+0k 0+0io 0pf+0w
      node013 1073.218u 8.003s 18:14.86 98.7% 0+0k 0+0io 0pf+0w
      node013 1025.269u 7.475s 17:15.42 99.7% 0+0k 0+0io 0pf+0w
      node013 1070.333u 7.999s 18:09.02 99.0% 0+0k 0+0io 0pf+0w
      node013 1033.496u 7.684s 17:31.27 99.0% 0+0k 0+0io 0pf+0w
      node013 1054.617u 8.160s 17:59.72 98.4% 0+0k 0+0io 0pf+0w
      node013 1069.434u 7.822s 18:09.00 98.9% 0+0k 0+0io 0pf+0w
      node013 1108.614u 8.065s 18:45.74 99.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8477.25	 wallclock=8622.85
8477.382u 67.848s 19:00.66 749.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 21:23:37 ) 705.91user 10.13system 1:41.27elapsed 707%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 21:25:18 ) 56691.11user 87.08system 2:12:50elapsed 712%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 23:38:17 ) 12197.14user 12.31system 25:47.62elapsed 788%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:04:04 ) 0.172u 0.013s 0:00.38 47.3%	0+0k 0+0io 1pf+0w
>mixer      ( 00:04:05 ) 0.416u 0.141s 0:02.23 24.6%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  0.000526580028236
:CHARGE convergence:  0.0006904
>lapw0      ( 00:04:08 ) starting parallel lapw0 at Fri Feb  7 00:04:08 CST 2014
-------- .machine0 : 8 processors
13.814u 0.453s 0:04.26 334.7%	0+0k 0+0io 93pf+0w
>lapw1      ( 00:04:12 ) starting parallel lapw1 at Fri Feb  7 00:04:12 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 00:04:13 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 4837
[2] 4856
[3] 4875
[4] 4895
[5] 4914
[6] 4933
[7] 4952
[8] 4971
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1045.824u 3.737s 17:33.88 99.5%	0+0k 0+0io 0pf+0w
     node013(34) 1025.971u 3.844s 17:11.22 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1034.780u 4.127s 17:20.31 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1028.064u 3.579s 17:12.82 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1033.074u 3.656s 17:17.75 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1020.608u 4.216s 17:07.20 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1027.415u 3.451s 17:12.15 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1043.782u 3.307s 17:27.59 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8259.52	 wallclock=8302.92
8260.003u 31.206s 17:36.96 784.4%	0+0k 0+0io 5pf+0w
>lapwso     ( 00:21:49 ) running LAPWSO in parallel mode
[1] 6457
[2] 6463
[3] 6469
[4] 6476
[5] 6482
[6] 6488
[7] 6494
[8] 6500
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1024.750u 7.603s 17:14.89 99.7% 0+0k 0+0io 0pf+0w
      node013 1068.273u 8.364s 18:03.43 99.3% 0+0k 0+0io 0pf+0w
      node013 1064.127u 8.709s 18:04.19 98.9% 0+0k 0+0io 0pf+0w
      node013 1014.812u 7.450s 17:04.72 99.7% 0+0k 0+0io 0pf+0w
      node013 991.839u 8.296s 16:45.46 99.4% 0+0k 0+0io 0pf+0w
      node013 1054.509u 7.318s 17:52.39 99.0% 0+0k 0+0io 0pf+0w
      node013 1063.498u 8.422s 18:00.66 99.1% 0+0k 0+0io 0pf+0w
      node013 1024.161u 7.945s 17:24.54 98.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8305.97	 wallclock=8430.28
8306.090u 68.458s 18:12.85 766.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:40:02 ) 702.27user 10.14system 1:33.95elapsed 758%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:41:36 ) 47902.80user 72.87system 1:49:45elapsed 728%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:31:23 ) 12131.92user 12.52system 25:46.73elapsed 785%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:57:10 ) 0.155u 0.018s 0:00.61 26.2%	0+0k 0+0io 1pf+0w
>mixer      ( 02:57:12 ) 0.411u 0.146s 0:02.13 25.8%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  0.000236090039834
:CHARGE convergence:  0.0001526
>lapw0      ( 02:57:14 ) starting parallel lapw0 at Fri Feb  7 02:57:14 CST 2014
-------- .machine0 : 8 processors
12.746u 0.449s 0:04.08 323.0%	0+0k 0+0io 94pf+0w
>lapw1      ( 02:57:18 ) starting parallel lapw1 at Fri Feb  7 02:57:18 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 02:57:19 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 8816
[2] 8835
[3] 8854
[4] 8873
[5] 8892
[6] 8912
[7] 8931
[8] 8950
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1043.456u 4.162s 17:28.69 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1040.913u 3.558s 17:26.25 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1044.697u 3.551s 17:31.89 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1035.034u 3.531s 17:19.67 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1039.095u 3.770s 17:26.92 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1027.832u 3.746s 17:14.12 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1037.785u 3.043s 17:22.19 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1037.760u 3.678s 17:25.53 99.6%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8306.57	 wallclock=8355.26
8307.061u 30.261s 17:36.17 789.3%	0+0k 0+0io 5pf+0w
>lapwso     ( 03:14:57 ) running LAPWSO in parallel mode
[1] 10400
[2] 10406
[3] 10412
[4] 10418
[5] 10425
[6] 10431
[7] 10437
[8] 10443
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1072.821u 7.536s 18:09.68 99.1% 0+0k 0+0io 0pf+0w
      node013 1096.096u 7.413s 18:27.27 99.6% 0+0k 0+0io 0pf+0w
      node013 1068.848u 8.985s 18:07.07 99.1% 0+0k 0+0io 0pf+0w
      node013 1079.927u 8.285s 18:13.27 99.5% 0+0k 0+0io 0pf+0w
      node013 1093.637u 7.663s 18:27.19 99.4% 0+0k 0+0io 0pf+0w
      node013 1067.123u 7.461s 18:04.68 99.0% 0+0k 0+0io 0pf+0w
      node013 1060.419u 8.124s 17:56.94 99.2% 0+0k 0+0io 0pf+0w
      node013 1040.598u 7.895s 17:31.97 99.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8579.47	 wallclock=8698.07
8579.583u 67.742s 18:36.72 774.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:34:20 ) 704.32user 10.29system 1:33.42elapsed 764%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:35:54 ) 56041.96user 80.19system 2:11:02elapsed 713%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:46:56 ) 12289.14user 12.35system 26:00.35elapsed 788%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:12:57 ) 0.163u 0.019s 0:00.39 43.5%	0+0k 0+0io 1pf+0w
>mixer      ( 06:12:58 ) 0.422u 0.133s 0:02.30 23.9%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  2.83400295302e-05
:CHARGE convergence:  0.0004344
>lapw0      ( 06:13:00 ) starting parallel lapw0 at Fri Feb  7 06:13:00 CST 2014
-------- .machine0 : 8 processors
12.773u 0.468s 0:04.30 307.6%	0+0k 0+0io 95pf+0w
>lapw1      ( 06:13:05 ) starting parallel lapw1 at Fri Feb  7 06:13:08 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 06:13:09 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 13513
[2] 13532
[3] 13551
[4] 13570
[5] 13589
[6] 13609
[7] 13628
[8] 13647
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1016.671u 3.744s 17:02.10 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1043.431u 3.786s 17:28.79 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1048.452u 3.527s 17:34.32 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1028.870u 3.727s 17:13.89 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1028.019u 4.703s 17:17.75 99.5%	0+0k 0+0io 0pf+0w
     node013(34) 1043.913u 3.638s 17:31.13 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1039.957u 2.987s 17:27.59 99.5%	0+0k 0+0io 0pf+0w
     node013(34) 1040.441u 3.265s 17:25.49 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8289.75	 wallclock=8341.06
8290.234u 30.596s 17:38.60 786.0%	0+0k 0+0io 2pf+0w
>lapwso     ( 06:30:46 ) running LAPWSO in parallel mode
[1] 15095
[2] 15102
[3] 15108
[4] 15114
[5] 15120
[6] 15126
[7] 15133
[8] 15139
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1083.989u 7.585s 18:19.86 99.2% 0+0k 0+0io 0pf+0w
      node013 1063.600u 8.314s 17:57.91 99.4% 0+0k 0+0io 0pf+0w
      node013 1080.652u 8.364s 18:20.65 98.9% 0+0k 0+0io 0pf+0w
      node013 1083.369u 8.045s 18:20.41 99.1% 0+0k 0+0io 0pf+0w
      node013 1058.069u 7.770s 17:50.07 99.6% 0+0k 0+0io 0pf+0w
      node013 1080.752u 8.170s 18:19.49 99.0% 0+0k 0+0io 0pf+0w
      node013 1101.663u 7.405s 18:39.75 99.0% 0+0k 0+0io 0pf+0w
      node013 1067.946u 8.447s 18:06.63 99.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8620.04	 wallclock=8754.77
8620.183u 68.492s 18:51.89 767.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 06:49:38 ) 704.51user 10.18system 1:42.01elapsed 700%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 06:51:20 ) 58758.39user 88.32system 2:17:36elapsed 712%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 09:09:05 ) 12175.47user 12.26system 25:42.72elapsed 790%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 09:34:48 ) 0.163u 0.017s 0:00.50 34.0%	0+0k 0+0io 1pf+0w
>mixer      ( 09:34:49 ) 0.434u 0.141s 0:02.50 22.8%	0+0k 0+0io 9pf+0w
:ENERGY convergence:  0.000111200031824
:CHARGE convergence:  0.0001954
>lapw0      ( 09:34:52 ) starting parallel lapw0 at Fri Feb  7 09:34:52 CST 2014
-------- .machine0 : 8 processors
12.636u 0.500s 0:04.22 311.1%	0+0k 0+0io 121pf+0w
>lapw1      ( 09:34:56 ) starting parallel lapw1 at Fri Feb  7 09:34:56 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 09:34:57 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 17817
[2] 17836
[3] 17855
[4] 17875
[5] 17894
[6] 17913
[7] 17932
[8] 17951
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1029.988u 4.015s 17:17.72 99.6%	0+0k 0+0io 1pf+0w
     node013(34) 1047.539u 3.929s 17:34.90 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1036.796u 3.583s 17:24.03 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1045.237u 3.462s 17:31.07 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1047.240u 3.510s 17:32.69 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1034.943u 3.651s 17:23.11 99.5%	0+0k 0+0io 0pf+0w
     node013(34) 1041.341u 3.797s 17:27.65 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1039.573u 3.255s 17:24.03 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8322.66	 wallclock=8375.2
8323.168u 30.465s 17:39.51 788.4%	0+0k 0+0io 19pf+0w
>lapwso     ( 09:52:36 ) running LAPWSO in parallel mode
[1] 19445
[2] 19451
[3] 19457
[4] 19463
[5] 19470
[6] 19476
[7] 19482
[8] 19488
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1062.107u 7.629s 18:01.54 98.9% 0+0k 0+0io 0pf+0w
      node013 1041.054u 8.424s 17:39.35 99.0% 0+0k 0+0io 0pf+0w
      node013 1087.283u 7.384s 18:19.88 99.5% 0+0k 0+0io 0pf+0w
      node013 1094.685u 7.307s 18:28.60 99.4% 0+0k 0+0io 0pf+0w
      node013 1066.851u 8.781s 18:02.31 99.3% 0+0k 0+0io 0pf+0w
      node013 1078.014u 8.833s 18:19.55 98.8% 0+0k 0+0io 0pf+0w
      node013 1059.388u 7.929s 18:00.32 98.7% 0+0k 0+0io 0pf+0w
      node013 1088.333u 7.957s 18:23.67 99.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8577.72	 wallclock=8715.22
8577.846u 68.599s 18:37.64 773.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 10:11:13 ) 712.79user 10.37system 1:33.99elapsed 769%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 10:12:47 ) 54552.76user 85.62system 2:06:48elapsed 718%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 12:19:36 ) 12076.53user 11.84system 25:42.67elapsed 783%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 12:45:18 ) 0.159u 0.014s 0:00.49 32.6%	0+0k 0+0io 1pf+0w
>mixer      ( 12:45:19 ) 0.435u 0.130s 0:02.59 21.6%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  9.63399652392e-05
:CHARGE convergence:  3.99e-05
>lapw0      ( 12:45:22 ) starting parallel lapw0 at Fri Feb  7 12:45:22 CST 2014
-------- .machine0 : 8 processors
12.649u 0.464s 0:04.13 317.1%	0+0k 0+0io 98pf+0w
>lapw1      ( 12:45:26 ) starting parallel lapw1 at Fri Feb  7 12:45:26 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 12:45:28 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 22023
[2] 22043
[3] 22062
[4] 22081
[5] 22100
[6] 22120
[7] 22139
[8] 22158
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1054.177u 3.769s 17:38.72 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1035.121u 3.717s 17:20.15 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1032.238u 3.799s 17:19.31 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1028.679u 3.865s 17:15.08 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1041.064u 3.923s 17:27.11 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1049.424u 3.624s 17:33.74 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1047.872u 3.462s 17:33.52 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1047.236u 3.602s 17:31.65 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8335.81	 wallclock=8379.28
8336.349u 30.993s 17:42.10 787.8%	0+0k 0+0io 11pf+0w
>lapwso     ( 13:03:09 ) running LAPWSO in parallel mode
[1] 23661
[2] 23668
[3] 23674
[4] 23680
[5] 23686
[6] 23692
[7] 23699
[8] 23705
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1028.438u 7.900s 17:28.71 98.8% 0+0k 0+0io 0pf+0w
      node013 1097.940u 8.048s 18:33.06 99.3% 0+0k 0+0io 0pf+0w
      node013 1041.540u 7.615s 17:37.33 99.2% 0+0k 0+0io 0pf+0w
      node013 1060.822u 7.927s 18:02.35 98.7% 0+0k 0+0io 0pf+0w
      node013 1063.674u 8.220s 18:02.20 99.0% 0+0k 0+0io 0pf+0w
      node013 1017.969u 7.249s 17:09.72 99.5% 0+0k 0+0io 0pf+0w
      node013 1053.319u 8.594s 18:02.18 98.1% 0+0k 0+0io 0pf+0w
      node013 1061.990u 8.213s 17:57.36 99.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8425.69	 wallclock=8572.91
8425.817u 68.106s 18:40.85 757.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 13:21:50 ) 703.62user 10.04system 1:35.20elapsed 749%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 13:23:25 ) 55483.87user 85.22system 2:10:54elapsed 707%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 15:34:20 ) 11996.31user 12.17system 25:40.18elapsed 779%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 16:00:00 ) 0.166u 0.022s 0:00.38 47.3%	0+0k 0+0io 1pf+0w
>mixer      ( 16:00:01 ) 0.407u 0.158s 0:02.25 24.4%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  1.02099729702e-05
:CHARGE convergence:  0.000184
>lapw0      ( 16:04:04 ) starting parallel lapw0 at Fri Feb  7 16:04:04 CST 2014
-------- .machine0 : 8 processors
12.177u 0.433s 0:15.95 78.9%	0+0k 0+0io 92pf+0w
>lapw1      ( 16:04:20 ) starting parallel lapw1 at Fri Feb  7 16:04:20 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 16:04:21 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 26407
[2] 26426
[3] 26445
[4] 26465
[5] 26484
[6] 26503
[7] 26522
[8] 26541
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1042.372u 4.880s 17:28.00 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1049.957u 3.750s 17:34.95 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1040.293u 3.616s 17:26.12 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1047.108u 3.620s 17:34.52 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1051.596u 3.620s 17:35.88 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1038.194u 3.654s 17:24.30 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1033.191u 3.110s 17:16.83 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1045.702u 3.266s 17:30.74 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8348.41	 wallclock=8391.34
8348.898u 30.793s 17:42.86 788.4%	0+0k 0+0io 8pf+0w
>lapwso     ( 16:22:03 ) running LAPWSO in parallel mode
[1] 28041
[2] 28047
[3] 28053
[4] 28060
[5] 28066
[6] 28072
[7] 28078
[8] 28084
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1063.662u 8.854s 17:58.29 99.4% 0+0k 0+0io 0pf+0w
      node013 1063.433u 7.981s 17:55.10 99.6% 0+0k 0+0io 0pf+0w
      node013 1034.405u 7.908s 17:31.70 99.1% 0+0k 0+0io 0pf+0w
      node013 1008.306u 7.613s 16:58.86 99.7% 0+0k 0+0io 0pf+0w
      node013 1063.739u 7.857s 18:01.91 99.0% 0+0k 0+0io 0pf+0w
      node013 1056.738u 7.713s 18:00.28 98.5% 0+0k 0+0io 0pf+0w
      node013 1089.143u 7.736s 18:23.32 99.4% 0+0k 0+0io 0pf+0w
      node013 1077.538u 8.619s 18:25.08 98.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8456.96	 wallclock=8594.54
8457.093u 68.663s 18:37.59 762.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 16:40:40 ) 706.48user 9.87system 1:32.75elapsed 772%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 16:42:13 ) 56578.70user 79.71system 2:10:47elapsed 721%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 18:53:01 ) 12224.30user 12.29system 25:54.50elapsed 787%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 19:18:56 ) 0.148u 0.019s 0:00.37 40.5%	0+0k 0+0io 1pf+0w
>mixer      ( 19:18:57 ) 0.408u 0.146s 0:02.37 22.7%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.000121610006317
:CHARGE convergence:  6.2e-05
>lapw0      ( 19:18:59 ) starting parallel lapw0 at Fri Feb  7 19:18:59 CST 2014
-------- .machine0 : 8 processors
13.707u 0.447s 0:04.28 330.3%	0+0k 0+0io 96pf+0w
>lapw1      ( 19:19:04 ) starting parallel lapw1 at Fri Feb  7 19:19:04 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 19:19:05 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 30658
[2] 30677
[3] 30696
[4] 30716
[5] 30735
[6] 30754
[7] 30773
[8] 30792
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1038.587u 3.746s 17:23.84 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1035.300u 3.870s 17:19.81 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1047.882u 3.786s 17:32.66 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1041.462u 4.351s 17:27.37 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1042.390u 3.755s 17:27.23 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1045.241u 3.697s 17:32.74 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1030.050u 3.696s 17:15.79 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1045.295u 3.263s 17:30.34 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8326.21	 wallclock=8369.78
8326.671u 31.483s 17:40.18 788.3%	0+0k 0+0io 8pf+0w
>lapwso     ( 19:36:44 ) running LAPWSO in parallel mode
[1] 32287
[2] 32294
[3] 32300
[4] 32306
[5] 32312
[6] 32318
[7] 32325
[8] 32331
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1039.483u 7.379s 17:28.97 99.7% 0+0k 0+0io 0pf+0w
      node013 1020.871u 8.290s 17:18.06 99.1% 0+0k 0+0io 0pf+0w
      node013 1037.809u 7.899s 17:30.82 99.5% 0+0k 0+0io 0pf+0w
      node013 1069.525u 8.723s 18:13.46 98.6% 0+0k 0+0io 0pf+0w
      node013 1008.742u 7.902s 17:07.51 98.9% 0+0k 0+0io 0pf+0w
      node013 1031.102u 7.777s 17:28.88 99.0% 0+0k 0+0io 0pf+0w
      node013 1062.519u 8.465s 18:03.69 98.8% 0+0k 0+0io 0pf+0w
      node013 1045.190u 7.710s 17:36.79 99.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8315.24	 wallclock=8448.18
8315.358u 68.527s 18:22.60 760.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 19:55:07 ) 708.74user 9.68system 1:35.65elapsed 751%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 19:56:42 ) 46896.10user 81.59system 1:51:24elapsed 702%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 21:48:09 ) 11979.06user 12.45system 25:18.98elapsed 789%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 22:13:28 ) 0.163u 0.015s 0:00.49 34.6%	0+0k 0+0io 1pf+0w
>mixer      ( 22:13:29 ) 0.435u 0.136s 0:02.25 24.8%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  4.69600781798e-05
:CHARGE convergence:  0.0002232
>lapw0      ( 22:13:32 ) starting parallel lapw0 at Fri Feb  7 22:13:35 CST 2014
-------- .machine0 : 8 processors
13.059u 0.440s 0:04.21 320.4%	0+0k 0+0io 112pf+0w
>lapw1      ( 22:13:39 ) starting parallel lapw1 at Fri Feb  7 22:13:39 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 22:13:40 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 2247
[2] 2266
[3] 2285
[4] 2305
[5] 2324
[6] 2343
[7] 2362
[8] 2382
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1027.646u 3.790s 17:13.29 99.8%	0+0k 0+0io 1pf+0w
     node013(34) 1044.687u 3.586s 17:34.41 99.4%	0+0k 0+0io 0pf+0w
     node013(34) 1015.451u 3.849s 17:00.70 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1042.769u 3.673s 17:28.35 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1040.569u 3.536s 17:25.82 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1036.123u 4.044s 17:22.96 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1040.610u 3.591s 17:26.49 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1039.951u 3.309s 17:23.62 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8287.81	 wallclock=8335.64
8288.277u 30.670s 17:37.99 786.2%	0+0k 0+0io 14pf+0w
>lapwso     ( 22:31:17 ) running LAPWSO in parallel mode
[1] 3927
[2] 3933
[3] 3940
[4] 3946
[5] 3952
[6] 3959
[7] 3965
[8] 3972
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1058.521u 7.937s 17:53.79 99.3% 0+0k 0+0io 0pf+0w
      node013 1063.750u 7.996s 18:06.92 98.6% 0+0k 0+0io 0pf+0w
      node013 1049.467u 8.086s 17:48.79 98.9% 0+0k 0+0io 0pf+0w
      node013 1061.005u 8.375s 18:02.11 98.8% 0+0k 0+0io 0pf+0w
      node013 1090.140u 7.811s 18:21.59 99.6% 0+0k 0+0io 0pf+0w
      node013 1066.533u 8.343s 18:05.57 99.0% 0+0k 0+0io 0pf+0w
      node013 1056.503u 8.225s 17:59.71 98.6% 0+0k 0+0io 0pf+0w
      node013 1082.001u 7.873s 18:18.40 99.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8527.92	 wallclock=8676.88
8528.051u 68.981s 18:31.36 773.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:49:49 ) 700.20user 9.89system 1:36.21elapsed 738%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:51:25 ) 48731.53user 73.01system 1:54:11elapsed 712%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:45:36 ) 12112.89user 12.25system 25:51.70elapsed 781%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:11:28 ) 0.155u 0.008s 0:00.42 35.7%	0+0k 0+0io 1pf+0w
>mixer      ( 01:11:28 ) 0.340u 0.110s 0:00.72 62.5%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  0.000126990024
:CHARGE convergence:  0.0001822
>lapw0      ( 01:11:29 ) starting parallel lapw0 at Sat Feb  8 01:11:29 CST 2014
-------- .machine0 : 8 processors
12.193u 0.451s 0:04.00 316.0%	0+0k 0+0io 96pf+0w
>lapw1      ( 01:11:33 ) starting parallel lapw1 at Sat Feb  8 01:11:34 CST 2014
->  starting parallel LAPW1 jobs at Sat Feb  8 01:11:35 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 6486
[2] 6506
[3] 6525
[4] 6544
[5] 6563
[6] 6582
[7] 6602
[8] 6621
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1036.651u 4.120s 17:23.19 99.7%	0+0k 0+0io 1pf+0w
     node013(34) 1032.641u 4.115s 17:18.06 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1025.815u 3.881s 17:13.00 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1030.338u 3.733s 17:15.27 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1035.661u 3.513s 17:20.53 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1032.692u 3.691s 17:17.94 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1024.101u 3.050s 17:09.81 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1039.068u 3.660s 17:24.63 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8256.97	 wallclock=8302.43
8257.442u 31.056s 17:34.02 786.3%	0+0k 0+0io 8pf+0w
>lapwso     ( 01:29:08 ) running LAPWSO in parallel mode
[1] 8108
[2] 8114
[3] 8121
[4] 8127
[5] 8133
[6] 8139
[7] 8145
[8] 8152
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1019.589u 7.728s 17:16.21 99.1% 0+0k 0+0io 0pf+0w
      node013 1073.981u 8.001s 18:08.29 99.4% 0+0k 0+0io 0pf+0w
      node013 1066.993u 7.777s 18:07.20 98.8% 0+0k 0+0io 0pf+0w
      node013 1063.308u 7.899s 17:58.09 99.3% 0+0k 0+0io 0pf+0w
      node013 1064.676u 7.969s 17:58.58 99.4% 0+0k 0+0io 0pf+0w
      node013 1062.851u 7.641s 17:58.81 99.2% 0+0k 0+0io 0pf+0w
      node013 1054.452u 8.990s 18:03.17 98.1% 0+0k 0+0io 0pf+0w
      node013 1020.255u 8.074s 17:24.35 98.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8426.11	 wallclock=8574.7
8426.236u 68.437s 18:14.93 775.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:47:23 ) 705.37user 10.16system 1:33.69elapsed 763%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:48:56 ) 55710.48user 87.30system 2:09:29elapsed 718%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:58:26 ) 12176.39user 12.24system 25:54.15elapsed 784%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:24:20 ) 0.158u 0.018s 0:00.38 42.1%	0+0k 0+0io 1pf+0w
>mixer      ( 04:24:21 ) 0.366u 0.139s 0:01.15 42.6%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  4.10500215366e-05
:CHARGE convergence:  0.0003321
>lapw0      ( 04:24:22 ) starting parallel lapw0 at Sat Feb  8 04:25:55 CST 2014
-------- .machine0 : 8 processors
12.598u 0.461s 1:37.11 13.4%	0+0k 0+0io 96pf+0w
>lapw1      ( 04:27:33 ) starting parallel lapw1 at Sat Feb  8 04:27:33 CST 2014
->  starting parallel LAPW1 jobs at Sat Feb  8 04:27:34 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 11252
[2] 11271
[3] 11291
[4] 11310
[5] 11329
[6] 11348
[7] 11367
[8] 11387
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1020.528u 3.761s 17:05.20 99.9%	0+0k 0+0io 1pf+0w
     node013(34) 1046.595u 3.520s 17:31.73 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1015.354u 3.841s 16:59.48 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1037.925u 3.739s 17:24.57 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1036.502u 3.715s 17:22.30 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1036.403u 4.150s 17:23.89 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1036.636u 3.268s 17:22.62 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1039.964u 3.755s 17:26.97 99.6%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8269.91	 wallclock=8316.76
8270.365u 31.043s 17:36.69 785.6%	0+0k 0+0io 9pf+0w
>lapwso     ( 04:45:09 ) running LAPWSO in parallel mode
[1] 12861
[2] 12867
[3] 12874
[4] 12880
[5] 12886
[6] 12892
[7] 12898
[8] 12905
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1029.872u 7.673s 17:23.64 99.4% 0+0k 0+0io 0pf+0w
      node013 1084.894u 9.289s 18:24.77 99.0% 0+0k 0+0io 0pf+0w
      node013 1075.074u 7.893s 18:09.75 99.3% 0+0k 0+0io 0pf+0w
      node013 1066.335u 8.067s 18:04.48 99.0% 0+0k 0+0io 0pf+0w
      node013 1054.478u 8.056s 17:47.56 99.5% 0+0k 0+0io 0pf+0w
      node013 1057.231u 7.389s 17:47.46 99.7% 0+0k 0+0io 0pf+0w
      node013 1078.706u 7.322s 18:09.74 99.6% 0+0k 0+0io 0pf+0w
      node013 1097.308u 7.997s 18:38.22 98.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8543.9	 wallclock=8665.62
8544.022u 68.012s 18:51.39 761.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 05:04:01 ) 707.34user 10.19system 1:34.28elapsed 761%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 05:05:35 ) 49018.73user 70.37system 1:53:34elapsed 720%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:59:10 ) 11952.27user 12.43system 25:24.68elapsed 784%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 07:24:34 ) 0.170u 0.018s 0:00.44 40.9%	0+0k 0+0io 1pf+0w
>mixer      ( 07:24:35 ) 0.383u 0.115s 0:01.47 33.3%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  7.11600296199e-05
:CHARGE convergence:  0.000497
>lapw0      ( 07:24:37 ) starting parallel lapw0 at Sat Feb  8 07:24:37 CST 2014
-------- .machine0 : 8 processors
14.244u 0.435s 0:04.36 336.4%	0+0k 0+0io 114pf+0w
>lapw1      ( 07:24:41 ) starting parallel lapw1 at Sat Feb  8 07:24:41 CST 2014
->  starting parallel LAPW1 jobs at Sat Feb  8 07:24:43 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 15250
[2] 15269
[3] 15289
[4] 15308
[5] 15327
[6] 15346
[7] 15365
[8] 15385
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1049.484u 3.667s 17:34.62 99.8%	0+0k 0+0io 1pf+0w
     node013(34) 1040.092u 3.856s 17:26.41 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1024.159u 3.844s 17:08.22 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1047.257u 3.659s 17:33.15 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1047.948u 3.690s 17:32.76 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1013.544u 3.839s 16:58.88 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1040.830u 3.408s 17:28.21 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1043.677u 3.599s 17:30.42 99.6%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8306.99	 wallclock=8352.67
8307.473u 30.854s 17:41.51 785.5%	0+0k 0+0io 7pf+0w
>lapwso     ( 07:42:23 ) running LAPWSO in parallel mode
[1] 16868
[2] 16874
[3] 16880
[4] 16886
[5] 16892
[6] 16899
[7] 16905
[8] 16911
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1053.993u 8.225s 17:50.10 99.2% 0+0k 0+0io 0pf+0w
      node013 1072.949u 7.748s 18:10.50 99.0% 0+0k 0+0io 0pf+0w
      node013 1094.535u 7.607s 18:28.88 99.3% 0+0k 0+0io 0pf+0w
      node013 1054.143u 8.048s 17:50.90 99.1% 0+0k 0+0io 0pf+0w
      node013 1046.248u 8.243s 17:41.99 99.2% 0+0k 0+0io 0pf+0w
      node013 1063.687u 8.228s 18:01.75 99.0% 0+0k 0+0io 0pf+0w
      node013 1088.401u 8.454s 18:28.29 98.9% 0+0k 0+0io 0pf+0w
      node013 1066.400u 8.007s 18:07.05 98.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8540.36	 wallclock=8679.46
8540.479u 68.922s 18:39.72 768.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 08:01:03 ) 706.04user 10.32system 1:37.58elapsed 734%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 08:02:40 ) 57177.12user 91.41system 2:12:52elapsed 718%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 10:15:33 ) 11981.81user 12.27system 25:22.05elapsed 788%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 10:40:55 ) 0.160u 0.016s 0:00.48 35.4%	0+0k 0+0io 1pf+0w
>mixer      ( 10:40:56 ) 0.392u 0.126s 0:01.60 31.8%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  7.05400016159e-05
:CHARGE convergence:  0.0005784
>lapw0      ( 10:40:57 ) starting parallel lapw0 at Sat Feb  8 10:40:58 CST 2014
-------- .machine0 : 8 processors
14.427u 0.446s 0:04.32 343.9%	0+0k 0+0io 97pf+0w
>lapw1      ( 10:41:02 ) starting parallel lapw1 at Sat Feb  8 10:41:02 CST 2014
->  starting parallel LAPW1 jobs at Sat Feb  8 10:41:03 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 19517
[2] 19536
[3] 19555
[4] 19574
[5] 19594
[6] 19613
[7] 19632
[8] 19651
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1040.994u 4.037s 17:28.11 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1010.573u 3.948s 16:55.01 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1040.437u 3.663s 17:24.86 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1026.139u 3.778s 17:15.18 99.4%	0+0k 0+0io 0pf+0w
     node013(34) 1022.099u 3.766s 17:07.94 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1038.753u 4.234s 17:24.94 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1031.703u 2.986s 17:17.50 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1028.972u 3.402s 17:13.22 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8239.67	 wallclock=8286.76
8240.164u 31.086s 17:32.46 785.8%	0+0k 0+0io 4pf+0w
>lapwso     ( 10:58:34 ) running LAPWSO in parallel mode
[1] 21134
[2] 21140
[3] 21147
[4] 21153
[5] 21159
[6] 21165
[7] 21171
[8] 21178
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1048.899u 8.063s 17:47.04 99.0% 0+0k 0+0io 0pf+0w
      node013 1100.222u 7.957s 18:37.56 99.1% 0+0k 0+0io 0pf+0w
      node013 1072.000u 7.692s 18:06.75 99.3% 0+0k 0+0io 0pf+0w
      node013 1080.370u 9.611s 18:28.25 98.3% 0+0k 0+0io 0pf+0w
      node013 1043.317u 8.313s 17:38.28 99.3% 0+0k 0+0io 0pf+0w
      node013 1072.706u 7.331s 18:05.34 99.5% 0+0k 0+0io 0pf+0w
      node013 1070.620u 7.533s 18:05.91 99.2% 0+0k 0+0io 0pf+0w
      node013 1094.039u 7.751s 18:27.50 99.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8582.17	 wallclock=8716.63
8582.297u 68.597s 18:44.29 769.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 11:17:19 ) 716.49user 10.08system 1:34.62elapsed 767%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 11:18:53 ) 48526.15user 79.58system 1:52:41elapsed 718%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 13:11:41 ) 11941.40user 12.24system 25:18.75elapsed 787%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 13:37:00 ) 0.163u 0.015s 0:00.34 50.0%	0+0k 0+0io 1pf+0w
>mixer      ( 13:37:00 ) 0.414u 0.124s 0:01.61 32.9%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  5.16599975526e-05
:CHARGE convergence:  0.0007507
>lapw0      ( 13:37:02 ) starting parallel lapw0 at Sat Feb  8 13:37:02 CST 2014
-------- .machine0 : 8 processors
12.679u 0.445s 0:04.01 326.9%	0+0k 0+0io 93pf+0w
>lapw1      ( 13:37:06 ) starting parallel lapw1 at Sat Feb  8 13:37:07 CST 2014
->  starting parallel LAPW1 jobs at Sat Feb  8 13:37:08 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 23530
[2] 23549
[3] 23568
[4] 23587
[5] 23606
[6] 23626
[7] 23645
[8] 23664
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node013(34) 1044.652u 3.659s 17:32.67 99.5%	0+0k 0+0io 0pf+0w
     node013(34) 1026.993u 3.881s 17:11.72 99.9%	0+0k 0+0io 0pf+0w
     node013(34) 1030.013u 3.805s 17:15.91 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1045.310u 3.839s 17:32.45 99.6%	0+0k 0+0io 0pf+0w
     node013(34) 1031.744u 4.489s 17:17.73 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1015.655u 3.685s 17:00.81 99.8%	0+0k 0+0io 0pf+0w
     node013(34) 1044.041u 3.298s 17:30.41 99.7%	0+0k 0+0io 0pf+0w
     node013(34) 1039.577u 3.523s 17:24.13 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node013	 k=272	 user=8277.98	 wallclock=8325.83
8278.467u 31.476s 17:38.83 784.8%	0+0k 0+0io 4pf+0w
>lapwso     ( 13:54:45 ) running LAPWSO in parallel mode
[1] 25154
[2] 25160
[3] 25166
[4] 25172
[5] 25178
[6] 25185
[7] 25191
[8] 25197
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node013 1067.318u 7.995s 18:00.09 99.5% 0+0k 0+0io 0pf+0w
      node013 1065.341u 8.078s 18:01.76 99.2% 0+0k 0+0io 0pf+0w
      node013 1068.350u 7.843s 18:09.10 98.8% 0+0k 0+0io 0pf+0w
      node013 1064.440u 7.931s 18:06.77 98.6% 0+0k 0+0io 0pf+0w
      node013 1081.087u 9.022s 18:28.41 98.3% 0+0k 0+0io 0pf+0w
      node013 1081.850u 7.495s 18:18.21 99.1% 0+0k 0+0io 0pf+0w
      node013 1064.075u 7.896s 18:04.14 98.8% 0+0k 0+0io 0pf+0w
      node013 1095.988u 7.919s 18:28.72 99.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node013	 user=8588.45	 wallclock=8737.2
8588.578u 68.579s 18:41.70 771.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 14:13:27 ) 705.35user 9.80system 1:35.41elapsed 749%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 14:15:03 ) 56085.33user 86.54system 2:12:13elapsed 707%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 16:27:25 ) 12075.11user 12.09system 25:37.42elapsed 786%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 16:53:03 ) 0.173u 0.015s 0:00.58 31.0%	0+0k 0+0io 1pf+0w
>mixer      ( 16:53:04 ) 0.403u 0.139s 0:02.19 24.2%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  4.52005770057e-06
:CHARGE convergence:  0.0008773
