Calculating alpha_Pu_2 in /scratch/ykent33893/alpha_Pu_2
on node021 with PID 17621




   start        Tue Feb  4 21:15:30 2014 with lapw0 (1/100 to go)

   cycle 0 	Tue Feb  4 21:15:30 2014 1000/0 to go

>lapw0      ( 21:15:30 ) starting parallel lapw0 at Tue Feb  4 21:15:31 CST 2014
-------- .machine0 : 8 processors
10.656u 0.415s 0:06.94 159.3%	0+0k 0+0io 109pf+0w
>lapw1      ( 21:15:38 ) starting parallel lapw1 at Tue Feb  4 21:15:47 CST 2014
->  starting parallel LAPW1 jobs at Tue Feb  4 21:15:47 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 17848
[2] 17867
[3] 17887
[4] 17906
[5] 17925
[6] 17944
[7] 17963
[8] 17983
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 623.594u 2.473s 10:26.89 99.8%	0+0k 0+0io 1pf+0w
     node021(34) 626.077u 3.422s 10:29.76 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 623.277u 2.218s 10:25.81 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 627.244u 2.662s 10:30.83 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 623.410u 2.739s 10:26.47 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 624.367u 2.814s 10:30.01 99.5%	0+0k 0+0io 0pf+0w
     node021(34) 624.176u 2.786s 10:28.21 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 621.097u 2.719s 10:23.96 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4993.24	 wallclock=5021.94
4993.575u 22.740s 10:36.33 788.3%	0+0k 0+0io 1pf+0w
>lapwso     ( 21:26:23 ) running LAPWSO in parallel mode
[1] 18990
[2] 18996
[3] 19002
[4] 19008
[5] 19015
[6] 19021
[7] 19027
[8] 19033
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 649.625u 5.435s 11:01.77 98.9% 0+0k 0+0io 1pf+0w
      node021 660.018u 5.450s 11:13.09 98.8% 0+0k 0+0io 0pf+0w
      node021 696.841u 5.600s 11:48.79 99.1% 0+0k 0+0io 0pf+0w
      node021 661.571u 5.940s 11:11.52 99.4% 0+0k 0+0io 0pf+0w
      node021 680.357u 5.872s 11:38.08 98.3% 0+0k 0+0io 0pf+0w
      node021 671.126u 5.615s 11:20.92 99.3% 0+0k 0+0io 0pf+0w
      node021 655.846u 5.482s 11:05.62 99.3% 0+0k 0+0io 0pf+0w
      node021 692.035u 5.575s 11:46.77 98.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5367.42	 wallclock=5466.56
5367.538u 45.245s 11:54.60 757.4%	0+0k 0+0io 1pf+0w
>dmft1      ( 21:38:18 ) 539.19user 7.17system 1:14.09elapsed 737%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 21:39:32 ) 59307.37user 91.31system 2:14:43elapsed 734%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 23:54:25 ) 11131.81user 9.72system 23:17.00elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:17:43 ) 0.139u 0.011s 0:00.27 51.8%	0+0k 0+0io 1pf+0w
>mixer      ( 00:17:43 ) 0.308u 0.105s 0:00.72 55.5%	0+0k 0+0io 5pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0248384
>lapw0      ( 00:17:44 ) starting parallel lapw0 at Wed Feb  5 00:17:47 CST 2014
-------- .machine0 : 8 processors
10.311u 0.428s 0:03.68 291.5%	0+0k 0+0io 103pf+0w
>lapw1      ( 00:17:51 ) starting parallel lapw1 at Wed Feb  5 00:17:51 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 00:17:51 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 21547
[2] 21566
[3] 21586
[4] 21605
[5] 21624
[6] 21643
[7] 21662
[8] 21682
[5]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 629.212u 2.724s 10:32.74 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 623.950u 3.034s 10:28.81 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 622.439u 2.615s 10:25.76 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 626.425u 2.875s 10:29.85 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 619.633u 2.933s 10:23.21 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 619.891u 3.261s 10:25.21 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 623.836u 2.987s 10:27.04 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 620.536u 2.973s 10:23.60 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4985.92	 wallclock=5016.22
4986.267u 24.291s 10:36.71 786.9%	0+0k 0+0io 17pf+0w
>lapwso     ( 00:28:28 ) running LAPWSO in parallel mode
[1] 22680
[2] 22686
[3] 22692
[4] 22698
[5] 22704
[6] 22711
[7] 22717
[8] 22723
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 627.913u 6.429s 10:51.60 97.3% 0+0k 0+0io 0pf+0w
      node021 649.328u 5.382s 10:59.10 99.3% 0+0k 0+0io 0pf+0w
      node021 648.789u 5.499s 11:00.45 99.0% 0+0k 0+0io 0pf+0w
      node021 645.558u 5.590s 10:57.93 98.9% 0+0k 0+0io 0pf+0w
      node021 674.548u 5.110s 11:26.93 98.9% 0+0k 0+0io 0pf+0w
      node021 639.009u 5.633s 10:54.65 98.4% 0+0k 0+0io 0pf+0w
      node021 644.190u 5.262s 10:58.81 98.5% 0+0k 0+0io 0pf+0w
      node021 659.363u 5.806s 11:11.78 99.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5188.7	 wallclock=5301.25
5188.823u 47.746s 11:34.57 753.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:40:02 ) 539.50user 7.44system 1:16.14elapsed 718%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:41:19 ) 52946.22user 88.83system 2:04:35elapsed 709%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:45:55 ) 10357.00user 9.36system 21:39.70elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:07:35 ) 0.132u 0.012s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 03:07:35 ) 0.290u 0.113s 0:00.40 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  6.60199439153e-05
:CHARGE convergence:  0.0246549
>lapw0      ( 03:07:36 ) starting parallel lapw0 at Wed Feb  5 03:07:36 CST 2014
-------- .machine0 : 8 processors
10.277u 0.419s 0:03.54 301.6%	0+0k 0+0io 86pf+0w
>lapw1      ( 03:07:40 ) starting parallel lapw1 at Wed Feb  5 03:07:40 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 03:07:40 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 25088
[2] 25107
[3] 25126
[4] 25146
[5] 25165
[6] 25184
[7] 25203
[8] 25222
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 626.682u 2.871s 10:30.19 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 624.089u 2.938s 10:28.35 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 623.725u 2.437s 10:26.34 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 627.281u 3.054s 10:30.96 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 625.789u 3.007s 10:28.86 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 622.402u 3.121s 10:27.70 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 622.207u 3.298s 10:27.03 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 621.063u 2.992s 10:24.13 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4993.24	 wallclock=5023.56
4993.557u 24.659s 10:35.26 789.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:18:15 ) running LAPWSO in parallel mode
[1] 26227
[2] 26233
[3] 26239
[4] 26245
[5] 26252
[6] 26258
[7] 26264
[8] 26270
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 631.997u 5.350s 10:40.95 99.4% 0+0k 0+0io 0pf+0w
      node021 644.892u 5.562s 10:57.56 98.9% 0+0k 0+0io 0pf+0w
      node021 660.376u 5.678s 11:10.84 99.2% 0+0k 0+0io 0pf+0w
      node021 655.035u 6.138s 11:14.18 98.0% 0+0k 0+0io 0pf+0w
      node021 649.601u 5.968s 11:01.18 99.1% 0+0k 0+0io 0pf+0w
      node021 662.396u 5.539s 11:12.17 99.3% 0+0k 0+0io 0pf+0w
      node021 646.107u 5.649s 10:59.21 98.8% 0+0k 0+0io 0pf+0w
      node021 659.851u 5.510s 11:09.79 99.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5210.26	 wallclock=5305.88
5210.372u 48.446s 11:20.40 772.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:29:35 ) 540.43user 7.75system 1:14.47elapsed 736%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:30:50 ) 58382.88user 96.80system 2:14:17elapsed 725%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:45:07 ) 10363.69user 9.41system 21:40.37elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:06:48 ) 0.134u 0.010s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 06:06:49 ) 0.309u 0.099s 0:01.89 20.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000599439954385
:CHARGE convergence:  0.0264921
>lapw0      ( 06:06:51 ) starting parallel lapw0 at Wed Feb  5 06:06:52 CST 2014
-------- .machine0 : 8 processors
10.393u 0.399s 0:09.76 110.4%	0+0k 0+0io 81pf+0w
>lapw1      ( 06:07:01 ) starting parallel lapw1 at Wed Feb  5 06:07:03 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 06:07:03 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 29209
[2] 29228
[3] 29248
[4] 29267
[5] 29286
[6] 29305
[7] 29324
[8] 29344
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 609.068u 2.982s 10:12.94 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 618.436u 2.949s 10:23.91 99.5%	0+0k 0+0io 0pf+0w
     node021(34) 618.085u 2.696s 10:21.73 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 614.319u 3.281s 10:18.24 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 626.301u 3.054s 10:29.48 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 625.172u 3.218s 10:28.90 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 615.675u 3.012s 10:18.88 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 618.797u 3.095s 10:22.58 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4945.85	 wallclock=4976.66
4946.175u 25.200s 10:35.45 782.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 06:17:38 ) running LAPWSO in parallel mode
[1] 30329
[2] 30335
[3] 30341
[4] 30347
[5] 30353
[6] 30360
[7] 30366
[8] 30372
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 627.981u 5.770s 10:41.55 98.7% 0+0k 0+0io 0pf+0w
      node021 619.047u 5.543s 10:29.68 99.1% 0+0k 0+0io 0pf+0w
      node021 643.689u 6.646s 11:00.24 98.4% 0+0k 0+0io 0pf+0w
      node021 638.779u 6.099s 10:49.67 99.2% 0+0k 0+0io 0pf+0w
      node021 616.034u 5.377s 10:24.36 99.5% 0+0k 0+0io 0pf+0w
      node021 625.793u 5.637s 10:36.48 99.2% 0+0k 0+0io 0pf+0w
      node021 635.298u 5.299s 10:48.00 98.8% 0+0k 0+0io 0pf+0w
      node021 628.548u 5.490s 10:42.02 98.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5035.17	 wallclock=5132
5035.286u 48.923s 11:05.66 763.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 06:28:45 ) 544.38user 7.68system 1:15.93elapsed 727%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 06:30:01 ) 58309.73user 98.43system 2:14:52elapsed 721%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 08:44:55 ) 11332.01user 9.45system 23:39.95elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 09:08:35 ) 0.138u 0.007s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 09:08:35 ) 0.318u 0.096s 0:00.41 97.5%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.0030218299944
:CHARGE convergence:  0.034641
>lapw0      ( 09:08:36 ) starting parallel lapw0 at Wed Feb  5 09:08:36 CST 2014
-------- .machine0 : 8 processors
10.443u 0.442s 0:03.54 307.3%	0+0k 0+0io 86pf+0w
>lapw1      ( 09:08:39 ) starting parallel lapw1 at Wed Feb  5 09:08:39 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 09:08:39 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 483
[2] 503
[3] 522
[4] 541
[5] 560
[6] 579
[7] 599
[8] 628
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 602.486u 2.602s 10:05.42 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 621.689u 3.164s 10:25.47 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 614.522u 2.522s 10:19.16 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 623.048u 2.946s 10:26.33 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 618.430u 3.340s 10:22.90 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 620.124u 3.243s 10:23.94 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 613.152u 3.191s 10:17.38 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 617.103u 2.920s 10:20.09 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4930.55	 wallclock=4960.69
4930.880u 24.819s 10:30.66 785.7%	0+0k 0+0io 0pf+0w
>lapwso     ( 09:19:10 ) running LAPWSO in parallel mode
[1] 1633
[2] 1640
[3] 1646
[4] 1652
[5] 1658
[6] 1664
[7] 1671
[8] 1677
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 644.065u 5.373s 10:52.23 99.5% 0+0k 0+0io 0pf+0w
      node021 637.735u 5.252s 10:45.34 99.6% 0+0k 0+0io 0pf+0w
      node021 662.252u 5.566s 11:13.08 99.2% 0+0k 0+0io 0pf+0w
      node021 644.972u 5.573s 10:57.20 98.9% 0+0k 0+0io 0pf+0w
      node021 633.896u 5.880s 10:43.73 99.3% 0+0k 0+0io 0pf+0w
      node021 641.150u 5.429s 10:49.07 99.6% 0+0k 0+0io 0pf+0w
      node021 642.230u 5.722s 10:50.79 99.5% 0+0k 0+0io 0pf+0w
      node021 645.787u 6.310s 11:07.61 97.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5152.09	 wallclock=5239.05
5152.216u 48.195s 11:18.22 766.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 09:30:29 ) 541.34user 7.76system 1:16.91elapsed 713%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 09:31:46 ) 59472.14user 99.57system 2:16:25elapsed 727%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 11:48:11 ) 10348.01user 9.73system 21:38.52elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 12:09:50 ) 0.125u 0.016s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 12:09:50 ) 0.312u 0.115s 0:00.43 97.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00281499000266
:CHARGE convergence:  0.0277289
>lapw0      ( 12:09:51 ) starting parallel lapw0 at Wed Feb  5 12:09:51 CST 2014
-------- .machine0 : 8 processors
10.521u 0.396s 0:03.59 303.8%	0+0k 0+0io 84pf+0w
>lapw1      ( 12:09:54 ) starting parallel lapw1 at Wed Feb  5 12:09:55 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 12:09:55 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 4258
[2] 4278
[3] 4297
[4] 4316
[5] 4335
[6] 4354
[7] 4374
[8] 4395
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 616.433u 2.739s 10:19.30 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 631.244u 3.018s 10:36.46 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 629.783u 2.942s 10:34.79 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 628.952u 2.943s 10:32.65 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 629.982u 2.939s 10:33.64 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 628.519u 3.074s 10:32.21 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 613.605u 3.161s 10:17.07 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 625.251u 3.062s 10:28.64 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=5003.77	 wallclock=5034.76
5004.106u 24.771s 10:38.95 787.0%	0+0k 0+0io 0pf+0w
>lapwso     ( 12:20:34 ) running LAPWSO in parallel mode
[1] 5368
[2] 5374
[3] 5380
[4] 5386
[5] 5392
[6] 5399
[7] 5405
[8] 5411
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 644.901u 5.664s 10:57.41 98.9% 0+0k 0+0io 0pf+0w
      node021 631.158u 5.325s 10:38.48 99.6% 0+0k 0+0io 0pf+0w
      node021 656.086u 6.229s 11:09.61 98.9% 0+0k 0+0io 0pf+0w
      node021 629.911u 5.335s 10:40.26 99.2% 0+0k 0+0io 0pf+0w
      node021 644.848u 5.670s 10:53.47 99.5% 0+0k 0+0io 0pf+0w
      node021 660.385u 5.618s 11:11.69 99.1% 0+0k 0+0io 0pf+0w
      node021 644.257u 5.976s 10:54.77 99.3% 0+0k 0+0io 0pf+0w
      node021 643.440u 5.447s 10:50.00 99.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5154.99	 wallclock=5235.69
5155.097u 48.356s 11:20.33 764.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 12:31:54 ) 541.15user 7.65system 1:17.12elapsed 711%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 12:33:11 ) 61947.53user 101.18system 2:24:24elapsed 716%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 14:57:37 ) 10341.13user 9.18system 21:37.33elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 15:19:14 ) 0.138u 0.011s 0:00.15 93.3%	0+0k 0+0io 0pf+0w
>mixer      ( 15:19:16 ) 0.324u 0.108s 0:00.43 97.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00437968003098
:CHARGE convergence:  0.0401711
>lapw0      ( 15:19:17 ) starting parallel lapw0 at Wed Feb  5 15:19:17 CST 2014
-------- .machine0 : 8 processors
10.540u 0.446s 0:03.66 300.0%	0+0k 0+0io 85pf+0w
>lapw1      ( 15:19:21 ) starting parallel lapw1 at Wed Feb  5 15:19:26 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 15:19:26 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 8014
[2] 8033
[3] 8052
[4] 8072
[5] 8091
[6] 8110
[7] 8129
[8] 8148
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 609.933u 2.980s 10:15.19 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 621.447u 3.000s 10:25.40 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 605.754u 2.531s 10:08.70 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 620.056u 2.868s 10:26.50 99.4%	0+0k 0+0io 0pf+0w
     node021(34) 621.338u 3.013s 10:25.87 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 617.594u 3.696s 10:23.29 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 619.998u 2.851s 10:24.45 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 611.717u 3.039s 10:15.46 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4927.84	 wallclock=4964.86
4928.158u 24.883s 10:35.88 778.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 15:29:58 ) running LAPWSO in parallel mode
[1] 9127
[2] 9134
[3] 9140
[4] 9146
[5] 9152
[6] 9158
[7] 9165
[8] 9171
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 622.310u 6.023s 10:35.03 98.9% 0+0k 0+0io 0pf+0w
      node021 631.352u 5.750s 10:42.77 99.1% 0+0k 0+0io 0pf+0w
      node021 626.793u 5.774s 10:37.56 99.2% 0+0k 0+0io 0pf+0w
      node021 648.175u 6.288s 11:05.37 98.3% 0+0k 0+0io 0pf+0w
      node021 666.998u 5.429s 11:14.86 99.6% 0+0k 0+0io 0pf+0w
      node021 649.698u 5.956s 11:07.73 98.1% 0+0k 0+0io 0pf+0w
      node021 651.460u 5.083s 10:58.10 99.7% 0+0k 0+0io 0pf+0w
      node021 653.253u 5.341s 11:03.08 99.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5150.04	 wallclock=5244.5
5150.170u 48.742s 11:22.41 761.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 15:41:20 ) 541.08user 7.83system 1:21.18elapsed 676%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 15:42:41 ) 60861.56user 109.79system 2:23:35elapsed 707%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 18:06:17 ) 10397.84user 9.38system 23:48.56elapsed 728%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 18:30:06 ) 0.134u 0.009s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 18:30:06 ) 0.335u 0.108s 0:00.44 97.7%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000864180037752
:CHARGE convergence:  0.0429656
>lapw0      ( 18:30:07 ) starting parallel lapw0 at Wed Feb  5 18:30:07 CST 2014
-------- .machine0 : 8 processors
10.446u 0.395s 0:03.56 304.2%	0+0k 0+0io 83pf+0w
>lapw1      ( 18:30:10 ) starting parallel lapw1 at Wed Feb  5 18:30:11 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 18:30:11 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 11797
[2] 11816
[3] 11835
[4] 11855
[5] 11874
[6] 11893
[7] 11912
[8] 11931
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 606.035u 2.814s 10:10.74 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 623.513u 3.037s 10:27.19 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 627.127u 2.408s 10:29.87 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 623.475u 3.050s 10:27.46 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 619.108u 3.131s 10:23.08 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 621.533u 3.252s 10:25.63 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 607.030u 3.196s 10:10.53 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 611.047u 3.163s 10:14.42 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4938.87	 wallclock=4968.92
4939.202u 24.955s 10:33.15 784.0%	0+0k 0+0io 0pf+0w
>lapwso     ( 18:40:44 ) running LAPWSO in parallel mode
[1] 12915
[2] 12922
[3] 12928
[4] 12934
[5] 12940
[6] 12946
[7] 12953
[8] 12959
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 630.394u 5.895s 10:46.53 98.4% 0+0k 0+0io 0pf+0w
      node021 630.960u 5.557s 10:41.49 99.2% 0+0k 0+0io 0pf+0w
      node021 669.341u 5.385s 11:19.10 99.3% 0+0k 0+0io 0pf+0w
      node021 642.148u 5.418s 10:51.83 99.3% 0+0k 0+0io 0pf+0w
      node021 661.323u 5.700s 11:16.60 98.5% 0+0k 0+0io 0pf+0w
      node021 666.073u 5.888s 11:17.92 99.1% 0+0k 0+0io 0pf+0w
      node021 663.830u 5.527s 11:13.75 99.3% 0+0k 0+0io 0pf+0w
      node021 638.705u 5.661s 10:47.30 99.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5202.77	 wallclock=5294.52
5202.893u 48.190s 11:27.65 763.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 18:52:13 ) 540.44user 7.79system 1:21.62elapsed 671%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 18:53:35 ) 63380.58user 96.22system 2:28:31elapsed 712%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 21:22:07 ) 10385.82user 9.50system 21:51.03elapsed 792%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 21:43:58 ) 0.125u 0.013s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 21:43:58 ) 0.340u 0.116s 0:00.45 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00259677995928
:CHARGE convergence:  0.0369179
>lapw0      ( 21:43:58 ) starting parallel lapw0 at Wed Feb  5 21:43:59 CST 2014
-------- .machine0 : 8 processors
10.365u 0.414s 0:03.54 304.2%	0+0k 0+0io 84pf+0w
>lapw1      ( 21:44:02 ) starting parallel lapw1 at Wed Feb  5 21:44:02 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 21:44:02 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 15624
[2] 15643
[3] 15663
[4] 15682
[5] 15701
[6] 15720
[7] 15739
[8] 15759
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 605.018u 2.742s 10:08.09 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 622.772u 3.419s 10:26.78 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 624.234u 2.427s 10:27.24 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 609.437u 3.220s 10:12.78 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 621.786u 2.920s 10:24.75 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 622.884u 2.875s 10:26.26 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 619.915u 3.147s 10:25.69 99.5%	0+0k 0+0io 0pf+0w
     node021(34) 615.025u 3.095s 10:19.04 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4941.07	 wallclock=4970.63
4941.418u 24.736s 10:33.04 784.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 21:54:35 ) running LAPWSO in parallel mode
[1] 16752
[2] 16758
[3] 16764
[4] 16771
[5] 16777
[6] 16783
[7] 16789
[8] 16795
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 646.562u 6.133s 11:01.05 98.7% 0+0k 0+0io 0pf+0w
      node021 627.871u 5.452s 10:35.56 99.6% 0+0k 0+0io 0pf+0w
      node021 656.157u 6.272s 11:09.48 98.9% 0+0k 0+0io 0pf+0w
      node021 665.961u 5.389s 11:16.35 99.2% 0+0k 0+0io 0pf+0w
      node021 640.102u 5.747s 10:52.36 99.0% 0+0k 0+0io 0pf+0w
      node021 679.956u 5.437s 11:29.27 99.4% 0+0k 0+0io 0pf+0w
      node021 677.515u 5.916s 11:29.47 99.1% 0+0k 0+0io 0pf+0w
      node021 642.077u 5.117s 10:47.82 99.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5236.2	 wallclock=5321.36
5236.313u 48.639s 11:38.79 756.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:06:14 ) 539.16user 7.59system 1:29.74elapsed 609%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:07:44 ) 60693.17user 99.33system 2:23:03elapsed 708%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:30:48 ) 10368.46user 9.35system 21:40.69elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:52:28 ) 0.130u 0.011s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 00:52:29 ) 0.355u 0.114s 0:00.47 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000548079959117
:CHARGE convergence:  0.0389632
>lapw0      ( 00:52:29 ) starting parallel lapw0 at Thu Feb  6 00:52:29 CST 2014
-------- .machine0 : 8 processors
10.327u 0.410s 0:03.53 303.9%	0+0k 0+0io 85pf+0w
>lapw1      ( 00:52:33 ) starting parallel lapw1 at Thu Feb  6 00:52:33 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 00:52:33 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 19389
[2] 19408
[3] 19428
[4] 19447
[5] 19466
[6] 19485
[7] 19504
[8] 19524
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 625.330u 2.617s 10:28.28 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 621.631u 3.024s 10:24.82 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 620.361u 2.698s 10:23.92 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 623.948u 3.027s 10:29.74 99.5%	0+0k 0+0io 0pf+0w
     node021(34) 620.436u 3.147s 10:24.35 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 622.811u 3.065s 10:25.96 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 622.432u 3.235s 10:26.24 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 618.350u 3.003s 10:21.41 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4975.3	 wallclock=5004.72
4975.632u 24.731s 10:34.03 788.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:03:07 ) running LAPWSO in parallel mode
[1] 20524
[2] 20530
[3] 20536
[4] 20542
[5] 20549
[6] 20555
[7] 20561
[8] 20567
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 635.696u 5.596s 10:46.98 99.1% 0+0k 0+0io 0pf+0w
      node021 657.993u 5.344s 11:10.74 98.8% 0+0k 0+0io 0pf+0w
      node021 653.676u 5.893s 11:06.97 98.8% 0+0k 0+0io 0pf+0w
      node021 649.393u 5.456s 11:02.03 98.9% 0+0k 0+0io 0pf+0w
      node021 659.003u 5.952s 11:16.04 98.3% 0+0k 0+0io 0pf+0w
      node021 647.731u 5.573s 11:00.10 98.9% 0+0k 0+0io 0pf+0w
      node021 637.350u 5.641s 10:49.41 99.0% 0+0k 0+0io 0pf+0w
      node021 633.384u 5.269s 10:42.96 99.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5174.23	 wallclock=5275.23
5174.351u 47.881s 11:23.77 763.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:14:31 ) 541.69user 7.84system 1:18.32elapsed 701%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:15:49 ) 61102.75user 97.87system 2:21:39elapsed 720%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:37:30 ) 10355.01user 9.43system 21:47.21elapsed 792%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:59:18 ) 0.131u 0.014s 0:00.18 77.7%	0+0k 0+0io 0pf+0w
>mixer      ( 03:59:19 ) 0.340u 0.122s 0:02.15 21.3%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00042769999709
:CHARGE convergence:  0.0406783
>lapw0      ( 03:59:23 ) starting parallel lapw0 at Thu Feb  6 03:59:23 CST 2014
-------- .machine0 : 8 processors
10.473u 0.433s 0:05.82 187.2%	0+0k 0+0io 82pf+0w
>lapw1      ( 03:59:29 ) starting parallel lapw1 at Thu Feb  6 03:59:31 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 03:59:31 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 23141
[2] 23160
[3] 23179
[4] 23198
[5] 23217
[6] 23237
[7] 23256
[8] 23275
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 611.440u 2.795s 10:16.30 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 628.537u 2.956s 10:43.31 98.1%	0+0k 0+0io 0pf+0w
     node021(34) 620.813u 2.431s 10:32.33 98.5%	0+0k 0+0io 0pf+0w
     node021(34) 617.322u 2.928s 10:28.77 98.6%	0+0k 0+0io 0pf+0w
     node021(34) 619.933u 2.944s 10:30.24 98.8%	0+0k 0+0io 0pf+0w
     node021(34) 616.043u 3.190s 10:24.89 99.0%	0+0k 0+0io 0pf+0w
     node021(34) 618.824u 4.012s 10:27.48 99.2%	0+0k 0+0io 0pf+0w
     node021(34) 621.492u 3.142s 10:28.62 99.3%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4954.4	 wallclock=5031.94
4954.764u 25.301s 10:45.57 771.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:10:16 ) running LAPWSO in parallel mode
[1] 24759
[2] 24766
[3] 24772
[4] 24778
[5] 24784
[6] 24790
[7] 24797
[8] 24803
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 669.679u 6.109s 11:21.67 99.1% 0+0k 0+0io 0pf+0w
      node021 608.410u 5.549s 10:24.68 98.2% 0+0k 0+0io 0pf+0w
      node021 700.180u 5.839s 11:48.90 99.5% 0+0k 0+0io 0pf+0w
      node021 626.063u 5.454s 10:38.84 98.8% 0+0k 0+0io 0pf+0w
      node021 658.252u 5.631s 11:07.37 99.4% 0+0k 0+0io 0pf+0w
      node021 640.074u 6.180s 10:53.15 98.9% 0+0k 0+0io 0pf+0w
      node021 676.709u 5.520s 11:29.73 98.9% 0+0k 0+0io 0pf+0w
      node021 662.521u 5.195s 11:13.47 99.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5241.89	 wallclock=5337.81
5242.018u 48.640s 11:54.12 740.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:22:11 ) 542.01user 7.67system 1:15.50elapsed 728%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:23:26 ) 59195.35user 98.28system 2:16:46elapsed 722%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:40:13 ) 10384.01user 9.40system 21:43.27elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 07:01:57 ) 0.130u 0.012s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 07:01:58 ) 0.354u 0.116s 0:00.48 95.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00286832998972
:CHARGE convergence:  0.0337484
>lapw0      ( 07:01:59 ) starting parallel lapw0 at Thu Feb  6 07:01:59 CST 2014
-------- .machine0 : 8 processors
10.696u 0.431s 0:09.49 117.1%	0+0k 0+0io 85pf+0w
>lapw1      ( 07:02:08 ) starting parallel lapw1 at Thu Feb  6 07:02:10 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 07:02:10 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 27321
[2] 27341
[3] 27360
[4] 27379
[5] 27398
[6] 27418
[7] 27437
[8] 27456
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 629.670u 2.571s 10:35.72 99.4%	0+0k 0+0io 0pf+0w
     node021(34) 614.755u 3.080s 10:20.68 99.5%	0+0k 0+0io 0pf+0w
     node021(34) 632.987u 2.431s 10:37.86 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 633.135u 2.858s 10:38.22 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 632.700u 2.957s 10:36.43 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 628.422u 3.179s 10:32.35 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 631.697u 2.906s 10:34.67 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 623.256u 3.367s 10:27.43 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=5026.62	 wallclock=5063.36
5026.970u 24.278s 10:43.79 784.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 07:12:52 ) running LAPWSO in parallel mode
[1] 28461
[2] 28467
[3] 28473
[4] 28479
[5] 28486
[6] 28492
[7] 28498
[8] 28504
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 644.104u 5.998s 10:57.15 98.9% 0+0k 0+0io 0pf+0w
      node021 683.399u 5.446s 11:35.23 99.0% 0+0k 0+0io 0pf+0w
      node021 661.047u 6.065s 11:10.97 99.4% 0+0k 0+0io 0pf+0w
      node021 676.831u 5.967s 11:28.94 99.1% 0+0k 0+0io 0pf+0w
      node021 645.630u 5.426s 10:52.84 99.7% 0+0k 0+0io 0pf+0w
      node021 649.150u 5.847s 10:59.54 99.3% 0+0k 0+0io 0pf+0w
      node021 657.576u 5.845s 11:13.18 98.5% 0+0k 0+0io 0pf+0w
      node021 667.932u 5.173s 11:15.56 99.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5285.67	 wallclock=5373.41
5285.792u 48.890s 11:39.40 762.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 07:24:32 ) 539.44user 7.78system 1:15.40elapsed 725%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 07:25:47 ) 68896.48user 119.91system 2:38:51elapsed 724%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 10:04:39 ) 10408.16user 9.12system 21:45.82elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 10:26:25 ) 0.135u 0.008s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 10:26:25 ) 0.349u 0.116s 0:00.46 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00790814007632
:CHARGE convergence:  0.0101073
>lapw0      ( 10:26:26 ) starting parallel lapw0 at Thu Feb  6 10:26:26 CST 2014
-------- .machine0 : 8 processors
10.325u 0.415s 0:03.53 303.9%	0+0k 0+0io 86pf+0w
>lapw1      ( 10:26:29 ) starting parallel lapw1 at Thu Feb  6 10:26:29 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 10:26:29 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 31288
[2] 31307
[3] 31326
[4] 31346
[5] 31365
[6] 31384
[7] 31403
[8] 31422
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 605.873u 3.132s 10:09.88 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 609.591u 3.164s 10:14.59 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 618.453u 2.517s 10:21.49 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 614.757u 3.106s 10:18.20 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 615.451u 3.186s 10:20.37 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 621.647u 3.211s 10:25.72 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 621.577u 3.026s 10:24.75 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 611.745u 3.268s 10:15.49 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4919.09	 wallclock=4950.49
4919.430u 25.515s 10:32.10 782.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 10:37:01 ) running LAPWSO in parallel mode
[1] 32406
[2] 32413
[3] 32419
[4] 32425
[5] 32431
[6] 32437
[7] 32444
[8] 32450
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 631.086u 5.412s 10:40.70 99.3% 0+0k 0+0io 0pf+0w
      node021 620.830u 5.594s 10:34.09 98.7% 0+0k 0+0io 0pf+0w
      node021 660.305u 6.038s 11:10.68 99.3% 0+0k 0+0io 0pf+0w
      node021 657.929u 5.973s 11:09.81 99.1% 0+0k 0+0io 0pf+0w
      node021 614.743u 5.723s 10:23.06 99.5% 0+0k 0+0io 0pf+0w
      node021 661.555u 5.824s 11:11.41 99.3% 0+0k 0+0io 0pf+0w
      node021 643.138u 5.492s 10:52.91 99.3% 0+0k 0+0io 0pf+0w
      node021 625.004u 5.684s 10:35.92 99.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5114.59	 wallclock=5198.58
5114.724u 48.827s 11:19.58 759.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 10:48:21 ) 540.29user 7.99system 1:14.72elapsed 733%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 10:49:36 ) 62050.01user 97.46system 2:24:05elapsed 718%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 13:13:42 ) 10371.58user 9.38system 21:39.94elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 13:35:22 ) 0.134u 0.011s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 13:35:23 ) 0.359u 0.106s 0:00.47 95.7%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00210269994568
:CHARGE convergence:  0.0026436
>lapw0      ( 13:35:23 ) starting parallel lapw0 at Thu Feb  6 13:35:23 CST 2014
-------- .machine0 : 8 processors
10.398u 0.387s 0:03.54 304.2%	0+0k 0+0io 82pf+0w
>lapw1      ( 13:35:27 ) starting parallel lapw1 at Thu Feb  6 13:35:27 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 13:35:27 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 2640
[2] 2660
[3] 2679
[4] 2698
[5] 2717
[6] 2736
[7] 2756
[8] 2775
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 616.746u 2.777s 10:19.60 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 624.396u 3.059s 10:28.03 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 627.564u 2.425s 10:30.46 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 628.103u 2.833s 10:31.29 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 629.460u 3.102s 10:34.90 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 625.075u 3.671s 10:30.67 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 614.947u 3.210s 10:18.39 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 625.407u 3.091s 10:28.62 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4991.7	 wallclock=5021.96
4992.045u 25.069s 10:40.21 783.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 13:46:07 ) running LAPWSO in parallel mode
[1] 3827
[2] 3834
[3] 3840
[4] 3846
[5] 3852
[6] 3858
[7] 3865
[8] 3871
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 610.893u 6.217s 10:27.99 98.2% 0+0k 0+0io 0pf+0w
      node021 600.249u 5.303s 10:11.30 99.0% 0+0k 0+0io 0pf+0w
      node021 627.506u 6.167s 10:40.02 99.0% 0+0k 0+0io 0pf+0w
      node021 635.116u 5.891s 10:47.68 98.9% 0+0k 0+0io 0pf+0w
      node021 658.237u 5.299s 11:06.42 99.5% 0+0k 0+0io 0pf+0w
      node021 628.524u 6.059s 10:41.23 98.9% 0+0k 0+0io 0pf+0w
      node021 615.805u 5.299s 10:22.99 99.6% 0+0k 0+0io 0pf+0w
      node021 623.571u 5.329s 10:31.56 99.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=4999.9	 wallclock=5089.19
5000.034u 48.713s 11:13.64 749.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 13:57:21 ) 541.69user 7.85system 1:14.69elapsed 735%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 13:58:35 ) 60264.50user 96.84system 2:21:05elapsed 713%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 16:19:41 ) 10352.76user 9.60system 21:39.09elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 16:41:20 ) 0.128u 0.013s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 16:41:41 ) 0.370u 0.098s 0:00.47 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000636660028249
:CHARGE convergence:  0.0055199
>lapw0      ( 16:41:41 ) starting parallel lapw0 at Thu Feb  6 16:41:42 CST 2014
-------- .machine0 : 8 processors
10.331u 0.406s 0:03.53 303.9%	0+0k 0+0io 86pf+0w
>lapw1      ( 16:41:45 ) starting parallel lapw1 at Thu Feb  6 16:41:48 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 16:41:48 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 6447
[2] 6466
[3] 6486
[4] 6505
[5] 6524
[6] 6543
[7] 6562
[8] 6582
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 606.834u 2.806s 10:10.20 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 617.991u 3.041s 10:21.36 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 618.222u 2.458s 10:20.75 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 612.434u 3.179s 10:15.81 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 615.956u 3.086s 10:21.20 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 602.320u 3.432s 10:06.67 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 613.494u 3.250s 10:17.56 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 611.785u 3.487s 10:16.22 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4899.04	 wallclock=4929.77
4899.373u 25.626s 10:26.52 786.0%	0+0k 0+0io 0pf+0w
>lapwso     ( 16:52:16 ) running LAPWSO in parallel mode
[1] 7556
[2] 7562
[3] 7568
[4] 7574
[5] 7581
[6] 7587
[7] 7593
[8] 7599
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 627.137u 5.569s 10:38.26 99.1% 0+0k 0+0io 0pf+0w
      node021 643.320u 6.045s 10:59.88 98.4% 0+0k 0+0io 0pf+0w
      node021 648.722u 5.972s 11:05.21 98.4% 0+0k 0+0io 0pf+0w
      node021 650.455u 5.884s 11:04.29 98.8% 0+0k 0+0io 0pf+0w
      node021 649.494u 5.856s 11:00.08 99.2% 0+0k 0+0io 0pf+0w
      node021 649.701u 5.488s 10:58.07 99.5% 0+0k 0+0io 0pf+0w
      node021 651.770u 5.697s 11:06.47 98.6% 0+0k 0+0io 0pf+0w
      node021 626.090u 5.575s 10:39.79 98.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5146.69	 wallclock=5252.05
5146.826u 49.219s 11:15.70 768.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 17:03:32 ) 539.78user 7.72system 1:14.38elapsed 736%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 17:04:46 ) 53366.17user 86.38system 2:04:09elapsed 717%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 19:08:56 ) 10390.73user 9.53system 21:47.15elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 19:30:43 ) 0.132u 0.009s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 19:30:43 ) 0.362u 0.111s 0:00.47 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.0007864900399
:CHARGE convergence:  0.0022321
>lapw0      ( 19:30:44 ) starting parallel lapw0 at Thu Feb  6 19:30:44 CST 2014
-------- .machine0 : 8 processors
10.405u 0.409s 0:03.55 304.2%	0+0k 0+0io 85pf+0w
>lapw1      ( 19:30:47 ) starting parallel lapw1 at Thu Feb  6 19:30:47 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 19:30:47 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 9948
[2] 9968
[3] 9987
[4] 10006
[5] 10025
[6] 10044
[7] 10064
[8] 10083
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 610.528u 2.822s 10:13.43 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 622.356u 3.056s 10:27.87 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 612.783u 2.545s 10:15.42 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 612.752u 3.027s 10:16.11 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 622.323u 3.146s 10:26.55 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 624.024u 3.142s 10:28.39 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 616.113u 3.472s 10:21.95 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 614.076u 2.995s 10:17.75 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4934.95	 wallclock=4967.47
4935.307u 25.112s 10:34.72 781.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 19:41:22 ) running LAPWSO in parallel mode
[1] 11076
[2] 11082
[3] 11089
[4] 11095
[5] 11101
[6] 11107
[7] 11113
[8] 11120
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 625.203u 5.772s 10:38.34 98.8% 0+0k 0+0io 0pf+0w
      node021 673.366u 5.557s 11:24.13 99.2% 0+0k 0+0io 0pf+0w
      node021 624.176u 5.483s 10:32.26 99.5% 0+0k 0+0io 0pf+0w
      node021 636.610u 6.224s 10:50.11 98.8% 0+0k 0+0io 0pf+0w
      node021 636.120u 5.582s 10:54.24 98.0% 0+0k 0+0io 0pf+0w
      node021 662.395u 5.702s 11:12.21 99.3% 0+0k 0+0io 0pf+0w
      node021 664.034u 5.450s 11:15.94 99.0% 0+0k 0+0io 0pf+0w
      node021 634.370u 5.324s 10:41.49 99.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5156.27	 wallclock=5248.72
5156.395u 48.290s 11:28.36 756.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 19:52:50 ) 541.95user 7.87system 1:15.04elapsed 732%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 19:54:05 ) 61819.27user 96.30system 2:24:26elapsed 714%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 22:18:32 ) 10366.45user 9.37system 21:40.55elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 22:40:13 ) 0.130u 0.015s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 22:40:13 ) 0.357u 0.114s 0:00.47 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.21799530461e-05
:CHARGE convergence:  0.0023237
>lapw0      ( 22:40:13 ) starting parallel lapw0 at Thu Feb  6 22:40:13 CST 2014
-------- .machine0 : 8 processors
10.792u 0.400s 0:03.60 310.8%	0+0k 0+0io 84pf+0w
>lapw1      ( 22:40:17 ) starting parallel lapw1 at Thu Feb  6 22:40:17 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 22:40:17 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 13745
[2] 13764
[3] 13783
[4] 13803
[5] 13822
[6] 13841
[7] 13860
[8] 13879
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 626.294u 3.503s 10:31.00 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 629.520u 2.861s 10:32.82 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 628.112u 2.376s 10:31.09 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 623.942u 2.932s 10:27.12 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 625.577u 3.043s 10:30.46 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 623.878u 3.181s 10:27.53 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 625.242u 3.050s 10:29.11 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 618.473u 3.047s 10:23.81 99.6%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=5001.04	 wallclock=5032.94
5001.392u 24.888s 10:36.46 789.7%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:50:54 ) running LAPWSO in parallel mode
[1] 14885
[2] 14891
[3] 14897
[4] 14904
[5] 14910
[6] 14916
[7] 14922
[8] 14928
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 619.973u 5.600s 10:33.85 98.6% 0+0k 0+0io 0pf+0w
      node021 614.035u 5.588s 10:22.73 99.4% 0+0k 0+0io 0pf+0w
      node021 616.403u 6.007s 10:33.49 98.2% 0+0k 0+0io 0pf+0w
      node021 650.870u 5.259s 10:59.65 99.4% 0+0k 0+0io 0pf+0w
      node021 637.679u 6.187s 10:49.60 99.1% 0+0k 0+0io 0pf+0w
      node021 650.362u 5.578s 11:00.79 99.2% 0+0k 0+0io 0pf+0w
      node021 660.151u 5.701s 11:12.45 99.0% 0+0k 0+0io 0pf+0w
      node021 638.550u 5.659s 10:51.35 98.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5088.02	 wallclock=5183.91
5088.147u 48.696s 11:21.64 753.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 23:02:15 ) 542.41user 7.66system 1:15.92elapsed 724%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 23:03:31 ) 59735.98user 95.46system 2:18:55elapsed 717%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:22:27 ) 10414.71user 9.37system 21:46.33elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:44:13 ) 0.127u 0.013s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 01:44:14 ) 0.378u 0.098s 0:00.48 95.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00035653996747
:CHARGE convergence:  0.0042103
>lapw0      ( 01:44:14 ) starting parallel lapw0 at Fri Feb  7 01:44:14 CST 2014
-------- .machine0 : 8 processors
10.725u 0.379s 0:03.58 309.7%	0+0k 0+0io 83pf+0w
>lapw1      ( 01:44:18 ) starting parallel lapw1 at Fri Feb  7 01:44:27 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 01:44:27 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 17468
[2] 17487
[3] 17507
[4] 17526
[5] 17546
[6] 17566
[7] 17585
[8] 17604
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 621.477u 2.693s 10:26.41 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 629.650u 2.999s 10:32.88 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 607.655u 2.488s 10:10.26 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 611.514u 3.812s 10:15.64 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 617.191u 2.913s 10:21.38 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 624.997u 3.110s 10:29.81 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 623.722u 3.036s 10:27.34 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 621.141u 2.984s 10:24.54 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4957.35	 wallclock=4988.26
4957.664u 24.974s 10:36.14 783.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:55:03 ) running LAPWSO in parallel mode
[1] 18600
[2] 18607
[3] 18613
[4] 18619
[5] 18625
[6] 18631
[7] 18638
[8] 18644
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 642.645u 6.287s 10:57.79 98.6% 0+0k 0+0io 0pf+0w
      node021 647.519u 5.546s 10:56.10 99.5% 0+0k 0+0io 0pf+0w
      node021 660.404u 5.885s 11:14.23 98.8% 0+0k 0+0io 0pf+0w
      node021 659.402u 5.510s 11:10.47 99.1% 0+0k 0+0io 0pf+0w
      node021 662.434u 5.983s 11:12.34 99.4% 0+0k 0+0io 0pf+0w
      node021 653.822u 5.748s 11:01.94 99.6% 0+0k 0+0io 0pf+0w
      node021 660.623u 5.293s 11:08.26 99.6% 0+0k 0+0io 0pf+0w
      node021 659.462u 5.953s 11:12.60 98.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5246.31	 wallclock=5333.73
5246.433u 49.417s 11:23.04 775.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:06:26 ) 540.26user 7.84system 1:17.67elapsed 705%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:07:44 ) 61422.93user 108.79system 2:23:17elapsed 715%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:31:02 ) 10400.15user 9.47system 21:44.51elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:52:46 ) 0.132u 0.010s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 04:52:46 ) 0.352u 0.122s 0:00.47 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000658040051349
:CHARGE convergence:  0.0012349
>lapw0      ( 04:52:47 ) starting parallel lapw0 at Fri Feb  7 04:52:47 CST 2014
-------- .machine0 : 8 processors
10.445u 0.409s 0:03.54 306.2%	0+0k 0+0io 84pf+0w
>lapw1      ( 04:52:51 ) starting parallel lapw1 at Fri Feb  7 04:52:54 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 04:52:54 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 21701
[2] 21720
[3] 21740
[4] 21759
[5] 21778
[6] 21797
[7] 21816
[8] 21836
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 624.253u 2.726s 10:27.50 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 607.868u 3.537s 10:12.31 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 621.912u 2.546s 10:24.64 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 622.858u 2.950s 10:26.25 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 621.242u 3.112s 10:25.52 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 620.370u 3.115s 10:25.35 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 620.186u 3.034s 10:23.36 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 617.490u 2.955s 10:21.25 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4956.18	 wallclock=4986.18
4956.519u 24.862s 10:32.97 786.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 05:03:27 ) running LAPWSO in parallel mode
[1] 22826
[2] 22832
[3] 22839
[4] 22845
[5] 22851
[6] 22857
[7] 22863
[8] 22870
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 623.971u 6.195s 10:36.34 99.0% 0+0k 0+0io 0pf+0w
      node021 649.647u 5.315s 11:00.53 99.1% 0+0k 0+0io 0pf+0w
      node021 624.354u 6.214s 10:34.41 99.3% 0+0k 0+0io 0pf+0w
      node021 626.690u 5.590s 10:36.07 99.4% 0+0k 0+0io 0pf+0w
      node021 660.955u 5.695s 11:13.78 98.9% 0+0k 0+0io 0pf+0w
      node021 661.769u 5.620s 11:11.18 99.4% 0+0k 0+0io 0pf+0w
      node021 657.286u 5.274s 11:10.30 98.8% 0+0k 0+0io 0pf+0w
      node021 628.015u 5.224s 10:35.51 99.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5132.69	 wallclock=5218.12
5132.803u 48.321s 11:21.04 760.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 05:14:48 ) 541.36user 8.00system 1:15.86elapsed 724%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 05:16:04 ) 61647.30user 95.46system 2:23:02elapsed 719%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 07:39:07 ) 10366.61user 9.41system 21:39.74elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 08:00:47 ) 0.131u 0.010s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 08:00:47 ) 0.356u 0.123s 0:00.48 97.9%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000226279953495
:CHARGE convergence:  0.0001967
>lapw0      ( 08:00:47 ) starting parallel lapw0 at Fri Feb  7 08:00:48 CST 2014
-------- .machine0 : 8 processors
10.483u 0.413s 0:03.55 306.7%	0+0k 0+0io 88pf+0w
>lapw1      ( 08:00:51 ) starting parallel lapw1 at Fri Feb  7 08:00:51 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 08:00:51 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 25444
[2] 25464
[3] 25483
[4] 25502
[5] 25521
[6] 25540
[7] 25560
[8] 25579
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 608.709u 2.710s 10:11.50 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 625.524u 2.946s 10:29.07 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 620.469u 2.971s 10:24.24 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 608.584u 3.202s 10:14.26 99.5%	0+0k 0+0io 0pf+0w
     node021(34) 619.461u 2.994s 10:23.81 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 619.881u 3.026s 10:24.62 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 616.888u 3.287s 10:21.45 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 615.889u 3.135s 10:19.80 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4935.41	 wallclock=4968.75
4935.739u 25.190s 10:31.36 785.7%	0+0k 0+0io 0pf+0w
>lapwso     ( 08:11:23 ) running LAPWSO in parallel mode
[1] 26577
[2] 26584
[3] 26590
[4] 26596
[5] 26602
[6] 26608
[7] 26615
[8] 26621
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 633.502u 5.856s 10:47.10 98.8% 0+0k 0+0io 0pf+0w
      node021 693.442u 5.443s 11:42.34 99.5% 0+0k 0+0io 0pf+0w
      node021 635.392u 5.692s 10:41.94 99.8% 0+0k 0+0io 0pf+0w
      node021 640.496u 5.710s 10:51.82 99.1% 0+0k 0+0io 0pf+0w
      node021 688.139u 5.936s 11:41.73 98.9% 0+0k 0+0io 0pf+0w
      node021 664.597u 5.702s 11:13.85 99.4% 0+0k 0+0io 0pf+0w
      node021 660.547u 5.554s 11:12.78 99.0% 0+0k 0+0io 0pf+0w
      node021 664.243u 5.221s 11:12.04 99.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5280.36	 wallclock=5363.6
5280.485u 48.272s 11:49.04 751.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 08:23:12 ) 542.21user 7.94system 1:15.92elapsed 724%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 08:24:28 ) 52694.07user 85.38system 2:02:16elapsed 719%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 10:26:44 ) 10353.09user 9.39system 21:38.61elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 10:48:23 ) 0.138u 0.008s 0:00.16 81.2%	0+0k 0+0io 0pf+0w
>mixer      ( 10:48:23 ) 0.361u 0.115s 0:00.47 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.0659994334e-05
:CHARGE convergence:  0.0001815
>lapw0      ( 10:48:24 ) starting parallel lapw0 at Fri Feb  7 10:48:24 CST 2014
-------- .machine0 : 8 processors
10.694u 0.382s 0:03.59 308.3%	0+0k 0+0io 87pf+0w
>lapw1      ( 10:48:27 ) starting parallel lapw1 at Fri Feb  7 10:48:27 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 10:48:27 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 28952
[2] 28971
[3] 28990
[4] 29009
[5] 29029
[6] 29048
[7] 29067
[8] 29086
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 611.112u 3.024s 10:14.57 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 628.230u 3.022s 10:32.60 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 629.614u 2.467s 10:33.68 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 609.924u 3.188s 10:13.17 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 626.677u 3.356s 10:32.01 99.6%	0+0k 0+0io 0pf+0w
     node021(34) 616.307u 3.347s 10:21.29 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 625.058u 3.013s 10:28.18 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 605.764u 3.166s 10:09.31 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4952.69	 wallclock=4984.81
4953.021u 25.487s 10:37.32 781.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 10:59:05 ) running LAPWSO in parallel mode
[1] 30078
[2] 30084
[3] 30090
[4] 30096
[5] 30103
[6] 30109
[7] 30115
[8] 30121
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 606.426u 5.495s 10:14.93 99.5% 0+0k 0+0io 0pf+0w
      node021 640.297u 6.534s 11:00.18 97.9% 0+0k 0+0io 0pf+0w
      node021 642.610u 5.768s 10:56.32 98.7% 0+0k 0+0io 0pf+0w
      node021 639.807u 5.511s 10:48.23 99.5% 0+0k 0+0io 0pf+0w
      node021 618.161u 5.599s 10:28.74 99.2% 0+0k 0+0io 0pf+0w
      node021 642.955u 5.610s 10:54.63 99.0% 0+0k 0+0io 0pf+0w
      node021 636.267u 5.150s 10:44.01 99.5% 0+0k 0+0io 0pf+0w
      node021 647.828u 5.530s 10:59.26 99.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5074.35	 wallclock=5166.3
5074.475u 48.425s 11:09.57 765.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 11:10:14 ) 541.78user 7.88system 1:14.54elapsed 737%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 11:11:29 ) 51667.19user 85.44system 1:58:43elapsed 726%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 13:10:13 ) 10351.51user 9.27system 21:38.28elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 13:31:51 ) 0.132u 0.009s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 13:31:51 ) 0.360u 0.117s 0:00.48 97.9%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  7.38899689168e-05
:CHARGE convergence:  0.0001566
>lapw0      ( 13:31:52 ) starting parallel lapw0 at Fri Feb  7 13:31:52 CST 2014
-------- .machine0 : 8 processors
10.504u 0.404s 0:03.55 307.0%	0+0k 0+0io 83pf+0w
>lapw1      ( 13:31:56 ) starting parallel lapw1 at Fri Feb  7 13:31:56 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 13:31:56 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 32404
[2] 32423
[3] 32442
[4] 32461
[5] 32481
[6] 32500
[7] 32519
[8] 32538
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 604.988u 2.904s 10:09.67 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 630.919u 2.934s 10:34.21 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 623.908u 2.522s 10:28.09 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 618.103u 3.093s 10:21.33 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 626.103u 3.784s 10:30.35 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 625.344u 2.952s 10:28.83 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 617.319u 3.087s 10:21.24 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 613.805u 3.011s 10:17.17 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4960.49	 wallclock=4990.89
4960.821u 25.200s 10:36.47 783.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 13:42:32 ) running LAPWSO in parallel mode
[1] 1114
[2] 1120
[3] 1126
[4] 1134
[5] 1140
[6] 1146
[7] 1152
[8] 1158
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 641.857u 6.260s 10:55.90 98.8% 0+0k 0+0io 0pf+0w
      node021 621.829u 6.222s 10:39.72 98.1% 0+0k 0+0io 0pf+0w
      node021 666.307u 5.939s 11:20.25 98.8% 0+0k 0+0io 0pf+0w
      node021 618.859u 5.315s 10:27.07 99.5% 0+0k 0+0io 0pf+0w
      node021 639.067u 5.319s 10:46.26 99.7% 0+0k 0+0io 0pf+0w
      node021 646.940u 5.882s 11:02.31 98.5% 0+0k 0+0io 0pf+0w
      node021 654.151u 5.462s 11:04.20 99.3% 0+0k 0+0io 0pf+0w
      node021 615.987u 5.573s 10:28.89 98.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5105	 wallclock=5204.6
5105.129u 49.123s 11:25.47 751.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 13:53:58 ) 544.32user 7.84system 1:14.86elapsed 737%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 13:55:13 ) 51271.30user 92.35system 1:59:08elapsed 718%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 15:54:21 ) 10363.44user 9.24system 26:44.61elapsed 646%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 16:21:06 ) 0.124u 0.014s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 16:21:06 ) 0.357u 0.125s 0:00.48 97.9%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  8.58200946823e-05
:CHARGE convergence:  0.0002984
>lapw0      ( 16:21:07 ) starting parallel lapw0 at Fri Feb  7 16:21:07 CST 2014
-------- .machine0 : 8 processors
10.382u 0.417s 0:03.54 304.8%	0+0k 0+0io 84pf+0w
>lapw1      ( 16:21:10 ) starting parallel lapw1 at Fri Feb  7 16:21:11 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 16:21:11 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 3569
[2] 3596
[3] 3616
[4] 3636
[5] 3655
[6] 3683
[7] 3703
[8] 3723
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 625.906u 3.390s 10:30.65 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 615.369u 3.186s 10:19.29 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 625.825u 2.483s 10:28.39 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 625.352u 3.189s 10:29.39 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 628.369u 3.091s 10:34.13 99.5%	0+0k 0+0io 0pf+0w
     node021(34) 623.873u 3.061s 10:27.40 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 614.375u 3.136s 10:17.57 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 613.007u 3.179s 10:16.55 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4972.08	 wallclock=5003.37
4972.403u 25.644s 10:39.44 781.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 16:31:50 ) running LAPWSO in parallel mode
[1] 4747
[2] 4753
[3] 4760
[4] 4766
[5] 4772
[6] 4778
[7] 4784
[8] 4791
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 619.322u 6.190s 10:32.63 98.8% 0+0k 0+0io 0pf+0w
      node021 609.921u 5.442s 10:21.20 99.0% 0+0k 0+0io 0pf+0w
      node021 641.246u 6.110s 10:52.81 99.1% 0+0k 0+0io 0pf+0w
      node021 636.887u 5.951s 10:48.48 99.1% 0+0k 0+0io 0pf+0w
      node021 638.977u 5.741s 10:54.91 98.4% 0+0k 0+0io 0pf+0w
      node021 659.744u 5.473s 11:06.78 99.7% 0+0k 0+0io 0pf+0w
      node021 644.316u 5.266s 10:51.89 99.6% 0+0k 0+0io 0pf+0w
      node021 643.940u 5.558s 10:54.35 99.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5094.35	 wallclock=5183.05
5094.466u 48.886s 11:15.00 761.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 16:43:05 ) 540.21user 7.65system 5:32.92elapsed 164%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 16:48:38 ) 52631.32user 87.37system 2:03:29elapsed 711%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 18:52:07 ) 10342.65user 9.26system 25:39.00elapsed 672%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 19:17:46 ) 0.127u 0.014s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 19:17:46 ) 0.368u 0.111s 0:00.48 97.9%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  4.38700662926e-05
:CHARGE convergence:  0.0001807
>lapw0      ( 19:17:47 ) starting parallel lapw0 at Fri Feb  7 19:17:47 CST 2014
-------- .machine0 : 8 processors
10.419u 0.382s 0:03.54 304.8%	0+0k 0+0io 88pf+0w
>lapw1      ( 19:17:51 ) starting parallel lapw1 at Fri Feb  7 19:17:51 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 19:17:51 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 7221
[2] 7240
[3] 7259
[4] 7278
[5] 7297
[6] 7317
[7] 7336
[8] 7355
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 601.492u 2.904s 10:04.89 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 611.609u 3.244s 10:16.66 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 622.789u 2.476s 10:26.11 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 612.666u 3.135s 10:16.43 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 624.750u 3.019s 10:28.36 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 621.697u 3.705s 10:25.76 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 602.857u 3.086s 10:06.58 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 603.665u 3.169s 10:07.62 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4901.53	 wallclock=4932.41
4901.864u 25.641s 10:33.67 777.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 19:28:24 ) running LAPWSO in parallel mode
[1] 8389
[2] 8395
[3] 8401
[4] 8408
[5] 8414
[6] 8420
[7] 8426
[8] 8432
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 665.510u 5.251s 11:13.34 99.6% 0+0k 0+0io 0pf+0w
      node021 623.992u 5.590s 10:34.94 99.1% 0+0k 0+0io 0pf+0w
      node021 634.797u 5.864s 10:45.61 99.2% 0+0k 0+0io 0pf+0w
      node021 663.616u 6.406s 11:15.61 99.1% 0+0k 0+0io 0pf+0w
      node021 653.652u 5.883s 11:08.20 98.7% 0+0k 0+0io 0pf+0w
      node021 632.392u 5.417s 10:41.83 99.3% 0+0k 0+0io 0pf+0w
      node021 649.793u 5.455s 10:59.85 99.3% 0+0k 0+0io 0pf+0w
      node021 648.715u 5.422s 11:00.20 99.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5172.47	 wallclock=5259.58
5172.591u 48.513s 11:21.88 765.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 19:43:46 ) 544.54user 8.01system 1:14.19elapsed 744%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 19:45:01 ) 44983.60user 74.04system 1:46:00elapsed 708%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 21:31:01 ) 10351.88user 9.68system 21:38.74elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 21:52:40 ) 0.128u 0.011s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 21:52:40 ) 0.345u 0.130s 0:00.48 97.9%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  3.22100240737e-05
:CHARGE convergence:  5.89e-05
>lapw0      ( 21:52:41 ) starting parallel lapw0 at Fri Feb  7 21:52:41 CST 2014
-------- .machine0 : 8 processors
10.362u 0.422s 0:03.54 304.5%	0+0k 0+0io 82pf+0w
>lapw1      ( 21:52:44 ) starting parallel lapw1 at Fri Feb  7 21:52:45 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 21:52:45 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 10556
[2] 10575
[3] 10595
[4] 10614
[5] 10633
[6] 10652
[7] 10671
[8] 10691
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 622.252u 2.794s 10:25.12 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 625.660u 3.051s 10:29.69 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 607.294u 2.577s 10:10.01 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 622.510u 2.878s 10:25.82 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 619.232u 3.673s 10:24.58 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 614.486u 3.076s 10:18.64 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 621.324u 3.050s 10:26.08 99.7%	0+0k 0+0io 0pf+0w
     node021(34) 616.602u 3.046s 10:20.50 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4949.36	 wallclock=4980.44
4949.687u 25.077s 10:33.42 785.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:03:18 ) running LAPWSO in parallel mode
[1] 11691
[2] 11698
[3] 11704
[4] 11710
[5] 11716
[6] 11722
[7] 11729
[8] 11735
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 631.524u 6.583s 10:41.19 99.5% 0+0k 0+0io 0pf+0w
      node021 665.219u 5.277s 11:15.57 99.2% 0+0k 0+0io 0pf+0w
      node021 630.508u 6.569s 10:41.31 99.3% 0+0k 0+0io 0pf+0w
      node021 654.848u 5.480s 11:07.28 98.9% 0+0k 0+0io 0pf+0w
      node021 646.492u 5.380s 10:54.99 99.5% 0+0k 0+0io 0pf+0w
      node021 643.357u 5.714s 10:55.21 99.0% 0+0k 0+0io 0pf+0w
      node021 675.735u 5.355s 11:23.07 99.7% 0+0k 0+0io 0pf+0w
      node021 629.490u 5.138s 10:36.80 99.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5177.17	 wallclock=5255.42
5177.302u 48.728s 11:32.37 754.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:14:50 ) 543.46user 7.96system 1:16.04elapsed 725%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:16:06 ) 52536.80user 91.35system 2:04:30elapsed 704%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:20:37 ) 10374.18user 9.74system 21:41.92elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:42:19 ) 0.132u 0.013s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 00:44:24 ) 0.311u 0.107s 0:01.44 28.4%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.23700189963e-05
:CHARGE convergence:  1.7e-05
>lapw0      ( 00:44:47 ) starting parallel lapw0 at Sat Feb  8 00:46:21 CST 2014
-------- .machine0 : 8 processors
10.528u 0.405s 0:06.55 166.7%	0+0k 0+0io 89pf+0w
>lapw1      ( 00:46:27 ) starting parallel lapw1 at Sat Feb  8 00:46:27 CST 2014
->  starting parallel LAPW1 jobs at Sat Feb  8 00:46:28 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 14253
[2] 14272
[3] 14291
[4] 14310
[5] 14329
[6] 14349
[7] 14368
[8] 14387
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node021(34) 605.709u 2.767s 10:08.59 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 626.804u 2.987s 10:30.35 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 624.968u 2.378s 10:27.58 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 626.753u 3.016s 10:30.29 99.9%	0+0k 0+0io 0pf+0w
     node021(34) 623.722u 3.686s 10:28.48 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 601.257u 3.315s 10:07.11 99.5%	0+0k 0+0io 0pf+0w
     node021(34) 611.002u 3.121s 10:14.98 99.8%	0+0k 0+0io 0pf+0w
     node021(34) 612.509u 2.992s 10:15.87 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node021	 k=272	 user=4932.72	 wallclock=4963.25
4933.064u 25.151s 10:35.15 780.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 00:57:03 ) running LAPWSO in parallel mode
[1] 15371
[2] 15378
[3] 15384
[4] 15390
[5] 15396
[6] 15402
[7] 15409
[8] 15415
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node021 624.402u 5.775s 10:35.62 99.1% 0+0k 0+0io 0pf+0w
      node021 625.396u 5.649s 10:38.65 98.8% 0+0k 0+0io 0pf+0w
      node021 630.658u 6.233s 10:47.66 98.3% 0+0k 0+0io 0pf+0w
      node021 630.003u 5.763s 10:42.66 98.9% 0+0k 0+0io 0pf+0w
      node021 633.006u 5.625s 10:41.54 99.5% 0+0k 0+0io 0pf+0w
      node021 616.090u 5.499s 10:26.27 99.2% 0+0k 0+0io 0pf+0w
      node021 632.269u 5.306s 10:44.97 98.8% 0+0k 0+0io 0pf+0w
      node021 626.432u 5.607s 10:38.53 98.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node021	 user=5018.26	 wallclock=5115.9
5018.380u 48.669s 10:54.26 774.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:07:57 ) 538.57user 7.62system 1:16.07elapsed 718%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:09:13 ) 51258.58user 94.09system 1:59:01elapsed 719%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:08:18 ) 10382.62user 9.35system 21:46.71elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:30:05 ) 0.131u 0.011s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 03:30:05 ) 0.326u 0.101s 0:00.43 97.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  3.55998054147e-06
:CHARGE convergence:  0.0001039
