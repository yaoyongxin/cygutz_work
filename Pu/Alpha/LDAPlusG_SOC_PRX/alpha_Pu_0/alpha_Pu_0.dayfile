Calculating alpha_Pu_0 in /scratch/ykent33891/alpha_Pu_0
on node030 with PID 3993




   start        Tue Feb  4 21:15:30 2014 with lapw0 (1/100 to go)

   cycle 0 	Tue Feb  4 21:15:30 2014 1000/0 to go

>lapw0      ( 21:15:30 ) starting parallel lapw0 at Tue Feb  4 21:15:31 CST 2014
-------- .machine0 : 8 processors
10.122u 0.411s 0:06.96 151.2%	0+0k 0+0io 86pf+0w
>lapw1      ( 21:15:38 ) starting parallel lapw1 at Tue Feb  4 21:15:47 CST 2014
->  starting parallel LAPW1 jobs at Tue Feb  4 21:15:47 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 4238
[2] 4257
[3] 4276
[4] 4296
[5] 4315
[6] 4334
[7] 4353
[8] 4372
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 468.556u 2.404s 7:51.26 99.9%	0+0k 0+0io 1pf+0w
     node030(34) 465.931u 2.355s 7:48.63 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 460.979u 2.392s 7:43.73 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 464.170u 2.579s 7:47.95 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 463.302u 2.489s 7:46.86 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 457.735u 2.467s 7:41.67 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 455.517u 2.405s 7:38.78 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 455.478u 2.474s 7:38.18 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3691.67	 wallclock=3717.06
3691.947u 20.345s 7:52.49 785.6%	0+0k 0+0io 1pf+0w
>lapwso     ( 21:23:39 ) running LAPWSO in parallel mode
[1] 5183
[2] 5189
[3] 5195
[4] 5202
[5] 5208
[6] 5214
[7] 5220
[8] 5226
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 479.342u 3.812s 8:06.80 99.2% 0+0k 0+0io 1pf+0w
      node030 488.128u 3.479s 8:14.16 99.4% 0+0k 0+0io 0pf+0w
      node030 497.195u 3.923s 8:29.63 98.3% 0+0k 0+0io 0pf+0w
      node030 495.114u 3.733s 8:22.14 99.3% 0+0k 0+0io 0pf+0w
      node030 482.301u 3.822s 8:13.27 98.5% 0+0k 0+0io 0pf+0w
      node030 481.491u 3.874s 8:13.15 98.4% 0+0k 0+0io 0pf+0w
      node030 476.306u 3.632s 8:04.29 99.0% 0+0k 0+0io 0pf+0w
      node030 477.613u 4.174s 8:07.25 98.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3877.49	 wallclock=3950.69
3877.612u 30.728s 8:32.65 762.3%	0+0k 0+0io 1pf+0w
>dmft1      ( 21:32:12 ) 463.99user 6.11system 1:09.35elapsed 677%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 21:33:21 ) 64845.10user 95.78system 2:27:25elapsed 734%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:00:47 ) 10078.92user 9.01system 21:15.92elapsed 790%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:22:03 ) 0.135u 0.014s 0:00.20 70.0%	0+0k 0+0io 1pf+0w
>mixer      ( 00:22:03 ) 0.287u 0.111s 0:00.66 59.0%	0+0k 0+0io 6pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0279217
>lapw0      ( 00:22:04 ) starting parallel lapw0 at Wed Feb  5 00:22:04 CST 2014
-------- .machine0 : 8 processors
9.922u 0.429s 0:03.65 283.2%	0+0k 0+0io 102pf+0w
>lapw1      ( 00:22:08 ) starting parallel lapw1 at Wed Feb  5 00:22:08 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 00:22:08 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 7845
[2] 7864
[3] 7883
[4] 7902
[5] 7922
[6] 7941
[7] 7960
[8] 7979
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 460.915u 2.689s 7:43.91 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 460.817u 3.040s 7:44.98 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 459.789u 2.669s 7:43.30 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 462.388u 2.618s 7:46.10 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 462.204u 2.523s 7:44.86 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 456.135u 2.466s 7:38.75 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 459.568u 2.524s 7:43.13 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 458.013u 2.671s 7:40.89 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3679.83	 wallclock=3705.92
3680.099u 21.994s 7:51.81 784.6%	0+0k 0+0io 19pf+0w
>lapwso     ( 00:30:00 ) running LAPWSO in parallel mode
[1] 8783
[2] 8789
[3] 8795
[4] 8802
[5] 8808
[6] 8814
[7] 8820
[8] 8827
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 515.774u 4.154s 8:47.75 98.5% 0+0k 0+0io 0pf+0w
      node030 500.017u 3.883s 8:28.21 99.1% 0+0k 0+0io 0pf+0w
      node030 477.472u 3.889s 8:03.56 99.5% 0+0k 0+0io 0pf+0w
      node030 530.048u 4.084s 8:59.62 98.9% 0+0k 0+0io 0pf+0w
      node030 476.872u 3.977s 8:03.52 99.4% 0+0k 0+0io 0pf+0w
      node030 499.792u 3.643s 8:28.78 98.9% 0+0k 0+0io 0pf+0w
      node030 517.947u 3.915s 8:44.44 99.5% 0+0k 0+0io 0pf+0w
      node030 521.924u 4.105s 8:56.04 98.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=4039.85	 wallclock=4111.92
4039.952u 34.227s 9:07.62 743.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:39:07 ) 466.52user 6.41system 1:07.18elapsed 703%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:40:15 ) 60397.89user 87.36system 2:20:26elapsed 717%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:00:41 ) 9361.37user 8.50system 19:37.80elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:20:19 ) 0.138u 0.006s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 03:20:20 ) 0.293u 0.102s 0:01.06 36.7%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000745719997212
:CHARGE convergence:  0.0281222
>lapw0      ( 03:20:22 ) starting parallel lapw0 at Wed Feb  5 03:20:23 CST 2014
-------- .machine0 : 8 processors
9.892u 0.398s 0:04.89 210.2%	0+0k 0+0io 84pf+0w
>lapw1      ( 03:20:28 ) starting parallel lapw1 at Wed Feb  5 03:20:28 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 03:20:28 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 11327
[2] 11346
[3] 11366
[4] 11385
[5] 11404
[6] 11423
[7] 11442
[8] 11462
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 458.119u 2.749s 7:41.42 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 451.543u 2.701s 7:34.74 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 443.822u 3.141s 7:27.78 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 455.646u 2.598s 7:38.35 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 458.767u 2.673s 7:41.57 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 447.280u 2.703s 7:31.38 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 444.540u 2.697s 7:27.98 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 455.537u 2.628s 7:38.60 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3615.25	 wallclock=3641.82
3615.545u 22.638s 7:46.98 779.0%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:28:15 ) running LAPWSO in parallel mode
[1] 12261
[2] 12268
[3] 12274
[4] 12280
[5] 12286
[6] 12292
[7] 12299
[8] 12305
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 463.991u 4.090s 7:54.01 98.7% 0+0k 0+0io 0pf+0w
      node030 477.534u 3.662s 8:06.07 98.9% 0+0k 0+0io 0pf+0w
      node030 467.796u 3.833s 7:57.03 98.8% 0+0k 0+0io 0pf+0w
      node030 467.779u 3.789s 7:55.41 99.1% 0+0k 0+0io 0pf+0w
      node030 472.542u 4.696s 8:07.31 97.9% 0+0k 0+0io 0pf+0w
      node030 468.405u 3.654s 7:59.13 98.5% 0+0k 0+0io 0pf+0w
      node030 495.087u 3.940s 8:24.94 98.8% 0+0k 0+0io 0pf+0w
      node030 478.013u 4.133s 8:09.14 98.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3791.15	 wallclock=3873.04
3791.264u 34.433s 8:35.74 741.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:36:57 ) 466.86user 6.56system 1:08.36elapsed 692%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:38:06 ) 61653.20user 98.17system 2:16:44elapsed 752%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:54:50 ) 9336.11user 8.49system 19:30.08elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:14:20 ) 0.129u 0.012s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 06:14:21 ) 0.295u 0.109s 0:00.40 97.5%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00812665000558
:CHARGE convergence:  0.0481587
>lapw0      ( 06:14:21 ) starting parallel lapw0 at Wed Feb  5 06:14:21 CST 2014
-------- .machine0 : 8 processors
9.867u 0.403s 0:03.50 293.1%	0+0k 0+0io 86pf+0w
>lapw1      ( 06:14:25 ) starting parallel lapw1 at Wed Feb  5 06:14:26 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 06:14:26 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 15234
[2] 15253
[3] 15273
[4] 15292
[5] 15311
[6] 15330
[7] 15349
[8] 15369
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 466.263u 2.584s 7:50.74 99.5%	0+0k 0+0io 0pf+0w
     node030(34) 463.606u 2.738s 7:49.72 99.2%	0+0k 0+0io 0pf+0w
     node030(34) 464.166u 2.570s 7:48.52 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 460.965u 2.713s 7:45.87 99.5%	0+0k 0+0io 0pf+0w
     node030(34) 461.410u 2.508s 7:45.63 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 459.689u 2.573s 7:43.38 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 460.083u 2.733s 7:44.71 99.5%	0+0k 0+0io 0pf+0w
     node030(34) 455.921u 2.842s 7:42.63 99.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3692.1	 wallclock=3731.2
3692.401u 21.970s 7:52.85 785.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 06:22:18 ) running LAPWSO in parallel mode
[1] 16130
[2] 16136
[3] 16142
[4] 16149
[5] 16155
[6] 16161
[7] 16167
[8] 16174
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 485.574u 3.729s 8:14.97 98.8% 0+0k 0+0io 0pf+0w
      node030 477.462u 3.631s 8:04.43 99.3% 0+0k 0+0io 0pf+0w
      node030 481.856u 3.900s 8:09.50 99.2% 0+0k 0+0io 0pf+0w
      node030 490.838u 3.947s 8:21.08 98.7% 0+0k 0+0io 0pf+0w
      node030 497.100u 4.287s 8:31.44 98.0% 0+0k 0+0io 0pf+0w
      node030 477.928u 4.007s 8:05.96 99.1% 0+0k 0+0io 0pf+0w
      node030 483.627u 3.863s 8:12.55 98.9% 0+0k 0+0io 0pf+0w
      node030 473.653u 4.110s 8:05.33 98.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3868.04	 wallclock=3945.26
3868.158u 34.138s 8:38.97 751.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 06:31:00 ) 464.02user 6.64system 1:09.75elapsed 674%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 06:32:10 ) 60566.48user 103.74system 2:15:21elapsed 747%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 08:47:31 ) 9346.22user 8.50system 19:31.35elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 09:07:03 ) 0.132u 0.011s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 09:07:03 ) 0.302u 0.117s 0:00.42 97.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.0109489399474
:CHARGE convergence:  0.0164581
>lapw0      ( 09:07:05 ) starting parallel lapw0 at Wed Feb  5 09:07:06 CST 2014
-------- .machine0 : 8 processors
9.908u 0.407s 0:13.25 77.7%	0+0k 0+0io 82pf+0w
>lapw1      ( 09:07:19 ) starting parallel lapw1 at Wed Feb  5 09:07:26 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 09:07:26 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 18589
[2] 18608
[3] 18627
[4] 18646
[5] 18665
[6] 18685
[7] 18704
[8] 18723
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 450.664u 2.640s 7:34.05 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 453.420u 2.561s 7:36.50 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 445.940u 3.227s 7:29.27 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 448.840u 2.604s 7:33.67 99.5%	0+0k 0+0io 0pf+0w
     node030(34) 448.009u 2.646s 7:34.16 99.2%	0+0k 0+0io 0pf+0w
     node030(34) 446.429u 2.608s 7:34.43 98.8%	0+0k 0+0io 0pf+0w
     node030(34) 451.413u 2.702s 7:38.68 99.0%	0+0k 0+0io 0pf+0w
     node030(34) 454.618u 2.679s 7:42.10 98.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3599.33	 wallclock=3642.86
3599.596u 22.458s 7:50.46 769.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 09:15:16 ) running LAPWSO in parallel mode
[1] 19522
[2] 19529
[3] 19535
[4] 19541
[5] 19547
[6] 19553
[7] 19560
[8] 19566
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 479.990u 4.012s 8:10.06 98.7% 0+0k 0+0io 0pf+0w
      node030 492.315u 3.718s 8:17.02 99.7% 0+0k 0+0io 0pf+0w
      node030 505.417u 3.958s 8:34.59 98.9% 0+0k 0+0io 0pf+0w
      node030 504.720u 3.865s 8:34.99 98.7% 0+0k 0+0io 0pf+0w
      node030 496.646u 3.846s 8:25.60 98.9% 0+0k 0+0io 0pf+0w
      node030 490.106u 4.169s 8:18.58 99.1% 0+0k 0+0io 0pf+0w
      node030 501.533u 4.217s 8:32.62 98.6% 0+0k 0+0io 0pf+0w
      node030 482.051u 3.794s 8:10.91 98.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3952.78	 wallclock=4024.37
3952.920u 34.264s 8:42.04 763.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 09:24:02 ) 463.50user 6.57system 1:15.59elapsed 621%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 09:25:18 ) 61574.85user 95.55system 2:16:39elapsed 752%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 11:41:58 ) 9355.71user 8.39system 19:37.49elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 12:01:36 ) 0.136u 0.011s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 12:01:37 ) 0.311u 0.106s 0:00.42 97.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.0058607700048
:CHARGE convergence:  0.0341811
>lapw0      ( 12:01:37 ) starting parallel lapw0 at Wed Feb  5 12:01:39 CST 2014
-------- .machine0 : 8 processors
10.061u 0.393s 0:05.02 208.1%	0+0k 0+0io 82pf+0w
>lapw1      ( 12:01:44 ) starting parallel lapw1 at Wed Feb  5 12:01:45 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 12:01:45 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 22008
[2] 22027
[3] 22046
[4] 22065
[5] 22084
[6] 22104
[7] 22123
[8] 22142
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 462.039u 2.718s 7:45.33 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 463.086u 2.524s 7:45.78 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 463.636u 2.635s 7:46.33 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 456.594u 2.671s 7:39.94 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 459.720u 2.765s 7:43.95 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 460.720u 2.701s 7:44.78 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 451.392u 2.933s 7:35.00 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 456.718u 2.619s 7:40.13 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3673.9	 wallclock=3701.24
3674.212u 22.320s 7:51.12 784.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 12:09:37 ) running LAPWSO in parallel mode
[1] 22945
[2] 22951
[3] 22957
[4] 22963
[5] 22970
[6] 22976
[7] 22982
[8] 22988
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 484.505u 3.656s 8:12.81 99.0% 0+0k 0+0io 0pf+0w
      node030 503.573u 4.051s 8:33.71 98.8% 0+0k 0+0io 0pf+0w
      node030 497.309u 3.798s 8:24.02 99.4% 0+0k 0+0io 0pf+0w
      node030 499.476u 4.311s 8:30.30 98.7% 0+0k 0+0io 0pf+0w
      node030 483.117u 3.832s 8:08.55 99.6% 0+0k 0+0io 0pf+0w
      node030 505.960u 4.040s 8:33.25 99.3% 0+0k 0+0io 0pf+0w
      node030 493.663u 4.237s 8:20.48 99.4% 0+0k 0+0io 0pf+0w
      node030 495.596u 3.906s 8:24.85 98.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3963.2	 wallclock=4027.97
3963.310u 34.494s 8:40.95 767.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 12:18:18 ) 468.08user 6.90system 1:08.14elapsed 697%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 12:19:26 ) 61125.35user 97.16system 2:15:46elapsed 751%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 14:35:12 ) 9351.02user 8.50system 19:31.94elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 14:54:44 ) 0.134u 0.010s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 14:54:44 ) 0.320u 0.108s 0:00.43 97.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000982539961115
:CHARGE convergence:  0.036821
>lapw0      ( 14:54:45 ) starting parallel lapw0 at Wed Feb  5 14:54:45 CST 2014
-------- .machine0 : 8 processors
9.964u 0.361s 0:03.50 294.8%	0+0k 0+0io 84pf+0w
>lapw1      ( 14:54:48 ) starting parallel lapw1 at Wed Feb  5 14:54:48 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 14:54:48 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 25414
[2] 25433
[3] 25452
[4] 25472
[5] 25491
[6] 25510
[7] 25529
[8] 25548
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 468.287u 2.590s 7:51.55 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 467.039u 2.630s 7:50.45 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 462.525u 2.937s 7:46.13 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 465.010u 2.567s 7:47.75 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 460.761u 2.635s 7:44.77 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 460.268u 2.619s 7:43.08 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 461.477u 2.808s 7:45.67 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 457.822u 2.644s 7:40.84 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3703.19	 wallclock=3730.24
3703.468u 22.221s 7:53.77 786.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 15:02:42 ) running LAPWSO in parallel mode
[1] 26368
[2] 26374
[3] 26380
[4] 26386
[5] 26392
[6] 26399
[7] 26405
[8] 26411
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 487.990u 4.299s 8:18.41 98.7% 0+0k 0+0io 0pf+0w
      node030 506.550u 3.788s 8:36.15 98.8% 0+0k 0+0io 0pf+0w
      node030 481.190u 3.672s 8:07.76 99.4% 0+0k 0+0io 0pf+0w
      node030 494.413u 3.959s 8:23.19 99.0% 0+0k 0+0io 0pf+0w
      node030 490.438u 3.874s 8:18.89 99.0% 0+0k 0+0io 0pf+0w
      node030 503.751u 3.751s 8:33.04 98.9% 0+0k 0+0io 0pf+0w
      node030 489.404u 4.562s 8:23.59 98.0% 0+0k 0+0io 0pf+0w
      node030 474.876u 3.605s 8:00.27 99.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3928.61	 wallclock=4001.3
3928.737u 34.208s 8:40.81 760.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 15:11:23 ) 468.70user 6.92system 1:08.72elapsed 692%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 15:12:32 ) 60965.65user 94.47system 2:15:45elapsed 749%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 17:28:17 ) 9346.58user 8.52system 19:31.39elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 17:47:48 ) 0.129u 0.011s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 17:47:48 ) 0.323u 0.112s 0:00.43 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000390709959902
:CHARGE convergence:  0.0356766
>lapw0      ( 17:47:49 ) starting parallel lapw0 at Wed Feb  5 17:47:49 CST 2014
-------- .machine0 : 8 processors
9.926u 0.415s 0:03.49 295.9%	0+0k 0+0io 87pf+0w
>lapw1      ( 17:47:53 ) starting parallel lapw1 at Wed Feb  5 17:47:53 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 17:47:53 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 28829
[2] 28848
[3] 28868
[4] 28887
[5] 28906
[6] 28925
[7] 28944
[8] 28964
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 462.838u 2.663s 7:46.55 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 449.435u 2.792s 7:33.40 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 460.190u 2.529s 7:42.82 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 458.223u 2.551s 7:41.94 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 461.242u 2.535s 7:43.89 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 459.405u 2.897s 7:42.94 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 457.843u 2.682s 7:40.66 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 454.743u 2.629s 7:37.88 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3663.92	 wallclock=3690.08
3664.220u 22.034s 7:49.27 785.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 17:55:42 ) running LAPWSO in parallel mode
[1] 29763
[2] 29769
[3] 29776
[4] 29782
[5] 29788
[6] 29794
[7] 29800
[8] 29807
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 474.945u 4.576s 8:05.05 98.8% 0+0k 0+0io 0pf+0w
      node030 497.333u 3.612s 8:24.09 99.3% 0+0k 0+0io 0pf+0w
      node030 480.066u 3.877s 8:15.40 97.6% 0+0k 0+0io 0pf+0w
      node030 485.821u 3.589s 8:12.37 99.3% 0+0k 0+0io 0pf+0w
      node030 493.185u 3.629s 8:19.00 99.5% 0+0k 0+0io 0pf+0w
      node030 491.453u 4.018s 8:19.03 99.2% 0+0k 0+0io 0pf+0w
      node030 479.322u 3.765s 8:05.28 99.5% 0+0k 0+0io 0pf+0w
      node030 461.055u 4.184s 7:51.43 98.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3863.18	 wallclock=3931.65
3863.311u 33.878s 8:28.01 767.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 18:04:10 ) 463.02user 6.84system 1:07.98elapsed 691%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 18:05:18 ) 61389.14user 95.67system 2:16:01elapsed 753%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 20:21:20 ) 9343.65user 8.29system 19:35.46elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 20:40:55 ) 0.130u 0.013s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 20:40:55 ) 0.333u 0.116s 0:00.45 97.7%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00125221000053
:CHARGE convergence:  0.0317168
>lapw0      ( 20:40:56 ) starting parallel lapw0 at Wed Feb  5 20:40:56 CST 2014
-------- .machine0 : 8 processors
9.852u 0.396s 0:03.46 295.9%	0+0k 0+0io 84pf+0w
>lapw1      ( 20:40:59 ) starting parallel lapw1 at Wed Feb  5 20:40:59 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 20:40:59 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 32251
[2] 32270
[3] 32290
[4] 32309
[5] 32328
[6] 32347
[7] 32366
[8] 32386
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 468.639u 2.672s 7:51.78 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 470.092u 2.603s 7:52.79 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 459.140u 2.676s 7:42.39 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 458.331u 3.163s 7:42.90 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 457.902u 2.616s 7:41.80 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 455.111u 2.567s 7:37.76 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 454.387u 2.552s 7:37.62 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 460.341u 2.720s 7:43.11 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3683.94	 wallclock=3710.15
3684.205u 22.365s 7:55.05 780.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 20:48:54 ) running LAPWSO in parallel mode
[1] 758
[2] 764
[3] 770
[4] 776
[5] 782
[6] 789
[7] 795
[8] 801
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 479.354u 3.926s 8:09.15 98.7% 0+0k 0+0io 0pf+0w
      node030 502.336u 4.501s 8:36.38 98.1% 0+0k 0+0io 0pf+0w
      node030 475.233u 3.634s 8:00.23 99.7% 0+0k 0+0io 0pf+0w
      node030 487.342u 3.810s 8:14.51 99.3% 0+0k 0+0io 0pf+0w
      node030 511.102u 4.002s 8:44.10 98.2% 0+0k 0+0io 0pf+0w
      node030 486.294u 3.938s 8:13.92 99.2% 0+0k 0+0io 0pf+0w
      node030 486.099u 3.821s 8:14.17 99.1% 0+0k 0+0io 0pf+0w
      node030 474.258u 3.855s 8:02.98 98.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3902.02	 wallclock=3975.44
3902.148u 34.153s 8:50.84 741.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 20:57:48 ) 466.25user 6.68system 1:11.30elapsed 663%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 20:59:00 ) 59732.95user 94.95system 2:12:13elapsed 754%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 23:11:13 ) 9365.60user 8.45system 19:38.42elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 23:30:52 ) 0.137u 0.007s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 23:30:55 ) 0.345u 0.117s 0:00.46 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000300999963656
:CHARGE convergence:  0.0328819
>lapw0      ( 23:30:55 ) starting parallel lapw0 at Wed Feb  5 23:30:55 CST 2014
-------- .machine0 : 8 processors
9.919u 0.440s 0:04.46 232.0%	0+0k 0+0io 83pf+0w
>lapw1      ( 23:31:00 ) starting parallel lapw1 at Wed Feb  5 23:31:01 CST 2014
->  starting parallel LAPW1 jobs at Wed Feb  5 23:31:01 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 3258
[2] 3277
[3] 3297
[4] 3316
[5] 3335
[6] 3354
[7] 3373
[8] 3393
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 450.132u 3.046s 7:35.54 99.4%	0+0k 0+0io 0pf+0w
     node030(34) 465.070u 2.633s 7:47.99 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 461.258u 2.549s 7:46.34 99.4%	0+0k 0+0io 0pf+0w
     node030(34) 452.510u 2.677s 7:36.51 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 457.926u 2.747s 7:43.35 99.4%	0+0k 0+0io 0pf+0w
     node030(34) 458.180u 2.626s 7:43.86 99.3%	0+0k 0+0io 0pf+0w
     node030(34) 448.758u 2.619s 7:32.33 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 452.150u 2.661s 7:37.06 99.5%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3645.98	 wallclock=3682.98
3646.277u 22.333s 7:50.25 780.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 23:38:51 ) running LAPWSO in parallel mode
[1] 4249
[2] 4255
[3] 4262
[4] 4268
[5] 4274
[6] 4280
[7] 4286
[8] 4293
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 494.341u 3.985s 8:25.82 98.5% 0+0k 0+0io 0pf+0w
      node030 486.693u 4.539s 8:16.56 98.9% 0+0k 0+0io 0pf+0w
      node030 491.665u 3.803s 8:20.06 99.0% 0+0k 0+0io 0pf+0w
      node030 507.926u 3.622s 8:31.72 99.9% 0+0k 0+0io 0pf+0w
      node030 492.572u 4.083s 8:20.66 99.1% 0+0k 0+0io 0pf+0w
      node030 495.169u 3.848s 8:20.59 99.6% 0+0k 0+0io 0pf+0w
      node030 479.059u 3.971s 8:06.20 99.3% 0+0k 0+0io 0pf+0w
      node030 480.870u 3.874s 8:08.62 99.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3928.3	 wallclock=3990.23
3928.407u 34.418s 8:37.44 765.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 23:47:29 ) 468.25user 6.75system 1:08.13elapsed 697%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 23:48:37 ) 60664.38user 96.04system 2:14:34elapsed 752%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:03:12 ) 9358.02user 8.41system 19:53.81elapsed 784%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:23:06 ) 0.129u 0.015s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 02:23:06 ) 0.349u 0.111s 0:00.46 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000278949970379
:CHARGE convergence:  0.0330647
>lapw0      ( 02:23:07 ) starting parallel lapw0 at Thu Feb  6 02:23:07 CST 2014
-------- .machine0 : 8 processors
10.001u 0.408s 0:03.49 297.9%	0+0k 0+0io 86pf+0w
>lapw1      ( 02:23:11 ) starting parallel lapw1 at Thu Feb  6 02:23:11 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 02:23:11 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 6719
[2] 6738
[3] 6758
[4] 6777
[5] 6796
[6] 6815
[7] 6834
[8] 6854
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 458.087u 2.960s 7:42.01 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 454.988u 2.793s 7:37.88 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 463.632u 2.723s 7:47.06 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 453.381u 2.706s 7:36.53 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 457.824u 2.662s 7:41.73 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 456.153u 2.537s 7:39.88 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 451.371u 2.662s 7:34.67 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 455.602u 2.648s 7:38.50 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3651.04	 wallclock=3678.26
3651.323u 22.464s 7:50.37 781.0%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:31:01 ) running LAPWSO in parallel mode
[1] 7658
[2] 7664
[3] 7671
[4] 7677
[5] 7683
[6] 7689
[7] 7695
[8] 7702
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 473.662u 4.533s 8:04.02 98.7% 0+0k 0+0io 0pf+0w
      node030 508.478u 3.912s 8:36.13 99.2% 0+0k 0+0io 0pf+0w
      node030 493.853u 3.984s 8:20.42 99.4% 0+0k 0+0io 0pf+0w
      node030 491.846u 3.905s 8:19.72 99.2% 0+0k 0+0io 0pf+0w
      node030 496.089u 3.654s 8:23.80 99.1% 0+0k 0+0io 0pf+0w
      node030 497.854u 3.715s 8:24.17 99.4% 0+0k 0+0io 0pf+0w
      node030 484.650u 3.750s 8:11.28 99.4% 0+0k 0+0io 0pf+0w
      node030 483.908u 4.051s 8:09.46 99.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3930.34	 wallclock=3989
3930.457u 34.179s 8:39.83 762.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:39:41 ) 467.55user 6.74system 1:08.09elapsed 696%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:40:49 ) 69952.12user 108.01system 2:35:11elapsed 752%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:16:07 ) 9378.95user 8.52system 19:39.56elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 05:35:47 ) 0.127u 0.012s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 05:35:47 ) 0.360u 0.101s 0:00.46 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00735889992211
:CHARGE convergence:  0.0073713
>lapw0      ( 05:35:47 ) starting parallel lapw0 at Thu Feb  6 05:35:48 CST 2014
-------- .machine0 : 8 processors
9.981u 0.385s 0:03.49 296.8%	0+0k 0+0io 85pf+0w
>lapw1      ( 05:35:51 ) starting parallel lapw1 at Thu Feb  6 05:35:51 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 05:35:51 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 10831
[2] 10850
[3] 10870
[4] 10889
[5] 10908
[6] 10927
[7] 10946
[8] 10966
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 463.351u 2.852s 7:47.20 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 463.887u 2.773s 7:47.11 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 461.860u 2.766s 7:46.15 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 457.773u 2.564s 7:41.21 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 462.122u 2.599s 7:45.54 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 461.412u 2.594s 7:44.17 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 447.684u 2.795s 7:31.20 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 458.254u 2.612s 7:41.11 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3676.34	 wallclock=3703.69
3676.635u 22.307s 7:50.85 785.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 05:43:42 ) running LAPWSO in parallel mode
[1] 11770
[2] 11776
[3] 11782
[4] 11789
[5] 11795
[6] 11801
[7] 11807
[8] 11813
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 488.279u 3.860s 8:17.30 98.9% 0+0k 0+0io 0pf+0w
      node030 497.853u 3.617s 8:22.36 99.8% 0+0k 0+0io 0pf+0w
      node030 494.029u 3.554s 8:21.58 99.2% 0+0k 0+0io 0pf+0w
      node030 491.838u 3.841s 8:19.58 99.2% 0+0k 0+0io 0pf+0w
      node030 492.631u 4.000s 8:20.42 99.2% 0+0k 0+0io 0pf+0w
      node030 505.629u 4.466s 8:36.74 98.7% 0+0k 0+0io 0pf+0w
      node030 489.706u 3.750s 8:15.98 99.4% 0+0k 0+0io 0pf+0w
      node030 477.496u 4.361s 8:08.71 98.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3937.46	 wallclock=4002.67
3937.578u 34.152s 8:44.49 757.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 05:52:27 ) 464.70user 6.75system 1:08.07elapsed 692%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 05:53:35 ) 70047.61user 107.41system 2:34:47elapsed 755%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 08:28:22 ) 9341.77user 8.49system 19:30.78elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 08:47:53 ) 0.134u 0.013s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 08:47:53 ) 0.341u 0.120s 0:00.46 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00395764003042
:CHARGE convergence:  0.0286818
>lapw0      ( 08:47:54 ) starting parallel lapw0 at Thu Feb  6 08:47:54 CST 2014
-------- .machine0 : 8 processors
9.910u 0.419s 0:03.48 296.5%	0+0k 0+0io 87pf+0w
>lapw1      ( 08:47:57 ) starting parallel lapw1 at Thu Feb  6 08:47:57 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 08:47:57 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 14469
[2] 14488
[3] 14507
[4] 14526
[5] 14546
[6] 14565
[7] 14584
[8] 14603
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 464.047u 3.069s 7:48.65 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 455.153u 2.776s 7:38.41 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 463.989u 2.521s 7:47.82 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 461.273u 2.476s 7:43.85 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 465.965u 2.658s 7:48.73 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 459.932u 2.668s 7:43.61 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 452.255u 2.644s 7:35.12 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 459.298u 2.638s 7:42.13 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3681.91	 wallclock=3708.32
3682.201u 22.204s 7:54.04 781.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 08:55:51 ) running LAPWSO in parallel mode
[1] 15409
[2] 15415
[3] 15421
[4] 15427
[5] 15433
[6] 15440
[7] 15446
[8] 15452
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 475.620u 3.739s 8:04.46 98.9% 0+0k 0+0io 0pf+0w
      node030 526.684u 5.025s 8:54.60 99.4% 0+0k 0+0io 0pf+0w
      node030 500.620u 3.503s 8:26.27 99.5% 0+0k 0+0io 0pf+0w
      node030 503.827u 3.409s 8:29.33 99.5% 0+0k 0+0io 0pf+0w
      node030 517.108u 3.934s 8:43.18 99.5% 0+0k 0+0io 0pf+0w
      node030 485.164u 3.630s 8:09.91 99.7% 0+0k 0+0io 0pf+0w
      node030 504.208u 4.175s 8:32.64 99.1% 0+0k 0+0io 0pf+0w
      node030 480.035u 3.571s 8:04.48 99.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3993.27	 wallclock=4044.87
3993.404u 33.641s 8:58.30 748.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 09:04:50 ) 468.62user 6.86system 1:10.01elapsed 679%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 09:06:00 ) 60590.73user 95.03system 2:15:21elapsed 747%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 11:21:22 ) 9329.27user 8.62system 19:34.33elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 11:40:56 ) 0.128u 0.013s 0:00.15 86.6%	0+0k 0+0io 0pf+0w
>mixer      ( 11:40:59 ) 0.353u 0.111s 0:02.17 21.1%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00563407002483
:CHARGE convergence:  0.0156698
>lapw0      ( 11:41:02 ) starting parallel lapw0 at Thu Feb  6 11:41:03 CST 2014
-------- .machine0 : 8 processors
9.905u 0.388s 0:08.31 123.7%	0+0k 0+0io 85pf+0w
>lapw1      ( 11:41:12 ) starting parallel lapw1 at Thu Feb  6 11:41:15 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 11:41:15 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 17872
[2] 17891
[3] 17911
[4] 17930
[5] 17949
[6] 17968
[7] 17987
[8] 18007
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 461.007u 3.135s 7:45.37 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 463.452u 2.665s 7:49.48 99.2%	0+0k 0+0io 0pf+0w
     node030(34) 457.582u 2.662s 7:41.06 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 461.618u 2.670s 7:46.82 99.4%	0+0k 0+0io 0pf+0w
     node030(34) 458.951u 2.858s 7:43.80 99.5%	0+0k 0+0io 0pf+0w
     node030(34) 459.527u 2.626s 7:42.60 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 458.829u 2.643s 7:43.43 99.5%	0+0k 0+0io 0pf+0w
     node030(34) 458.795u 2.620s 7:42.02 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3679.76	 wallclock=3714.58
3680.027u 22.684s 7:53.29 782.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 11:49:07 ) running LAPWSO in parallel mode
[1] 18806
[2] 18812
[3] 18818
[4] 18824
[5] 18830
[6] 18837
[7] 18843
[8] 18849
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 475.108u 4.280s 8:07.78 98.2% 0+0k 0+0io 0pf+0w
      node030 505.871u 4.091s 8:35.01 99.0% 0+0k 0+0io 0pf+0w
      node030 504.304u 4.025s 8:35.00 98.7% 0+0k 0+0io 0pf+0w
      node030 483.561u 3.725s 8:12.30 98.9% 0+0k 0+0io 0pf+0w
      node030 515.986u 3.629s 8:42.68 99.4% 0+0k 0+0io 0pf+0w
      node030 493.769u 3.983s 8:22.57 99.0% 0+0k 0+0io 0pf+0w
      node030 488.059u 4.366s 8:19.66 98.5% 0+0k 0+0io 0pf+0w
      node030 471.567u 3.649s 7:59.08 99.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3938.23	 wallclock=4014.08
3938.345u 34.424s 8:49.40 750.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 11:57:56 ) 465.72user 6.86system 1:08.15elapsed 693%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 11:59:04 ) 61308.16user 106.07system 2:16:24elapsed 750%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 14:15:30 ) 9413.68user 8.75system 19:44.74elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 14:35:15 ) 0.137u 0.011s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 14:35:16 ) 0.349u 0.113s 0:00.46 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00334610999562
:CHARGE convergence:  0.0018443
>lapw0      ( 14:35:16 ) starting parallel lapw0 at Thu Feb  6 14:35:16 CST 2014
-------- .machine0 : 8 processors
9.910u 0.420s 0:03.48 296.8%	0+0k 0+0io 86pf+0w
>lapw1      ( 14:35:20 ) starting parallel lapw1 at Thu Feb  6 14:35:20 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 14:35:20 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 21295
[2] 21314
[3] 21333
[4] 21352
[5] 21372
[6] 21391
[7] 21410
[8] 21429
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 463.562u 2.681s 7:46.83 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 460.831u 3.330s 7:44.49 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 459.961u 2.613s 7:45.81 99.3%	0+0k 0+0io 0pf+0w
     node030(34) 460.251u 2.541s 7:44.65 99.5%	0+0k 0+0io 0pf+0w
     node030(34) 460.517u 2.592s 7:43.53 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 457.886u 2.424s 7:42.03 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 456.246u 2.627s 7:39.90 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 455.853u 2.589s 7:39.67 99.7%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3675.11	 wallclock=3706.91
3675.391u 22.140s 7:49.87 786.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 14:43:10 ) running LAPWSO in parallel mode
[1] 22210
[2] 22216
[3] 22222
[4] 22228
[5] 22234
[6] 22241
[7] 22247
[8] 22253
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 486.686u 4.189s 8:17.36 98.6% 0+0k 0+0io 0pf+0w
      node030 504.590u 3.821s 8:33.29 99.0% 0+0k 0+0io 0pf+0w
      node030 504.393u 4.146s 8:32.86 99.1% 0+0k 0+0io 0pf+0w
      node030 492.224u 3.960s 8:21.59 98.9% 0+0k 0+0io 0pf+0w
      node030 498.171u 3.993s 8:26.40 99.1% 0+0k 0+0io 0pf+0w
      node030 501.802u 3.961s 8:29.57 99.2% 0+0k 0+0io 0pf+0w
      node030 479.649u 3.722s 8:05.95 99.4% 0+0k 0+0io 0pf+0w
      node030 469.384u 3.956s 7:59.08 98.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3936.9	 wallclock=4006.1
3937.014u 34.441s 8:37.59 767.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 14:51:48 ) 467.92user 6.68system 1:08.81elapsed 689%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 14:52:57 ) 52214.53user 86.89system 1:56:04elapsed 750%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 16:49:01 ) 10070.74user 8.58system 21:01.97elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 17:10:03 ) 0.134u 0.012s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 17:10:49 ) 0.346u 0.113s 0:00.46 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000185459968634
:CHARGE convergence:  0.0012481
>lapw0      ( 17:10:49 ) starting parallel lapw0 at Thu Feb  6 17:10:49 CST 2014
-------- .machine0 : 8 processors
10.094u 0.390s 0:03.51 298.5%	0+0k 0+0io 85pf+0w
>lapw1      ( 17:10:53 ) starting parallel lapw1 at Thu Feb  6 17:11:38 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 17:11:38 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 24477
[2] 24496
[3] 24516
[4] 24535
[5] 24554
[6] 24573
[7] 24592
[8] 24612
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 456.711u 2.874s 7:40.56 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 448.930u 2.801s 7:33.43 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 448.162u 2.620s 7:31.38 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 449.310u 3.193s 7:32.80 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 453.216u 2.645s 7:36.08 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 448.883u 2.616s 7:32.02 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 447.944u 2.649s 7:31.01 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 445.811u 2.796s 7:28.71 99.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3598.97	 wallclock=3625.99
3599.223u 22.983s 7:41.80 784.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 17:19:20 ) running LAPWSO in parallel mode
[1] 25407
[2] 25413
[3] 25419
[4] 25426
[5] 25432
[6] 25438
[7] 25444
[8] 25451
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 464.209u 3.952s 7:54.07 98.7% 0+0k 0+0io 0pf+0w
      node030 475.251u 4.193s 8:04.86 98.8% 0+0k 0+0io 0pf+0w
      node030 470.203u 3.777s 7:56.90 99.3% 0+0k 0+0io 0pf+0w
      node030 463.764u 3.983s 7:51.03 99.3% 0+0k 0+0io 0pf+0w
      node030 468.260u 3.659s 8:00.54 98.2% 0+0k 0+0io 0pf+0w
      node030 472.751u 4.383s 8:06.58 98.0% 0+0k 0+0io 0pf+0w
      node030 478.909u 4.163s 8:10.18 98.5% 0+0k 0+0io 0pf+0w
      node030 464.294u 3.712s 7:48.77 99.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3757.64	 wallclock=3832.93
3757.761u 34.494s 8:26.99 747.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 17:27:51 ) 466.42user 6.91system 1:14.32elapsed 636%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 17:29:05 ) 59974.26user 97.98system 2:14:30elapsed 744%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 19:43:36 ) 9363.70user 8.37system 19:33.51elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 20:03:09 ) 0.130u 0.010s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 20:03:10 ) 0.343u 0.122s 0:00.46 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000869289971888
:CHARGE convergence:  0.0031691
>lapw0      ( 20:03:10 ) starting parallel lapw0 at Thu Feb  6 20:03:10 CST 2014
-------- .machine0 : 8 processors
9.859u 0.414s 0:03.47 295.6%	0+0k 0+0io 89pf+0w
>lapw1      ( 20:03:14 ) starting parallel lapw1 at Thu Feb  6 20:03:14 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 20:03:14 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 27843
[2] 27862
[3] 27881
[4] 27900
[5] 27919
[6] 27939
[7] 27958
[8] 27977
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 455.858u 2.672s 7:39.41 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 462.919u 2.756s 7:47.10 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 451.170u 3.283s 7:34.56 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 461.108u 2.609s 7:43.90 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 461.298u 2.562s 7:44.30 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 451.149u 2.651s 7:34.61 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 448.541u 2.529s 7:31.69 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 454.982u 2.689s 7:38.69 99.7%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3647.03	 wallclock=3674.26
3647.307u 22.509s 7:49.61 781.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 20:11:03 ) running LAPWSO in parallel mode
[1] 28777
[2] 28784
[3] 28790
[4] 28796
[5] 28802
[6] 28808
[7] 28815
[8] 28821
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 479.991u 4.255s 8:09.74 98.8% 0+0k 0+0io 0pf+0w
      node030 525.183u 4.784s 8:55.53 98.9% 0+0k 0+0io 0pf+0w
      node030 514.716u 3.944s 8:43.86 99.0% 0+0k 0+0io 0pf+0w
      node030 510.487u 3.750s 8:40.09 98.8% 0+0k 0+0io 0pf+0w
      node030 480.223u 3.604s 8:04.08 99.9% 0+0k 0+0io 0pf+0w
      node030 512.792u 3.879s 8:40.71 99.2% 0+0k 0+0io 0pf+0w
      node030 488.956u 3.764s 8:18.48 98.8% 0+0k 0+0io 0pf+0w
      node030 497.787u 3.583s 8:23.10 99.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=4010.13	 wallclock=4075.59
4010.266u 34.225s 8:59.88 749.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 20:20:03 ) 463.45user 6.41system 1:10.65elapsed 664%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 20:21:14 ) 60875.56user 94.81system 2:16:01elapsed 747%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 22:37:18 ) 9370.24user 8.61system 19:38.89elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 22:56:57 ) 0.136u 0.007s 0:00.14 92.8%	0+0k 0+0io 0pf+0w
>mixer      ( 22:56:57 ) 0.355u 0.113s 0:00.47 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000420989934355
:CHARGE convergence:  0.0008957
>lapw0      ( 22:56:58 ) starting parallel lapw0 at Thu Feb  6 22:56:58 CST 2014
-------- .machine0 : 8 processors
9.716u 0.420s 0:03.45 293.6%	0+0k 0+0io 89pf+0w
>lapw1      ( 22:57:02 ) starting parallel lapw1 at Thu Feb  6 22:57:05 CST 2014
->  starting parallel LAPW1 jobs at Thu Feb  6 22:57:05 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 31255
[2] 31275
[3] 31294
[4] 31313
[5] 31332
[6] 31351
[7] 31371
[8] 31390
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 463.326u 2.637s 7:46.04 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 464.213u 2.586s 7:47.20 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 462.326u 2.529s 7:46.72 99.5%	0+0k 0+0io 0pf+0w
     node030(34) 461.165u 2.605s 7:44.28 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 460.346u 2.813s 7:45.33 99.5%	0+0k 0+0io 0pf+0w
     node030(34) 459.361u 2.531s 7:41.96 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 451.477u 2.685s 7:34.50 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 455.939u 3.061s 7:40.32 99.7%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3678.15	 wallclock=3706.35
3678.470u 22.208s 7:50.65 786.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 23:04:55 ) running LAPWSO in parallel mode
[1] 32214
[2] 32220
[3] 32226
[4] 32232
[5] 32238
[6] 32245
[7] 32251
[8] 32257
[8]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 476.881u 3.766s 8:06.91 98.7% 0+0k 0+0io 0pf+0w
      node030 505.937u 3.609s 8:31.72 99.5% 0+0k 0+0io 0pf+0w
      node030 505.670u 4.141s 8:35.42 98.9% 0+0k 0+0io 0pf+0w
      node030 481.056u 4.053s 8:12.70 98.4% 0+0k 0+0io 0pf+0w
      node030 483.525u 3.490s 8:08.94 99.6% 0+0k 0+0io 0pf+0w
      node030 497.186u 4.035s 8:28.56 98.5% 0+0k 0+0io 0pf+0w
      node030 491.325u 4.349s 8:19.47 99.2% 0+0k 0+0io 0pf+0w
      node030 495.335u 3.757s 8:21.47 99.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3936.91	 wallclock=4005.19
3937.039u 33.897s 8:40.16 763.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 23:13:57 ) 466.93user 6.75system 1:09.92elapsed 677%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 23:15:07 ) 51334.45user 84.33system 1:54:39elapsed 747%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:09:46 ) 9407.88user 8.51system 19:44.00elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:29:30 ) 0.131u 0.011s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 01:29:31 ) 0.351u 0.115s 0:00.46 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000136360060424
:CHARGE convergence:  0.0002528
>lapw0      ( 01:29:31 ) starting parallel lapw0 at Fri Feb  7 01:29:31 CST 2014
-------- .machine0 : 8 processors
9.867u 0.404s 0:03.47 295.6%	0+0k 0+0io 85pf+0w
>lapw1      ( 01:29:35 ) starting parallel lapw1 at Fri Feb  7 01:29:35 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 01:29:35 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 2020
[2] 2040
[3] 2059
[4] 2078
[5] 2097
[6] 2116
[7] 2136
[8] 2155
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 460.130u 3.051s 7:43.79 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 455.009u 2.755s 7:37.93 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 451.250u 2.718s 7:34.71 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 457.713u 2.624s 7:41.54 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 463.156u 2.726s 7:46.36 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 458.067u 2.753s 7:41.45 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 453.054u 2.659s 7:36.70 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 458.611u 2.632s 7:42.00 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3656.99	 wallclock=3684.48
3657.275u 22.686s 7:51.67 780.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:37:26 ) running LAPWSO in parallel mode
[1] 2985
[2] 2992
[3] 2998
[4] 3004
[5] 3010
[6] 3016
[7] 3023
[8] 3029
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 505.404u 3.764s 8:30.09 99.8% 0+0k 0+0io 0pf+0w
      node030 475.960u 3.520s 8:01.76 99.5% 0+0k 0+0io 0pf+0w
      node030 531.992u 4.709s 9:03.42 98.7% 0+0k 0+0io 0pf+0w
      node030 508.403u 3.638s 8:34.53 99.5% 0+0k 0+0io 0pf+0w
      node030 513.773u 3.812s 8:44.06 98.7% 0+0k 0+0io 0pf+0w
      node030 502.831u 4.274s 8:33.76 98.7% 0+0k 0+0io 0pf+0w
      node030 503.656u 3.651s 8:31.73 99.1% 0+0k 0+0io 0pf+0w
      node030 468.950u 3.789s 7:55.06 99.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=4010.97	 wallclock=4074.41
4011.088u 33.862s 9:08.17 737.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:47:20 ) 465.52user 6.57system 1:07.42elapsed 700%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:48:27 ) 51806.64user 86.07system 1:55:45elapsed 747%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:44:18 ) 9362.26user 8.49system 19:34.06elapsed 798%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:03:52 ) 0.137u 0.010s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 04:03:52 ) 0.363u 0.111s 0:00.47 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  5.5170035921e-05
:CHARGE convergence:  0.0001075
>lapw0      ( 04:03:53 ) starting parallel lapw0 at Fri Feb  7 04:03:53 CST 2014
-------- .machine0 : 8 processors
10.019u 0.395s 0:03.49 297.9%	0+0k 0+0io 85pf+0w
>lapw1      ( 04:03:56 ) starting parallel lapw1 at Fri Feb  7 04:03:56 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 04:03:56 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 5748
[2] 5767
[3] 5786
[4] 5805
[5] 5825
[6] 5844
[7] 5863
[8] 5882
[7]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 465.045u 2.671s 7:48.25 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 465.186u 2.595s 7:49.11 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 459.317u 2.674s 7:42.32 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 461.709u 2.990s 7:45.32 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 463.048u 2.558s 7:45.73 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 457.999u 2.791s 7:41.60 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 454.603u 2.640s 7:37.35 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 453.953u 2.650s 7:37.46 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3680.86	 wallclock=3707.14
3681.151u 22.328s 7:51.37 785.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:11:48 ) running LAPWSO in parallel mode
[1] 6692
[2] 6698
[3] 6704
[4] 6710
[5] 6717
[6] 6723
[7] 6729
[8] 6735
[8]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 516.923u 3.653s 8:40.72 99.9% 0+0k 0+0io 0pf+0w
      node030 498.693u 4.151s 8:27.55 99.0% 0+0k 0+0io 0pf+0w
      node030 511.004u 4.019s 8:37.76 99.4% 0+0k 0+0io 0pf+0w
      node030 474.594u 3.549s 7:59.99 99.6% 0+0k 0+0io 0pf+0w
      node030 496.412u 4.383s 8:29.58 98.2% 0+0k 0+0io 0pf+0w
      node030 502.734u 3.746s 8:32.04 98.9% 0+0k 0+0io 0pf+0w
      node030 500.655u 4.258s 8:31.06 98.7% 0+0k 0+0io 0pf+0w
      node030 502.810u 3.767s 8:34.53 98.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=4003.82	 wallclock=4073.23
4003.953u 34.229s 8:44.33 770.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:20:32 ) 467.71user 6.82system 1:08.44elapsed 693%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:21:41 ) 44399.92user 73.54system 1:39:21elapsed 745%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:01:06 ) 9384.68user 8.30system 19:37.14elapsed 797%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:20:44 ) 0.131u 0.015s 0:00.35 40.0%	0+0k 0+0io 0pf+0w
>mixer      ( 06:20:51 ) 0.361u 0.113s 0:01.88 25.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  4.92000253871e-05
:CHARGE convergence:  6.7e-05
>lapw0      ( 06:20:55 ) starting parallel lapw0 at Fri Feb  7 06:20:57 CST 2014
-------- .machine0 : 8 processors
10.555u 0.401s 0:11.07 98.9%	0+0k 0+0io 85pf+0w
>lapw1      ( 06:21:08 ) starting parallel lapw1 at Fri Feb  7 06:21:08 CST 2014
->  starting parallel LAPW1 jobs at Fri Feb  7 06:21:08 CST 2014
running LAPW1 in parallel mode (using .machines)
8 number_of_parallel_jobs
[1] 8724
[2] 8744
[3] 8763
[4] 8782
[5] 8801
[6] 8820
[7] 8840
[8] 8859
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[8]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node030(34) 445.748u 2.822s 7:29.52 99.7%	0+0k 0+0io 0pf+0w
     node030(34) 465.817u 2.884s 7:50.45 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 464.708u 2.496s 7:48.78 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 455.275u 2.727s 7:38.59 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 461.502u 2.894s 7:46.23 99.6%	0+0k 0+0io 0pf+0w
     node030(34) 458.722u 2.573s 7:41.55 99.9%	0+0k 0+0io 0pf+0w
     node030(34) 451.276u 2.676s 7:34.68 99.8%	0+0k 0+0io 0pf+0w
     node030(34) 449.795u 2.749s 7:33.16 99.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node030	 k=272	 user=3652.84	 wallclock=3682.96
3653.107u 22.601s 7:52.72 777.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 06:29:01 ) running LAPWSO in parallel mode
[1] 9647
[2] 9653
[3] 9659
[4] 9665
[5] 9671
[6] 9678
[7] 9684
[8] 9690
[8]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[7]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[6]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[5]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[4]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node030 476.090u 4.181s 8:08.52 98.3% 0+0k 0+0io 0pf+0w
      node030 494.131u 4.029s 8:21.73 99.2% 0+0k 0+0io 0pf+0w
      node030 485.444u 3.951s 8:16.50 98.5% 0+0k 0+0io 0pf+0w
      node030 511.752u 4.602s 8:45.39 98.2% 0+0k 0+0io 0pf+0w
      node030 514.932u 3.674s 8:41.89 99.3% 0+0k 0+0io 0pf+0w
      node030 486.380u 3.753s 8:13.72 99.2% 0+0k 0+0io 0pf+0w
      node030 490.502u 3.820s 8:19.56 98.9% 0+0k 0+0io 0pf+0w
      node030 486.644u 3.529s 8:12.53 99.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node030	 user=3945.88	 wallclock=4019.84
3945.998u 34.232s 8:51.14 749.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 06:37:52 ) 465.52user 6.75system 1:10.56elapsed 669%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 06:39:03 ) 51103.25user 84.79system 1:54:18elapsed 746%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 08:33:22 ) 9421.49user 8.57system 19:45.52elapsed 795%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 08:53:07 ) 0.131u 0.011s 0:00.14 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 08:53:08 ) 0.358u 0.114s 0:00.47 97.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  4.88990917802e-06
:CHARGE convergence:  0.0001279
