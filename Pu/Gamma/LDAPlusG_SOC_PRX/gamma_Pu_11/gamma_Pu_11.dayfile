Calculating gamma_Pu_11 in /scratch/ykent33706/gamma_Pu_11
on node017 with PID 21205




   start        Wed Jan 29 22:46:31 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 22:46:31 2014 1000/0 to go

>lapw0      ( 22:46:31 ) starting parallel lapw0 at Wed Jan 29 22:46:32 CST 2014
-------- .machine0 : 2 processors
2.377u 0.121s 0:03.55 70.1%	0+0k 0+0io 13pf+0w
>lapw1      ( 22:46:35 ) starting parallel lapw1 at Wed Jan 29 22:46:35 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 22:46:35 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 22015
[2] 22092
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 23072
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node017(665) 86.608u 1.648s 2:23.98 61.2%	0+0k 0+0io 0pf+0w
     node017(665) 86.804u 2.449s 2:30.51 59.2%	0+0k 0+0io 0pf+0w
     node017(1) 0.324u 0.017s 0:00.34 97.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node017	 k=1331	 user=173.736	 wallclock=294.83
173.963u 4.363s 2:32.96 116.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:49:08 ) running LAPWSO in parallel mode
[1] 23260
[2] 23273
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 24961
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node017 66.923u 3.120s 4:14.91 27.4% 0+0k 0+0io 0pf+0w
      node017 67.590u 3.182s 3:59.27 29.5% 0+0k 0+0io 0pf+0w
      node017 0.098u 0.013s 0:00.12 83.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node017	 user=134.611	 wallclock=494.3
134.741u 6.717s 4:15.05 55.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:53:23 ) 30.82user 1.14system 0:33.56elapsed 95%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:53:57 ) 5667.33user 10.58system 1:33:56elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:27:58 ) 545.42user 1.93system 4:34.89elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:32:33 ) 0.011u 0.001s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 00:32:33 ) 0.022u 0.013s 0:00.08 37.5%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0053715
>lapw0      ( 00:32:33 ) starting parallel lapw0 at Thu Jan 30 00:32:33 CST 2014
-------- .machine0 : 2 processors
2.444u 0.122s 0:03.46 73.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 00:32:37 ) starting parallel lapw1 at Thu Jan 30 00:32:37 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 00:32:37 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 26577
[2] 26596
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 26729
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node017(665) 89.805u 1.837s 1:35.32 96.1%	0+0k 0+0io 0pf+0w
     node017(665) 90.114u 2.738s 1:34.85 97.8%	0+0k 0+0io 0pf+0w
     node017(1) 0.325u 0.018s 0:01.89 17.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node017	 k=1331	 user=180.244	 wallclock=192.06
180.399u 4.836s 1:40.31 184.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 00:34:17 ) running LAPWSO in parallel mode
[1] 26870
[2] 26876
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 27537
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node017 66.794u 2.649s 2:12.21 52.5% 0+0k 0+0io 0pf+0w
      node017 68.517u 2.763s 2:09.38 55.0% 0+0k 0+0io 0pf+0w
      node017 0.099u 0.014s 0:00.11 90.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node017	 user=135.41	 wallclock=261.7
135.553u 6.082s 2:13.80 105.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:36:33 ) 30.84user 1.14system 0:18.39elapsed 173%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:36:51 ) 1982.82user 7.09system 32:49.40elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:09:41 ) 593.57user 2.18system 4:58.98elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:14:40 ) 0.011u 0.003s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 01:14:40 ) 0.022u 0.016s 0:00.08 37.5%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.34400067711e-05
:CHARGE convergence:  0.004766
>lapw0      ( 01:14:40 ) starting parallel lapw0 at Thu Jan 30 01:14:40 CST 2014
-------- .machine0 : 2 processors
2.573u 0.103s 0:03.44 77.6%	0+0k 0+0io 13pf+0w
>lapw1      ( 01:14:43 ) starting parallel lapw1 at Thu Jan 30 01:14:43 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:14:44 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 30738
[2] 30757
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 30890
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node017(665) 94.359u 1.902s 1:36.87 99.3%	0+0k 0+0io 0pf+0w
     node017(665) 93.362u 3.035s 1:36.98 99.3%	0+0k 0+0io 0pf+0w
     node017(1) 0.337u 0.010s 0:00.35 97.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node017	 k=1331	 user=188.058	 wallclock=194.2
188.203u 5.209s 1:40.37 192.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:16:24 ) running LAPWSO in parallel mode
[1] 31030
[2] 31037
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 31380
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node017 70.404u 2.833s 2:12.62 55.2% 0+0k 0+0io 0pf+0w
      node017 71.214u 2.881s 2:20.63 52.6% 0+0k 0+0io 0pf+0w
      node017 0.109u 0.012s 0:00.12 91.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node017	 user=141.727	 wallclock=273.37
141.867u 6.465s 2:22.22 104.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:18:46 ) 31.08user 1.24system 0:19.11elapsed 169%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:19:05 ) 2388.19user 9.32system 39:34.01elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:58:39 ) 596.14user 2.22system 5:00.36elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:03:40 ) 0.011u 0.003s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 02:03:40 ) 0.027u 0.012s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000272089993814
:CHARGE convergence:  0.0007246
>lapw0      ( 02:03:40 ) starting parallel lapw0 at Thu Jan 30 02:03:40 CST 2014
-------- .machine0 : 2 processors
2.550u 0.140s 0:03.45 77.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:03:43 ) starting parallel lapw1 at Thu Jan 30 02:03:43 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:03:43 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 2596
[2] 2615
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 2747
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node017(665) 92.685u 1.815s 1:34.65 99.8%	0+0k 0+0io 0pf+0w
     node017(665) 92.537u 2.989s 1:37.65 97.8%	0+0k 0+0io 0pf+0w
     node017(1) 0.336u 0.013s 0:00.35 97.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node017	 k=1331	 user=185.558	 wallclock=192.65
185.707u 5.079s 1:40.85 189.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:05:24 ) running LAPWSO in parallel mode
[1] 2891
[2] 2899
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 3256
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node017 70.009u 2.806s 2:25.44 50.0% 0+0k 0+0io 0pf+0w
      node017 70.810u 2.799s 2:17.23 53.6% 0+0k 0+0io 0pf+0w
      node017 0.107u 0.018s 0:00.12 91.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node017	 user=140.926	 wallclock=282.79
141.049u 6.404s 2:26.01 100.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:07:50 ) 33.14user 1.74system 0:22.02elapsed 158%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:08:12 ) 2208.25user 8.37system 36:34.71elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:44:47 ) 575.99user 2.00system 4:51.55elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:49:39 ) 0.012u 0.001s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 02:49:39 ) 0.031u 0.010s 0:00.09 44.4%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  7.48000456952e-06
:CHARGE convergence:  0.000693
