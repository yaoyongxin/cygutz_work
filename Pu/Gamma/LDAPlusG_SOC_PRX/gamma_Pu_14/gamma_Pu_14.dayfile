Calculating gamma_Pu_14 in /scratch/ykent33709/gamma_Pu_14
on node016 with PID 20610




   start        Wed Jan 29 22:46:28 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 22:46:28 2014 1000/0 to go

>lapw0      ( 22:46:28 ) starting parallel lapw0 at Wed Jan 29 22:46:28 CST 2014
-------- .machine0 : 2 processors
2.856u 0.132s 0:06.81 43.7%	0+0k 0+0io 13pf+0w
>lapw1      ( 22:46:35 ) starting parallel lapw1 at Wed Jan 29 22:46:35 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 22:46:35 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 21163
[2] 21300
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 22277
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 106.247u 3.474s 2:26.08 75.1%	0+0k 0+0io 0pf+0w
     node016(665) 105.659u 3.531s 2:25.68 74.9%	0+0k 0+0io 0pf+0w
     node016(1) 0.347u 0.013s 0:00.42 83.3%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=212.253	 wallclock=292.18
212.484u 7.298s 2:30.20 146.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:49:05 ) running LAPWSO in parallel mode
[1] 22432
[2] 22443
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 25527
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 85.238u 3.738s 4:27.88 33.2% 0+0k 0+0io 0pf+0w
      node016 84.055u 3.595s 4:25.78 32.9% 0+0k 0+0io 0pf+0w
      node016 0.126u 0.015s 0:00.14 92.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=169.419	 wallclock=533.8
169.599u 7.949s 4:28.88 66.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:53:34 ) 35.03user 1.23system 0:22.15elapsed 163%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:53:56 ) 5870.87user 12.00system 1:37:23elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:31:24 ) 630.46user 1.90system 5:29.86elapsed 191%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:36:54 ) 0.013u 0.001s 0:00.08 12.5%	0+0k 0+0io 0pf+0w
>mixer      ( 00:36:54 ) 0.023u 0.011s 0:00.06 50.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0027373
>lapw0      ( 00:36:54 ) starting parallel lapw0 at Thu Jan 30 00:36:54 CST 2014
-------- .machine0 : 2 processors
2.659u 0.114s 0:03.54 77.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 00:36:58 ) starting parallel lapw1 at Thu Jan 30 00:36:58 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 00:36:58 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 28001
[2] 28023
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 29526
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 105.658u 3.587s 2:45.46 66.0%	0+0k 0+0io 0pf+0w
     node016(665) 105.211u 3.690s 2:42.38 67.0%	0+0k 0+0io 0pf+0w
     node016(1) 0.346u 0.017s 0:04.70 7.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=211.215	 wallclock=332.54
211.429u 7.565s 2:51.52 127.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 00:39:49 ) running LAPWSO in parallel mode
[1] 29719
[2] 29733
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 31590
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 85.407u 3.474s 3:35.88 41.1% 0+0k 0+0io 0pf+0w
      node016 84.301u 3.513s 3:55.01 37.3% 0+0k 0+0io 0pf+0w
      node016 0.128u 0.016s 0:00.17 76.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=169.836	 wallclock=451.06
170.003u 7.971s 3:57.31 74.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:43:47 ) 37.59user 1.83system 0:24.54elapsed 160%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:44:11 ) 3145.30user 9.78system 52:09.45elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:36:21 ) 642.43user 1.94system 5:23.46elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:41:44 ) 0.012u 0.001s 0:00.03 33.3%	0+0k 0+0io 0pf+0w
>mixer      ( 01:41:44 ) 0.025u 0.014s 0:00.08 37.5%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.52400025399e-05
:CHARGE convergence:  0.0022067
>lapw0      ( 01:41:45 ) starting parallel lapw0 at Thu Jan 30 01:41:45 CST 2014
-------- .machine0 : 2 processors
2.728u 0.121s 0:03.55 80.0%	0+0k 0+0io 13pf+0w
>lapw1      ( 01:41:48 ) starting parallel lapw1 at Thu Jan 30 01:41:48 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:41:48 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 1330
[2] 1349
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 1604
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 113.515u 4.119s 1:58.02 99.6%	0+0k 0+0io 0pf+0w
     node016(665) 113.637u 4.256s 1:58.46 99.5%	0+0k 0+0io 0pf+0w
     node016(1) 0.360u 0.015s 0:00.37 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=227.512	 wallclock=236.85
227.700u 8.647s 2:02.57 192.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:43:51 ) running LAPWSO in parallel mode
[1] 1746
[2] 1892
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 2450
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 88.973u 3.411s 2:09.12 71.5% 0+0k 0+0io 0pf+0w
      node016 87.713u 3.578s 2:08.73 70.9% 0+0k 0+0io 0pf+0w
      node016 0.130u 0.016s 0:01.06 13.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=176.816	 wallclock=258.91
176.997u 7.870s 2:12.39 139.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:46:03 ) 38.83user 1.87system 0:23.65elapsed 172%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:46:27 ) 2618.90user 8.88system 43:22.58elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:29:50 ) 690.55user 2.24system 5:47.58elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:35:37 ) 0.012u 0.003s 0:00.03 33.3%	0+0k 0+0io 0pf+0w
>mixer      ( 02:35:37 ) 0.032u 0.012s 0:00.11 36.3%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  7.52099876991e-05
:CHARGE convergence:  0.000372
>lapw0      ( 02:35:37 ) starting parallel lapw0 at Thu Jan 30 02:35:37 CST 2014
-------- .machine0 : 2 processors
2.874u 0.126s 0:03.61 82.8%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:35:41 ) starting parallel lapw1 at Thu Jan 30 02:35:41 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:35:41 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 6064
[2] 6083
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 6245
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 116.616u 4.263s 2:00.96 99.9%	0+0k 0+0io 0pf+0w
     node016(665) 114.236u 4.317s 1:59.14 99.4%	0+0k 0+0io 0pf+0w
     node016(1) 0.353u 0.015s 0:00.37 97.2%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=231.205	 wallclock=240.47
231.359u 8.885s 2:04.60 192.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:37:46 ) running LAPWSO in parallel mode
[1] 6387
[2] 6393
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 6787
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 88.734u 3.404s 2:04.44 74.0% 0+0k 0+0io 0pf+0w
      node016 88.764u 3.473s 2:06.88 72.6% 0+0k 0+0io 0pf+0w
      node016 0.141u 0.012s 0:00.15 100.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=177.639	 wallclock=251.47
177.812u 7.726s 2:08.55 144.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:39:54 ) 37.01user 1.71system 0:21.92elapsed 176%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:40:16 ) 2800.07user 9.25system 46:23.25elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:26:40 ) 728.68user 2.38system 6:06.70elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:32:46 ) 0.011u 0.003s 0:00.03 33.3%	0+0k 0+0io 0pf+0w
>mixer      ( 03:32:55 ) 0.030u 0.011s 0:00.11 36.3%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.03000090551e-05
:CHARGE convergence:  0.0006049
>lapw0      ( 03:32:56 ) starting parallel lapw0 at Thu Jan 30 03:32:56 CST 2014
-------- .machine0 : 2 processors
2.731u 0.126s 0:03.55 80.2%	0+0k 0+0io 13pf+0w
>lapw1      ( 03:32:59 ) starting parallel lapw1 at Thu Jan 30 03:33:02 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 03:33:02 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 10656
[2] 10675
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 10836
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 113.529u 4.037s 1:58.28 99.3%	0+0k 0+0io 0pf+0w
     node016(665) 114.256u 4.396s 1:59.11 99.6%	0+0k 0+0io 0pf+0w
     node016(1) 0.356u 0.012s 0:00.37 97.2%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=228.141	 wallclock=237.76
228.321u 8.697s 2:02.57 193.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:35:05 ) running LAPWSO in parallel mode
[1] 10976
[2] 10982
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 11366
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 89.277u 3.398s 2:04.56 74.3% 0+0k 0+0io 0pf+0w
      node016 86.084u 3.416s 1:58.87 75.2% 0+0k 0+0io 0pf+0w
      node016 0.139u 0.009s 0:00.17 76.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=175.5	 wallclock=243.6
175.651u 7.670s 2:05.21 146.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:37:10 ) 35.60user 1.43system 0:20.88elapsed 177%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:37:31 ) 2685.73user 8.13system 44:28.22elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:22:00 ) 683.14user 2.51system 5:45.27elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:27:46 ) 0.012u 0.002s 0:00.06 16.6%	0+0k 0+0io 0pf+0w
>mixer      ( 04:27:46 ) 0.028u 0.010s 0:00.07 42.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  9.15900018299e-05
:CHARGE convergence:  0.0013214
>lapw0      ( 04:27:46 ) starting parallel lapw0 at Thu Jan 30 04:27:46 CST 2014
-------- .machine0 : 2 processors
3.453u 0.120s 0:04.23 84.3%	0+0k 0+0io 14pf+0w
>lapw1      ( 04:27:50 ) starting parallel lapw1 at Thu Jan 30 04:27:50 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 04:27:50 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 16572
[2] 16595
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 16925
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 112.760u 4.148s 2:09.65 90.1%	0+0k 0+0io 0pf+0w
     node016(665) 112.795u 4.137s 2:08.89 90.7%	0+0k 0+0io 0pf+0w
     node016(1) 0.355u 0.012s 0:00.37 97.2%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=225.91	 wallclock=258.91
226.084u 8.575s 2:13.64 175.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:30:04 ) running LAPWSO in parallel mode
[1] 17070
[2] 17076
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 17486
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 89.034u 3.312s 2:09.02 71.5% 0+0k 0+0io 0pf+0w
      node016 88.541u 3.337s 2:10.32 70.4% 0+0k 0+0io 0pf+0w
      node016 0.135u 0.012s 0:00.18 77.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=177.71	 wallclock=259.52
177.825u 7.598s 2:11.97 140.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:32:19 ) 38.47user 2.05system 0:23.11elapsed 175%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:32:42 ) 2611.73user 10.24system 43:15.54elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:15:58 ) 678.79user 2.32system 5:41.74elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 05:21:40 ) 0.010u 0.005s 0:00.04 25.0%	0+0k 0+0io 0pf+0w
>mixer      ( 05:21:40 ) 0.024u 0.019s 0:00.11 27.2%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  6.4720006776e-05
:CHARGE convergence:  0.0003076
>lapw0      ( 05:21:40 ) starting parallel lapw0 at Thu Jan 30 05:21:40 CST 2014
-------- .machine0 : 2 processors
2.776u 0.137s 0:03.59 80.7%	0+0k 0+0io 13pf+0w
>lapw1      ( 05:21:44 ) starting parallel lapw1 at Thu Jan 30 05:21:44 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 05:21:44 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 20449
[2] 20468
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 20621
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 106.694u 3.673s 1:51.18 99.2%	0+0k 0+0io 0pf+0w
     node016(665) 106.413u 3.744s 1:51.70 98.6%	0+0k 0+0io 0pf+0w
     node016(1) 0.362u 0.013s 0:00.37 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=213.469	 wallclock=223.25
213.641u 7.679s 1:55.55 191.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 05:23:39 ) running LAPWSO in parallel mode
[1] 20765
[2] 20772
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 21168
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 89.206u 3.426s 2:03.72 74.8% 0+0k 0+0io 0pf+0w
      node016 87.472u 3.552s 2:04.19 73.2% 0+0k 0+0io 0pf+0w
      node016 0.135u 0.014s 0:00.16 87.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=176.813	 wallclock=248.07
176.969u 7.871s 2:06.87 145.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 05:25:49 ) 37.02user 1.77system 0:20.80elapsed 186%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 05:26:10 ) 2211.88user 7.79system 36:32.86elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:02:43 ) 679.96user 2.13system 5:42.16elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:08:25 ) 0.012u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 06:08:25 ) 0.028u 0.013s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  6.14998862147e-06
:CHARGE convergence:  0.0006535
