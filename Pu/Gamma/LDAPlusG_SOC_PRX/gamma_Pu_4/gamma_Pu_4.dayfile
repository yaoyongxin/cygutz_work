Calculating gamma_Pu_4 in /scratch/ykent33699/gamma_Pu_4
on node020 with PID 26817




   start        Wed Jan 29 22:46:28 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 22:46:28 2014 1000/0 to go

>lapw0      ( 22:46:28 ) starting parallel lapw0 at Wed Jan 29 22:46:28 CST 2014
-------- .machine0 : 2 processors
2.153u 0.126s 0:03.34 67.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 22:46:32 ) starting parallel lapw1 at Wed Jan 29 22:46:32 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 22:46:32 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 27594
[2] 27671
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 28573
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 51.690u 0.861s 1:24.97 61.8%	0+0k 0+0io 0pf+0w
     node020(665) 51.145u 0.858s 1:28.32 58.8%	0+0k 0+0io 0pf+0w
     node020(1) 0.328u 0.015s 0:00.38 86.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=103.163	 wallclock=173.67
103.310u 1.963s 1:32.08 114.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:48:04 ) running LAPWSO in parallel mode
[1] 28751
[2] 28766
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 30009
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 33.702u 1.934s 3:19.62 17.8% 0+0k 0+0io 0pf+0w
      node020 32.766u 1.957s 2:40.12 21.6% 0+0k 0+0io 0pf+0w
      node020 0.059u 0.008s 0:00.10 50.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=66.527	 wallclock=359.84
66.654u 4.281s 3:19.77 35.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:51:24 ) 21.71user 0.76system 0:16.53elapsed 135%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:51:40 ) 5124.08user 10.87system 1:25:02elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:16:43 ) 415.06user 1.35system 3:31.94elapsed 196%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:20:15 ) 0.010u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 00:20:16 ) 0.025u 0.008s 0:00.42 4.7%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0093023
>lapw0      ( 00:20:17 ) starting parallel lapw0 at Thu Jan 30 00:20:17 CST 2014
-------- .machine0 : 2 processors
1.919u 0.098s 0:03.26 61.3%	0+0k 0+0io 13pf+0w
>lapw1      ( 00:20:20 ) starting parallel lapw1 at Thu Jan 30 00:20:21 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 00:20:21 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 31545
[2] 31564
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 31908
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 52.514u 0.904s 0:57.64 92.6%	0+0k 0+0io 0pf+0w
     node020(665) 53.181u 0.933s 0:56.44 95.8%	0+0k 0+0io 0pf+0w
     node020(1) 0.339u 0.012s 0:00.94 36.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=106.034	 wallclock=115.02
106.143u 2.047s 1:00.08 180.0%	0+0k 0+0io 0pf+0w
>lapwso     ( 00:21:21 ) running LAPWSO in parallel mode
[1] 32050
[2] 32058
[1] 417
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 34.688u 1.864s 1:59.93 30.4% 0+0k 0+0io 0pf+0w
      node020 33.541u 1.915s 2:01.16 29.2% 0+0k 0+0io 0pf+0w
      node020 0.061u 0.027s 0:06.97 1.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=68.29	 wallclock=248.06
68.387u 4.296s 2:09.58 56.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:23:31 ) 22.32user 1.05system 0:21.60elapsed 108%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:23:52 ) 2490.67user 6.87system 41:20.85elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:05:22 ) 437.98user 1.94system 3:41.13elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:09:03 ) 0.012u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 01:09:03 ) 0.024u 0.012s 0:00.03 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.97399965348e-05
:CHARGE convergence:  0.0083336
>lapw0      ( 01:09:03 ) starting parallel lapw0 at Thu Jan 30 01:09:04 CST 2014
-------- .machine0 : 2 processors
1.959u 0.098s 0:03.12 65.3%	0+0k 0+0io 13pf+0w
>lapw1      ( 01:09:07 ) starting parallel lapw1 at Thu Jan 30 01:09:07 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:09:07 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 3334
[2] 3353
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 3747
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 54.910u 0.900s 0:58.60 95.2%	0+0k 0+0io 0pf+0w
     node020(665) 54.013u 0.894s 0:57.86 94.8%	0+0k 0+0io 0pf+0w
     node020(1) 0.341u 0.011s 0:00.35 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=109.264	 wallclock=116.81
109.379u 2.012s 1:02.39 178.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:10:09 ) running LAPWSO in parallel mode
[1] 3899
[2] 3906
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 4465
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 35.806u 2.009s 1:26.85 43.5% 0+0k 0+0io 0pf+0w
      node020 34.540u 2.012s 1:35.17 38.4% 0+0k 0+0io 0pf+0w
      node020 0.062u 0.008s 0:00.07 85.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=70.408	 wallclock=182.09
70.528u 4.521s 1:37.05 77.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:11:46 ) 22.85user 1.17system 0:16.99elapsed 141%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:12:03 ) 2662.87user 7.77system 44:10.81elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:56:14 ) 450.08user 1.52system 3:46.92elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:00:01 ) 0.017u 0.003s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 02:00:01 ) 0.026u 0.011s 0:00.06 50.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000318890000926
:CHARGE convergence:  0.001853
>lapw0      ( 02:00:01 ) starting parallel lapw0 at Thu Jan 30 02:00:01 CST 2014
-------- .machine0 : 2 processors
1.939u 0.108s 0:04.99 40.6%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:00:06 ) starting parallel lapw1 at Thu Jan 30 02:00:06 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:00:06 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 6971
[2] 6994
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 7647
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 53.676u 0.995s 1:42.71 53.2%	0+0k 0+0io 0pf+0w
     node020(665) 52.482u 0.976s 1:39.17 53.8%	0+0k 0+0io 0pf+0w
     node020(1) 0.337u 0.015s 0:00.38 89.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=106.495	 wallclock=202.26
106.654u 2.209s 1:45.54 103.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:01:52 ) running LAPWSO in parallel mode
[1] 7789
[2] 7795
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 8008
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 34.522u 1.849s 1:26.70 41.9% 0+0k 0+0io 0pf+0w
      node020 33.453u 1.830s 1:28.20 40.0% 0+0k 0+0io 0pf+0w
      node020 0.061u 0.015s 0:00.07 100.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=68.036	 wallclock=174.97
68.130u 4.161s 1:30.35 80.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:03:22 ) 23.24user 1.20system 0:18.03elapsed 135%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:03:40 ) 2536.56user 8.33system 42:06.31elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:45:48 ) 434.51user 1.64system 3:39.20elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:49:28 ) 0.012u 0.000s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 02:49:28 ) 0.024u 0.010s 0:00.07 42.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.77299986919e-05
:CHARGE convergence:  0.0012705
>lapw0      ( 02:49:28 ) starting parallel lapw0 at Thu Jan 30 02:49:28 CST 2014
-------- .machine0 : 2 processors
1.683u 0.084s 0:02.97 59.2%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:49:31 ) starting parallel lapw1 at Thu Jan 30 02:49:31 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:49:31 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 10718
[2] 10740
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 10999
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 51.740u 0.902s 1:19.40 66.2%	0+0k 0+0io 0pf+0w
     node020(665) 51.635u 0.874s 1:16.09 68.9%	0+0k 0+0io 0pf+0w
     node020(1) 0.336u 0.013s 0:00.35 97.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=103.711	 wallclock=155.84
103.824u 1.992s 1:21.05 130.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:50:52 ) running LAPWSO in parallel mode
[1] 11141
[2] 11147
[2] 11328
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 35.014u 1.832s 1:29.46 41.1% 0+0k 0+0io 0pf+0w
      node020 33.727u 1.856s 1:25.05 41.8% 0+0k 0+0io 0pf+0w
      node020 0.058u 0.013s 0:00.07 85.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=68.799	 wallclock=174.58
68.904u 4.106s 1:30.38 80.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:52:22 ) 22.95user 1.06system 0:16.93elapsed 141%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:52:39 ) 2444.74user 8.25system 40:34.87elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:33:14 ) 452.69user 1.59system 3:48.25elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:37:03 ) 0.013u 0.000s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 03:37:06 ) 0.026u 0.013s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000117129995488
:CHARGE convergence:  0.0013213
>lapw0      ( 03:37:06 ) starting parallel lapw0 at Thu Jan 30 03:37:06 CST 2014
-------- .machine0 : 2 processors
2.046u 0.115s 0:03.17 67.8%	0+0k 0+0io 15pf+0w
>lapw1      ( 03:37:09 ) starting parallel lapw1 at Thu Jan 30 03:37:09 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 03:37:09 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 14153
[2] 14172
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 14258
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 54.984u 0.932s 0:56.03 99.7%	0+0k 0+0io 0pf+0w
     node020(665) 51.501u 0.932s 0:56.02 93.5%	0+0k 0+0io 0pf+0w
     node020(1) 0.343u 0.012s 0:00.35 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=106.828	 wallclock=112.4
106.950u 2.073s 0:59.36 183.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:38:08 ) running LAPWSO in parallel mode
[1] 14494
[2] 14639
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 14954
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 35.575u 1.900s 1:41.11 37.0% 0+0k 0+0io 0pf+0w
      node020 34.169u 1.988s 1:28.81 40.6% 0+0k 0+0io 0pf+0w
      node020 0.063u 0.008s 0:00.07 85.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=69.807	 wallclock=189.99
69.912u 4.387s 1:41.49 73.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:39:50 ) 22.87user 1.18system 0:15.47elapsed 155%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:40:05 ) 2505.72user 8.05system 41:36.67elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:21:42 ) 438.48user 1.58system 3:41.16elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:25:23 ) 0.011u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 04:25:23 ) 0.023u 0.016s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  6.53299939586e-05
:CHARGE convergence:  0.0003124
>lapw0      ( 04:25:24 ) starting parallel lapw0 at Thu Jan 30 04:25:24 CST 2014
-------- .machine0 : 2 processors
1.904u 0.098s 0:03.11 63.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 04:25:27 ) starting parallel lapw1 at Thu Jan 30 04:25:27 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 04:25:27 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 17920
[2] 17939
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 18024
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 52.876u 0.877s 0:55.19 97.3%	0+0k 0+0io 0pf+0w
     node020(665) 56.369u 0.959s 0:57.97 98.8%	0+0k 0+0io 0pf+0w
     node020(1) 0.339u 0.014s 0:00.35 97.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=109.584	 wallclock=113.51
109.693u 2.056s 1:01.38 182.0%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:26:28 ) running LAPWSO in parallel mode
[1] 18167
[2] 18173
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 18639
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 36.089u 2.012s 1:15.18 50.6% 0+0k 0+0io 0pf+0w
      node020 34.604u 2.003s 1:24.23 43.4% 0+0k 0+0io 0pf+0w
      node020 0.060u 0.010s 0:00.07 100.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=70.753	 wallclock=159.48
70.861u 4.490s 1:25.60 88.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:27:54 ) 22.82user 1.27system 0:15.81elapsed 152%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:28:10 ) 2548.60user 8.24system 42:19.31elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:10:30 ) 411.39user 1.38system 3:27.50elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 05:13:58 ) 0.017u 0.005s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 05:14:00 ) 0.034u 0.015s 0:00.06 66.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.40001066029e-06
:CHARGE convergence:  0.0002647
