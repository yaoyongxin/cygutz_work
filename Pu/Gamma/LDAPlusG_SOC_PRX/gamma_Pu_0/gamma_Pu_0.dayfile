Calculating gamma_Pu_0 in /scratch/ykent33695/gamma_Pu_0
on node022 with PID 18697




   start        Wed Jan 29 22:45:33 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 22:45:33 2014 1000/0 to go

>lapw0      ( 22:45:33 ) starting parallel lapw0 at Wed Jan 29 22:45:33 CST 2014
-------- .machine0 : 2 processors
1.587u 0.102s 0:02.95 56.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 22:45:36 ) starting parallel lapw1 at Wed Jan 29 22:45:36 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 22:45:36 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 18889
[2] 18909
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 18976
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(665) 38.219u 0.740s 0:39.57 98.4%	0+0k 0+0io 0pf+0w
     node022(665) 38.348u 0.735s 0:39.49 98.9%	0+0k 0+0io 0pf+0w
     node022(1) 0.369u 0.009s 0:00.59 61.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=1331	 user=76.936	 wallclock=79.65
77.019u 1.707s 0:44.61 176.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:46:21 ) running LAPWSO in parallel mode
[1] 19114
[2] 19121
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 19226
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 22.004u 1.445s 0:36.47 64.2% 0+0k 0+0io 0pf+0w
      node022 21.669u 1.466s 0:35.10 65.8% 0+0k 0+0io 0pf+0w
      node022 0.033u 0.014s 0:00.07 57.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=43.706	 wallclock=71.64
43.783u 3.091s 0:37.81 123.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:47:00 ) 17.87user 1.00system 0:11.30elapsed 166%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:47:11 ) 5395.95user 11.06system 1:29:38elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:16:50 ) 387.84user 1.51system 3:18.92elapsed 195%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:20:09 ) 0.010u 0.004s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 00:20:09 ) 0.018u 0.019s 0:00.08 25.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0078105
>lapw0      ( 00:20:09 ) starting parallel lapw0 at Thu Jan 30 00:20:09 CST 2014
-------- .machine0 : 2 processors
1.595u 0.094s 0:02.94 57.1%	0+0k 0+0io 13pf+0w
>lapw1      ( 00:20:12 ) starting parallel lapw1 at Thu Jan 30 00:20:12 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 00:20:12 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 22004
[2] 22023
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 22091
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(665) 38.888u 0.748s 0:41.66 95.1%	0+0k 0+0io 0pf+0w
     node022(665) 39.044u 0.734s 0:41.25 96.4%	0+0k 0+0io 0pf+0w
     node022(1) 0.372u 0.010s 0:00.66 57.5%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=1331	 user=78.304	 wallclock=83.57
78.413u 1.699s 0:44.32 180.7%	0+0k 0+0io 0pf+0w
>lapwso     ( 00:20:57 ) running LAPWSO in parallel mode
[1] 22231
[2] 22237
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 22349
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 22.059u 1.375s 0:38.69 60.5% 0+0k 0+0io 0pf+0w
      node022 21.322u 1.369s 0:34.12 66.4% 0+0k 0+0io 0pf+0w
      node022 0.034u 0.011s 0:00.39 10.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=43.415	 wallclock=73.2
43.499u 3.079s 0:38.97 119.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:21:36 ) 17.51user 0.85system 0:12.10elapsed 151%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:21:48 ) 2587.47user 8.47system 43:02.47elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:04:51 ) 367.56user 1.39system 3:05.57elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:07:56 ) 0.012u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 01:07:56 ) 0.024u 0.010s 0:00.03 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  3.31699993694e-05
:CHARGE convergence:  0.0061536
>lapw0      ( 01:07:56 ) starting parallel lapw0 at Thu Jan 30 01:07:56 CST 2014
-------- .machine0 : 2 processors
1.528u 0.104s 0:02.90 55.8%	0+0k 0+0io 13pf+0w
>lapw1      ( 01:07:59 ) starting parallel lapw1 at Thu Jan 30 01:08:00 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:08:00 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 23352
[2] 23371
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 23436
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(665) 37.409u 0.713s 0:39.31 96.9%	0+0k 0+0io 0pf+0w
     node022(665) 37.731u 0.750s 0:38.64 99.5%	0+0k 0+0io 0pf+0w
     node022(1) 0.366u 0.013s 0:00.38 97.3%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=1331	 user=75.506	 wallclock=78.33
75.595u 1.710s 0:43.31 178.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:08:43 ) running LAPWSO in parallel mode
[1] 23578
[2] 23584
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 23693
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 21.697u 1.464s 0:34.27 67.5% 0+0k 0+0io 0pf+0w
      node022 21.029u 1.440s 0:35.00 64.1% 0+0k 0+0io 0pf+0w
      node022 0.038u 0.010s 0:00.07 57.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=42.764	 wallclock=69.34
42.847u 3.244s 0:36.74 125.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:09:20 ) 16.96user 0.86system 0:10.11elapsed 176%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:09:30 ) 1608.31user 6.85system 26:38.01elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:36:08 ) 349.61user 1.18system 2:56.51elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:39:05 ) 0.017u 0.004s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 01:39:05 ) 0.027u 0.018s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000138490009704
:CHARGE convergence:  0.0018778
>lapw0      ( 01:39:05 ) starting parallel lapw0 at Thu Jan 30 01:39:05 CST 2014
-------- .machine0 : 2 processors
1.282u 0.106s 0:02.80 49.2%	0+0k 0+0io 13pf+0w
>lapw1      ( 01:39:08 ) starting parallel lapw1 at Thu Jan 30 01:39:08 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:39:08 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 24631
[2] 24650
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 24714
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(665) 35.824u 0.690s 0:36.82 99.1%	0+0k 0+0io 0pf+0w
     node022(665) 36.045u 0.693s 0:37.79 97.1%	0+0k 0+0io 0pf+0w
     node022(1) 0.372u 0.011s 0:00.38 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=1331	 user=72.241	 wallclock=74.99
72.378u 1.611s 0:41.33 178.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:39:49 ) running LAPWSO in parallel mode
[1] 24854
[2] 24860
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 24958
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 19.952u 1.305s 0:30.18 70.4% 0+0k 0+0io 0pf+0w
      node022 20.160u 1.336s 0:33.69 63.7% 0+0k 0+0io 0pf+0w
      node022 0.043u 0.010s 0:00.05 100.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=40.155	 wallclock=63.92
40.244u 3.014s 0:35.03 123.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:40:24 ) 16.65user 0.66system 0:10.57elapsed 163%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:40:35 ) 1996.98user 6.63system 33:07.82elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:13:43 ) 350.25user 1.12system 2:56.80elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:16:39 ) 0.018u 0.001s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 02:16:39 ) 0.033u 0.013s 0:00.04 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000123009987874
:CHARGE convergence:  0.0024156
>lapw0      ( 02:16:40 ) starting parallel lapw0 at Thu Jan 30 02:16:40 CST 2014
-------- .machine0 : 2 processors
1.290u 0.124s 0:02.82 50.0%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:16:43 ) starting parallel lapw1 at Thu Jan 30 02:16:43 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:16:43 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 25696
[2] 25715
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 25779
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(665) 35.959u 0.643s 0:36.81 99.4%	0+0k 0+0io 0pf+0w
     node022(665) 35.962u 0.708s 0:36.71 99.8%	0+0k 0+0io 0pf+0w
     node022(1) 0.374u 0.013s 0:00.38 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=1331	 user=72.295	 wallclock=73.9
72.424u 1.593s 0:41.34 179.0%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:17:24 ) running LAPWSO in parallel mode
[1] 25919
[2] 25926
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 26009
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 19.997u 1.344s 0:28.89 73.8% 0+0k 0+0io 0pf+0w
      node022 20.180u 1.291s 0:34.06 63.0% 0+0k 0+0io 0pf+0w
      node022 0.035u 0.007s 0:00.04 75.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=40.212	 wallclock=62.99
40.300u 2.976s 0:35.39 122.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:17:59 ) 16.67user 0.69system 0:10.91elapsed 159%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:18:10 ) 1991.16user 6.75system 33:01.03elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:51:11 ) 349.45user 1.11system 2:56.38elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:54:08 ) 0.017u 0.002s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 02:54:08 ) 0.027u 0.020s 0:00.05 80.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  5.0100061344e-06
:CHARGE convergence:  0.0028642
>lapw0      ( 02:54:08 ) starting parallel lapw0 at Thu Jan 30 02:54:08 CST 2014
-------- .machine0 : 2 processors
1.300u 0.106s 0:02.82 49.6%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:54:11 ) starting parallel lapw1 at Thu Jan 30 02:54:11 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:54:11 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 26742
[2] 26761
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 26825
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(665) 35.804u 0.667s 0:36.51 99.8%	0+0k 0+0io 0pf+0w
     node022(665) 35.996u 0.694s 0:38.19 96.0%	0+0k 0+0io 0pf+0w
     node022(1) 0.382u 0.008s 0:00.39 97.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=1331	 user=72.182	 wallclock=75.09
72.307u 1.598s 0:41.34 178.7%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:54:52 ) running LAPWSO in parallel mode
[1] 26965
[2] 26971
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 27067
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 19.995u 1.325s 0:32.07 66.4% 0+0k 0+0io 0pf+0w
      node022 20.150u 1.334s 0:32.34 66.4% 0+0k 0+0io 0pf+0w
      node022 0.038u 0.004s 0:00.04 75.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=40.183	 wallclock=64.45
40.262u 3.026s 0:34.11 126.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:55:27 ) 16.67user 0.68system 0:10.15elapsed 170%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:55:37 ) 1498.88user 6.57system 24:50.14elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:20:27 ) 349.34user 1.16system 2:56.40elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:23:23 ) 0.013u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 03:23:23 ) 0.031u 0.016s 0:00.05 80.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  5.890999455e-05
:CHARGE convergence:  0.001253
>lapw0      ( 03:23:23 ) starting parallel lapw0 at Thu Jan 30 03:23:27 CST 2014
-------- .machine0 : 2 processors
1.287u 0.111s 0:02.81 49.4%	0+0k 0+0io 13pf+0w
>lapw1      ( 03:23:29 ) starting parallel lapw1 at Thu Jan 30 03:23:29 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 03:23:30 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 27706
[2] 27725
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 27789
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(665) 35.853u 0.659s 0:37.13 98.3%	0+0k 0+0io 0pf+0w
     node022(665) 36.003u 0.704s 0:37.28 98.4%	0+0k 0+0io 0pf+0w
     node022(1) 0.380u 0.008s 0:00.38 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=1331	 user=72.236	 wallclock=74.79
72.367u 1.593s 0:41.34 178.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:24:11 ) running LAPWSO in parallel mode
[1] 27930
[2] 27936
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 28045
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 20.054u 1.320s 0:34.81 61.3% 0+0k 0+0io 0pf+0w
      node022 20.201u 1.313s 0:34.80 61.8% 0+0k 0+0io 0pf+0w
      node022 0.043u 0.013s 0:00.05 100.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=40.298	 wallclock=69.66
40.386u 3.015s 0:37.44 115.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:24:48 ) 16.62user 0.68system 0:13.72elapsed 126%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:25:02 ) 1483.36user 6.64system 24:33.38elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:49:35 ) 349.84user 1.13system 2:59.58elapsed 195%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:52:35 ) 0.013u 0.005s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 03:52:35 ) 0.033u 0.016s 0:00.05 80.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  3.19000100717e-05
:CHARGE convergence:  0.0007831
>lapw0      ( 03:52:35 ) starting parallel lapw0 at Thu Jan 30 03:52:35 CST 2014
-------- .machine0 : 2 processors
1.296u 0.129s 0:02.82 50.0%	0+0k 0+0io 13pf+0w
>lapw1      ( 03:52:38 ) starting parallel lapw1 at Thu Jan 30 03:52:38 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 03:52:38 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 28675
[2] 28694
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 28758
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(665) 35.835u 0.686s 0:36.53 99.9%	0+0k 0+0io 0pf+0w
     node022(665) 36.055u 0.650s 0:37.39 98.1%	0+0k 0+0io 0pf+0w
     node022(1) 0.377u 0.014s 0:00.39 97.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=1331	 user=72.267	 wallclock=74.31
72.398u 1.572s 0:41.34 178.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:53:20 ) running LAPWSO in parallel mode
[1] 28898
[2] 28904
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 29007
[3]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 20.012u 1.310s 0:30.98 68.8% 0+0k 0+0io 0pf+0w
      node022 20.216u 1.306s 0:32.60 65.9% 0+0k 0+0io 0pf+0w
      node022 0.039u 0.012s 0:02.16 1.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=40.267	 wallclock=65.74
40.350u 2.987s 0:34.65 125.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:53:54 ) 16.71user 0.66system 0:10.97elapsed 158%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:54:05 ) 1468.33user 6.56system 24:18.83elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:18:24 ) 349.42user 1.15system 2:56.39elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:21:21 ) 0.017u 0.004s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 04:21:21 ) 0.037u 0.011s 0:00.05 80.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  3.13700002152e-05
:CHARGE convergence:  0.0015793
>lapw0      ( 04:21:21 ) starting parallel lapw0 at Thu Jan 30 04:21:21 CST 2014
-------- .machine0 : 2 processors
1.312u 0.111s 0:02.82 50.3%	0+0k 0+0io 13pf+0w
>lapw1      ( 04:21:24 ) starting parallel lapw1 at Thu Jan 30 04:21:24 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 04:21:24 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 30102
[2] 30121
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 30185
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(665) 35.903u 0.642s 0:36.71 99.5%	0+0k 0+0io 0pf+0w
     node022(665) 36.014u 0.682s 0:37.60 97.5%	0+0k 0+0io 0pf+0w
     node022(1) 0.377u 0.013s 0:04.31 8.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=1331	 user=72.294	 wallclock=78.62
72.426u 1.565s 0:44.64 165.7%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:22:08 ) running LAPWSO in parallel mode
[1] 30326
[2] 30332
[3] 30435
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 19.947u 1.344s 0:33.44 63.6% 0+0k 0+0io 0pf+0w
      node022 20.155u 1.323s 0:35.10 61.1% 0+0k 0+0io 0pf+0w
      node022 0.043u 0.010s 0:00.07 71.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=40.145	 wallclock=68.61
40.235u 3.037s 0:36.43 118.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:22:45 ) 16.67user 0.68system 0:10.76elapsed 161%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:22:56 ) 1967.01user 6.58system 32:38.23elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:55:34 ) 349.30user 1.18system 2:59.34elapsed 195%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:58:33 ) 0.018u 0.003s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 04:58:33 ) 0.036u 0.013s 0:00.05 80.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  3.52399947587e-05
:CHARGE convergence:  0.0008113
>lapw0      ( 04:58:34 ) starting parallel lapw0 at Thu Jan 30 04:58:34 CST 2014
-------- .machine0 : 2 processors
1.280u 0.123s 0:02.81 49.8%	0+0k 0+0io 13pf+0w
>lapw1      ( 04:58:36 ) starting parallel lapw1 at Thu Jan 30 04:58:37 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 04:58:37 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 31161
[2] 31180
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 31244
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(665) 35.908u 0.646s 0:37.69 96.9%	0+0k 0+0io 0pf+0w
     node022(665) 36.056u 0.640s 0:37.61 97.5%	0+0k 0+0io 0pf+0w
     node022(1) 0.381u 0.012s 0:00.39 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=1331	 user=72.345	 wallclock=75.69
72.490u 1.515s 0:41.34 179.0%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:59:18 ) running LAPWSO in parallel mode
[1] 31384
[2] 31391
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 31483
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 19.965u 1.347s 0:33.30 63.9% 0+0k 0+0io 0pf+0w
      node022 20.164u 1.375s 0:31.29 68.8% 0+0k 0+0io 0pf+0w
      node022 0.043u 0.008s 0:00.07 57.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=40.172	 wallclock=64.66
40.263u 3.092s 0:33.71 128.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:59:52 ) 16.65user 0.67system 0:10.42elapsed 166%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 05:00:02 ) 1467.11user 6.53system 24:17.97elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:24:20 ) 350.18user 1.10system 2:56.75elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 05:27:17 ) 0.019u 0.001s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 05:27:20 ) 0.038u 0.012s 0:00.05 80.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.39100011438e-05
:CHARGE convergence:  0.0003903
>lapw0      ( 05:27:20 ) starting parallel lapw0 at Thu Jan 30 05:27:20 CST 2014
-------- .machine0 : 2 processors
1.308u 0.108s 0:02.81 49.8%	0+0k 0+0io 13pf+0w
>lapw1      ( 05:27:23 ) starting parallel lapw1 at Thu Jan 30 05:27:26 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 05:27:26 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 32117
[2] 32136
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 32200
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(665) 35.881u 0.653s 0:36.93 98.9%	0+0k 0+0io 0pf+0w
     node022(665) 35.981u 0.683s 0:37.32 98.2%	0+0k 0+0io 0pf+0w
     node022(1) 0.380u 0.010s 0:00.39 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=1331	 user=72.242	 wallclock=74.64
72.372u 1.564s 0:41.34 178.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 05:28:07 ) running LAPWSO in parallel mode
[1] 32340
[2] 32346
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 32449
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 19.983u 1.344s 0:32.60 65.3% 0+0k 0+0io 0pf+0w
      node022 20.174u 1.316s 0:32.74 65.6% 0+0k 0+0io 0pf+0w
      node022 0.036u 0.011s 0:00.05 80.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=40.193	 wallclock=65.39
40.279u 3.031s 0:35.12 123.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 05:28:43 ) 16.63user 0.68system 0:12.98elapsed 133%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 05:28:56 ) 1585.26user 6.64system 26:17.37elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:55:13 ) 349.61user 1.09system 2:56.45elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 05:58:09 ) 0.021u 0.000s 0:00.02 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 05:58:10 ) 0.034u 0.018s 0:00.05 80.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.33400060097e-05
:CHARGE convergence:  0.0001051
>lapw0      ( 05:58:10 ) starting parallel lapw0 at Thu Jan 30 05:58:10 CST 2014
-------- .machine0 : 2 processors
1.301u 0.096s 0:02.80 49.6%	0+0k 0+0io 13pf+0w
>lapw1      ( 05:58:13 ) starting parallel lapw1 at Thu Jan 30 05:58:13 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 05:58:13 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 651
[2] 670
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 734
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node022(665) 35.845u 0.662s 0:36.54 99.8%	0+0k 0+0io 0pf+0w
     node022(665) 36.051u 0.634s 0:37.46 97.9%	0+0k 0+0io 0pf+0w
     node022(1) 0.375u 0.010s 0:00.38 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node022	 k=1331	 user=72.271	 wallclock=74.38
72.398u 1.533s 0:41.34 178.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 05:58:54 ) running LAPWSO in parallel mode
[1] 885
[2] 891
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 982
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node022 19.960u 1.334s 0:31.63 67.3% 0+0k 0+0io 0pf+0w
      node022 20.168u 1.343s 0:31.92 67.3% 0+0k 0+0io 0pf+0w
      node022 0.045u 0.007s 0:00.08 50.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node022	 user=40.173	 wallclock=63.63
40.260u 3.028s 0:33.25 130.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 05:59:27 ) 16.70user 0.68system 0:10.42elapsed 166%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 05:59:38 ) 1969.33user 6.58system 32:39.32elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:32:17 ) 349.87user 1.03system 2:56.54elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:35:14 ) 0.019u 0.002s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 06:35:14 ) 0.034u 0.018s 0:00.05 80.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.39000655711e-06
:CHARGE convergence:  0.0003904
