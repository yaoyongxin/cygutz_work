Calculating gamma_Pu_6 in /scratch/ykent33701/gamma_Pu_6
on node018 with PID 20142




   start        Wed Jan 29 22:46:30 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 22:46:30 2014 1000/0 to go

>lapw0      ( 22:46:30 ) starting parallel lapw0 at Wed Jan 29 22:46:36 CST 2014
-------- .machine0 : 2 processors
2.127u 0.115s 0:07.09 31.4%	0+0k 0+0io 13pf+0w
>lapw1      ( 22:46:43 ) starting parallel lapw1 at Wed Jan 29 22:46:43 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 22:46:43 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 20699
[2] 20962
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 21676
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 60.392u 0.980s 1:58.49 51.7%	0+0k 0+0io 0pf+0w
     node018(665) 60.370u 0.965s 1:57.27 52.2%	0+0k 0+0io 0pf+0w
     node018(1) 0.340u 0.009s 0:00.35 97.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=121.102	 wallclock=236.11
121.290u 2.175s 2:04.43 99.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:48:47 ) running LAPWSO in parallel mode
[1] 21924
[2] 21972
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 23412
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 42.009u 2.464s 3:26.37 21.5% 0+0k 0+0io 0pf+0w
      node018 40.916u 2.366s 3:06.50 23.2% 0+0k 0+0io 0pf+0w
      node018 0.070u 0.009s 0:00.08 87.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=82.995	 wallclock=392.95
83.126u 5.169s 3:26.48 42.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:52:14 ) 24.10user 0.91system 0:30.77elapsed 81%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:52:45 ) 5662.91user 10.04system 1:34:03elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:26:52 ) 424.52user 1.44system 3:41.30elapsed 192%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:30:33 ) 0.014u 0.000s 0:01.99 0.5%	0+0k 0+0io 0pf+0w
>mixer      ( 00:30:42 ) 0.025u 0.009s 0:01.32 1.5%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0089317
>lapw0      ( 00:30:48 ) starting parallel lapw0 at Thu Jan 30 00:30:48 CST 2014
-------- .machine0 : 2 processors
2.123u 0.089s 0:08.31 26.4%	0+0k 0+0io 13pf+0w
>lapw1      ( 00:30:56 ) starting parallel lapw1 at Thu Jan 30 00:31:00 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 00:31:00 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 25065
[2] 25084
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 25479
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 60.484u 0.958s 1:07.32 91.2%	0+0k 0+0io 0pf+0w
     node018(665) 60.205u 1.011s 1:06.45 92.1%	0+0k 0+0io 0pf+0w
     node018(1) 0.326u 0.010s 0:00.34 97.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=121.015	 wallclock=134.11
121.144u 2.166s 1:13.26 168.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 00:32:11 ) running LAPWSO in parallel mode
[1] 25621
[2] 25629
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 26647
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 41.733u 2.082s 1:50.04 39.8% 0+0k 0+0io 0pf+0w
      node018 40.844u 2.056s 2:00.10 35.7% 0+0k 0+0io 0pf+0w
      node018 0.083u 0.014s 0:01.54 5.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=82.66	 wallclock=231.68
82.764u 4.684s 2:03.57 70.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:34:15 ) 24.15user 0.92system 0:32.27elapsed 77%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:34:47 ) 2325.06user 7.24system 38:37.37elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:13:24 ) 470.79user 1.88system 3:57.43elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:17:22 ) 0.013u 0.001s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 01:17:22 ) 0.020u 0.015s 0:00.03 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  4.22100129072e-05
:CHARGE convergence:  0.0081532
>lapw0      ( 01:17:22 ) starting parallel lapw0 at Thu Jan 30 01:17:22 CST 2014
-------- .machine0 : 2 processors
1.964u 0.110s 0:03.12 66.3%	0+0k 0+0io 13pf+0w
>lapw1      ( 01:17:25 ) starting parallel lapw1 at Thu Jan 30 01:17:25 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:17:25 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 29164
[2] 29183
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 29280
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 65.812u 1.058s 1:07.11 99.6%	0+0k 0+0io 0pf+0w
     node018(665) 61.382u 0.995s 1:03.72 97.8%	0+0k 0+0io 0pf+0w
     node018(1) 0.330u 0.012s 0:00.39 87.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=127.524	 wallclock=131.22
127.649u 2.281s 1:10.42 184.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:18:36 ) running LAPWSO in parallel mode
[1] 29431
[2] 29437
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 29939
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 43.260u 2.101s 1:21.77 55.4% 0+0k 0+0io 0pf+0w
      node018 41.662u 2.073s 1:25.19 51.3% 0+0k 0+0io 0pf+0w
      node018 0.071u 0.012s 0:01.29 6.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=84.993	 wallclock=168.25
85.089u 4.685s 1:26.60 103.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:20:02 ) 24.61user 1.03system 0:16.23elapsed 158%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:20:19 ) 2978.33user 7.89system 49:24.77elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:09:43 ) 480.03user 1.85system 4:02.03elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:13:45 ) 0.009u 0.005s 0:00.01 0.0%	0+0k 0+0io 0pf+0w
>mixer      ( 02:13:45 ) 0.026u 0.012s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000402009987738
:CHARGE convergence:  0.0025045
>lapw0      ( 02:13:46 ) starting parallel lapw0 at Thu Jan 30 02:13:46 CST 2014
-------- .machine0 : 2 processors
2.087u 0.116s 0:03.21 68.2%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:13:49 ) starting parallel lapw1 at Thu Jan 30 02:13:49 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:13:49 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 477
[2] 496
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 593
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 64.339u 1.028s 1:06.74 97.9%	0+0k 0+0io 0pf+0w
     node018(665) 64.365u 1.096s 1:05.75 99.5%	0+0k 0+0io 0pf+0w
     node018(1) 0.330u 0.018s 0:00.40 85.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=129.034	 wallclock=132.89
129.151u 2.367s 1:10.40 186.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:14:59 ) running LAPWSO in parallel mode
[1] 756
[2] 762
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 1370
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 43.612u 2.125s 1:37.71 46.8% 0+0k 0+0io 0pf+0w
      node018 42.839u 2.190s 1:35.32 47.2% 0+0k 0+0io 0pf+0w
      node018 0.070u 0.016s 0:00.09 88.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=86.521	 wallclock=193.12
86.641u 4.867s 1:40.66 90.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:16:40 ) 25.46user 1.35system 0:16.92elapsed 158%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:16:57 ) 2184.41user 8.50system 36:15.78elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:53:13 ) 459.50user 1.69system 3:51.70elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:57:05 ) 0.012u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 02:57:05 ) 0.028u 0.018s 0:00.09 33.3%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  7.2029986768e-05
:CHARGE convergence:  0.0010587
>lapw0      ( 02:57:05 ) starting parallel lapw0 at Thu Jan 30 02:57:05 CST 2014
-------- .machine0 : 2 processors
2.070u 0.113s 0:03.20 68.1%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:57:08 ) starting parallel lapw1 at Thu Jan 30 02:57:08 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:57:08 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 3418
[2] 3437
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 3542
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 60.382u 0.982s 1:05.03 94.3%	0+0k 0+0io 0pf+0w
     node018(665) 60.334u 1.011s 1:02.74 97.7%	0+0k 0+0io 0pf+0w
     node018(1) 0.330u 0.019s 0:00.35 97.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=121.046	 wallclock=128.12
121.152u 2.253s 1:08.34 180.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:58:16 ) running LAPWSO in parallel mode
[1] 3702
[2] 3708
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 3940
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 44.435u 2.130s 1:55.53 40.3% 0+0k 0+0io 0pf+0w
      node018 43.119u 2.250s 1:52.49 40.3% 0+0k 0+0io 0pf+0w
      node018 0.073u 0.011s 0:01.34 5.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=87.627	 wallclock=229.36
87.737u 4.933s 1:57.24 79.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:00:14 ) 26.43user 1.37system 0:18.71elapsed 148%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:00:32 ) 2181.93user 8.37system 36:11.03elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:36:45 ) 436.32user 1.56system 3:40.06elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:40:25 ) 0.011u 0.003s 0:00.22 4.5%	0+0k 0+0io 0pf+0w
>mixer      ( 03:40:26 ) 0.028u 0.012s 0:00.09 33.3%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000104750011815
:CHARGE convergence:  0.0008833
>lapw0      ( 03:40:26 ) starting parallel lapw0 at Thu Jan 30 03:40:26 CST 2014
-------- .machine0 : 2 processors
2.084u 0.111s 0:03.19 68.6%	0+0k 0+0io 13pf+0w
>lapw1      ( 03:40:29 ) starting parallel lapw1 at Thu Jan 30 03:40:29 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 03:40:29 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 6225
[2] 6244
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 6349
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 63.693u 1.021s 1:06.67 97.0%	0+0k 0+0io 0pf+0w
     node018(665) 63.279u 1.095s 1:06.55 96.7%	0+0k 0+0io 0pf+0w
     node018(1) 0.328u 0.015s 0:00.34 97.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=127.3	 wallclock=133.56
127.422u 2.345s 1:09.03 187.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:41:38 ) running LAPWSO in parallel mode
[1] 6490
[2] 6496
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 6716
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 43.856u 2.157s 1:24.09 54.7% 0+0k 0+0io 0pf+0w
      node018 42.996u 2.200s 1:23.66 54.0% 0+0k 0+0io 0pf+0w
      node018 0.074u 0.012s 0:00.09 88.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=86.926	 wallclock=167.84
87.049u 4.910s 1:26.63 106.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:43:08 ) 25.76user 1.37system 0:19.22elapsed 141%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:43:27 ) 2538.47user 8.25system 42:07.64elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:25:35 ) 459.77user 1.82system 3:51.85elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:29:27 ) 0.012u 0.003s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 04:29:27 ) 0.026u 0.015s 0:00.05 60.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  4.33100067312e-05
:CHARGE convergence:  0.0002098
>lapw0      ( 04:29:27 ) starting parallel lapw0 at Thu Jan 30 04:29:27 CST 2014
-------- .machine0 : 2 processors
2.080u 0.113s 0:03.20 68.4%	0+0k 0+0io 13pf+0w
>lapw1      ( 04:29:30 ) starting parallel lapw1 at Thu Jan 30 04:29:30 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 04:29:30 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 10325
[2] 10344
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 10444
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 67.601u 1.069s 1:09.54 98.7%	0+0k 0+0io 0pf+0w
     node018(665) 63.700u 1.030s 1:05.39 98.9%	0+0k 0+0io 0pf+0w
     node018(1) 0.333u 0.015s 0:00.35 97.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=131.634	 wallclock=135.28
131.744u 2.354s 1:11.41 187.7%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:30:42 ) running LAPWSO in parallel mode
[1] 10586
[2] 10593
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 10847
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 43.195u 2.155s 1:31.36 49.6% 0+0k 0+0io 0pf+0w
      node018 42.137u 2.154s 1:34.17 47.0% 0+0k 0+0io 0pf+0w
      node018 0.073u 0.015s 0:00.09 88.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=85.405	 wallclock=185.62
85.501u 4.876s 1:35.61 94.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:32:17 ) 24.82user 1.12system 0:17.00elapsed 152%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:32:34 ) 2167.20user 8.52system 35:55.89elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:08:30 ) 481.30user 1.89system 4:02.68elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 05:12:33 ) 0.011u 0.003s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 05:12:33 ) 0.027u 0.015s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  8.20000423118e-07
:CHARGE convergence:  7.2e-05
