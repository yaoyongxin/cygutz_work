Calculating gamma_Pu_7 in /scratch/ykent33702/gamma_Pu_7
on node018 with PID 20140




   start        Wed Jan 29 22:46:31 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 22:46:31 2014 1000/0 to go

>lapw0      ( 22:46:31 ) starting parallel lapw0 at Wed Jan 29 22:46:36 CST 2014
-------- .machine0 : 2 processors
2.284u 0.112s 0:07.19 33.2%	0+0k 0+0io 13pf+0w
>lapw1      ( 22:46:43 ) starting parallel lapw1 at Wed Jan 29 22:46:43 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 22:46:43 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 20905
[2] 20982
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 21645
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 65.150u 1.012s 1:56.62 56.7%	0+0k 0+0io 0pf+0w
     node018(665) 65.164u 1.006s 1:52.64 58.7%	0+0k 0+0io 0pf+0w
     node018(1) 0.331u 0.011s 0:00.36 94.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=130.645	 wallclock=229.62
130.819u 2.268s 2:01.63 109.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:48:45 ) running LAPWSO in parallel mode
[1] 21962
[2] 21978
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 23334
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 46.169u 2.391s 2:50.22 28.5% 0+0k 0+0io 0pf+0w
      node018 45.575u 2.503s 3:29.18 22.9% 0+0k 0+0io 0pf+0w
      node018 0.081u 0.009s 0:00.12 66.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=91.825	 wallclock=379.52
91.937u 5.248s 3:34.87 45.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:52:20 ) 25.39user 1.02system 0:48.64elapsed 54%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:53:08 ) 5672.05user 10.48system 1:34:09elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:27:19 ) 451.96user 1.57system 3:52.00elapsed 195%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:31:11 ) 0.011u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 00:31:11 ) 0.022u 0.013s 0:00.05 60.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0084918
>lapw0      ( 00:31:12 ) starting parallel lapw0 at Thu Jan 30 00:31:13 CST 2014
-------- .machine0 : 2 processors
3.447u 0.096s 0:06.42 54.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 00:31:18 ) starting parallel lapw1 at Thu Jan 30 00:31:23 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 00:31:23 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 25343
[2] 25363
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 25791
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 65.033u 1.041s 1:26.07 76.7%	0+0k 0+0io 0pf+0w
     node018(665) 64.879u 1.031s 1:24.43 78.0%	0+0k 0+0io 0pf+0w
     node018(1) 0.324u 0.011s 0:05.72 5.7%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=130.236	 wallclock=176.22
130.383u 2.264s 1:36.66 137.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 00:32:57 ) running LAPWSO in parallel mode
[1] 26185
[2] 26213
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 27207
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 46.477u 2.197s 2:51.90 28.3% 0+0k 0+0io 0pf+0w
      node018 45.670u 2.250s 2:30.47 31.8% 0+0k 0+0io 0pf+0w
      node018 0.087u 0.011s 0:01.66 5.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=92.234	 wallclock=324.03
92.358u 5.049s 2:53.71 56.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:35:55 ) 26.07user 1.19system 0:28.29elapsed 96%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:36:23 ) 2350.88user 7.26system 39:01.78elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:15:26 ) 457.21user 1.77system 3:50.58elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:19:17 ) 0.013u 0.000s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 01:19:18 ) 0.023u 0.013s 0:00.09 33.3%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.93799967039e-05
:CHARGE convergence:  0.0077
>lapw0      ( 01:19:18 ) starting parallel lapw0 at Thu Jan 30 01:19:18 CST 2014
-------- .machine0 : 2 processors
2.560u 0.100s 0:09.28 28.6%	0+0k 0+0io 14pf+0w
>lapw1      ( 01:19:27 ) starting parallel lapw1 at Thu Jan 30 01:19:27 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:19:27 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 29814
[2] 29837
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 30070
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 68.235u 1.092s 1:29.44 77.5%	0+0k 0+0io 0pf+0w
     node018(665) 66.877u 1.034s 1:24.88 79.9%	0+0k 0+0io 0pf+0w
     node018(1) 0.337u 0.010s 0:00.34 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=135.449	 wallclock=174.66
135.589u 2.333s 1:30.76 151.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:20:58 ) running LAPWSO in parallel mode
[1] 30213
[2] 30219
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 30477
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 47.757u 2.258s 1:26.83 57.5% 0+0k 0+0io 0pf+0w
      node018 46.512u 2.318s 1:23.78 58.2% 0+0k 0+0io 0pf+0w
      node018 0.077u 0.011s 0:00.11 72.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=94.346	 wallclock=170.72
94.466u 5.137s 1:30.80 109.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:22:29 ) 25.90user 1.08system 0:16.04elapsed 168%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:22:45 ) 8678.67user 15.16system 2:23:59elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:46:45 ) 477.29user 1.74system 4:00.60elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:50:45 ) 0.010u 0.004s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 03:50:46 ) 0.019u 0.020s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000432290005847
:CHARGE convergence:  0.0018502
>lapw0      ( 03:50:46 ) starting parallel lapw0 at Thu Jan 30 03:50:46 CST 2014
-------- .machine0 : 2 processors
2.159u 0.116s 0:03.23 69.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 03:50:49 ) starting parallel lapw1 at Thu Jan 30 03:50:49 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 03:50:49 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 7922
[2] 7941
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 8044
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 70.044u 1.109s 1:12.13 98.6%	0+0k 0+0io 0pf+0w
     node018(665) 67.721u 1.102s 1:09.76 98.6%	0+0k 0+0io 0pf+0w
     node018(1) 0.340u 0.010s 0:00.35 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=138.105	 wallclock=142.24
138.229u 2.454s 1:14.43 188.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:52:03 ) running LAPWSO in parallel mode
[1] 8185
[2] 8191
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 8692
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 48.115u 2.274s 1:43.76 48.5% 0+0k 0+0io 0pf+0w
      node018 48.068u 2.450s 1:27.69 57.6% 0+0k 0+0io 0pf+0w
      node018 0.078u 0.019s 0:00.11 72.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=96.261	 wallclock=191.56
96.375u 5.322s 1:44.57 97.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:53:48 ) 26.54user 1.35system 0:24.53elapsed 113%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:54:13 ) 2511.11user 8.91system 41:41.51elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:35:54 ) 467.86user 1.71system 3:55.92elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:39:50 ) 0.012u 0.003s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 04:39:50 ) 0.023u 0.016s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  7.96600070316e-05
:CHARGE convergence:  0.0010444
>lapw0      ( 04:39:50 ) starting parallel lapw0 at Thu Jan 30 04:39:50 CST 2014
-------- .machine0 : 2 processors
2.374u 0.107s 0:03.34 73.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 04:39:54 ) starting parallel lapw1 at Thu Jan 30 04:40:03 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 04:40:03 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 12061
[2] 12081
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 12184
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 66.822u 1.098s 1:10.37 96.5%	0+0k 0+0io 0pf+0w
     node018(665) 69.870u 1.120s 1:12.86 97.4%	0+0k 0+0io 0pf+0w
     node018(1) 0.340u 0.015s 0:00.43 81.3%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=137.032	 wallclock=143.66
137.181u 2.450s 1:16.46 182.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:41:19 ) running LAPWSO in parallel mode
[1] 12327
[2] 12333
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 12587
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 47.665u 2.268s 1:33.82 53.2% 0+0k 0+0io 0pf+0w
      node018 46.724u 2.308s 1:28.10 55.6% 0+0k 0+0io 0pf+0w
      node018 0.083u 0.012s 0:00.09 100.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=94.472	 wallclock=182.01
94.587u 5.138s 1:34.24 105.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:42:54 ) 26.88user 1.42system 0:19.08elapsed 148%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:43:13 ) 2240.71user 8.61system 37:09.05elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:20:22 ) 458.83user 1.86system 3:51.42elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 05:24:13 ) 0.010u 0.004s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 05:24:13 ) 0.026u 0.015s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000137879993417
:CHARGE convergence:  0.0017609
>lapw0      ( 05:24:13 ) starting parallel lapw0 at Thu Jan 30 05:24:13 CST 2014
-------- .machine0 : 2 processors
2.188u 0.122s 0:03.26 70.5%	0+0k 0+0io 13pf+0w
>lapw1      ( 05:24:17 ) starting parallel lapw1 at Thu Jan 30 05:24:20 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 05:24:20 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 14262
[2] 14282
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 14385
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 68.675u 1.068s 1:09.82 99.8%	0+0k 0+0io 0pf+0w
     node018(665) 68.901u 1.160s 1:11.68 97.7%	0+0k 0+0io 0pf+0w
     node018(1) 0.335u 0.014s 0:00.35 97.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=137.911	 wallclock=141.85
138.023u 2.480s 1:14.81 187.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 05:25:34 ) running LAPWSO in parallel mode
[1] 14525
[2] 14531
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 14742
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 47.892u 2.229s 1:29.42 56.0% 0+0k 0+0io 0pf+0w
      node018 46.701u 2.352s 1:21.45 60.2% 0+0k 0+0io 0pf+0w
      node018 0.077u 0.012s 0:00.09 88.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=94.67	 wallclock=170.96
94.782u 5.144s 1:30.01 111.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 05:27:05 ) 25.36user 1.12system 0:17.88elapsed 148%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 05:27:22 ) 1767.42user 7.24system 29:14.88elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:56:37 ) 428.94user 1.37system 3:36.33elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:00:14 ) 0.016u 0.004s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 06:00:14 ) 0.031u 0.018s 0:00.05 80.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  6.07599940849e-05
:CHARGE convergence:  0.000213
>lapw0      ( 06:00:14 ) starting parallel lapw0 at Thu Jan 30 06:00:14 CST 2014
-------- .machine0 : 2 processors
1.857u 0.132s 0:03.10 63.8%	0+0k 0+0io 13pf+0w
>lapw1      ( 06:00:17 ) starting parallel lapw1 at Thu Jan 30 06:00:17 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 06:00:17 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 15759
[2] 15779
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 15881
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 63.787u 1.047s 1:05.78 98.5%	0+0k 0+0io 0pf+0w
     node018(665) 63.929u 1.055s 1:05.06 99.8%	0+0k 0+0io 0pf+0w
     node018(1) 0.344u 0.014s 0:00.36 97.2%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=128.06	 wallclock=131.2
128.212u 2.377s 1:08.43 190.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 06:01:26 ) running LAPWSO in parallel mode
[1] 16021
[2] 16027
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 16264
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 45.402u 2.172s 1:35.72 49.6% 0+0k 0+0io 0pf+0w
      node018 45.072u 2.184s 1:33.73 50.4% 0+0k 0+0io 0pf+0w
      node018 0.080u 0.015s 0:00.09 100.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=90.554	 wallclock=189.54
90.664u 5.006s 1:40.84 94.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 06:03:07 ) 25.21user 1.01system 0:14.58elapsed 179%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 06:03:21 ) 1373.41user 6.71system 22:41.28elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:26:02 ) 427.82user 1.43system 3:35.72elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:29:38 ) 0.017u 0.001s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 06:29:59 ) 0.031u 0.017s 0:00.05 80.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  6.55000621919e-06
:CHARGE convergence:  0.0001286
