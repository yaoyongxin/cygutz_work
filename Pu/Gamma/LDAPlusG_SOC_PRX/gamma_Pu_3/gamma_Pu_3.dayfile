Calculating gamma_Pu_3 in /scratch/ykent33698/gamma_Pu_3
on node020 with PID 26805




   start        Wed Jan 29 22:46:28 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 22:46:28 2014 1000/0 to go

>lapw0      ( 22:46:28 ) starting parallel lapw0 at Wed Jan 29 22:46:28 CST 2014
-------- .machine0 : 2 processors
2.148u 0.121s 0:03.33 67.8%	0+0k 0+0io 13pf+0w
>lapw1      ( 22:46:32 ) starting parallel lapw1 at Wed Jan 29 22:46:32 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 22:46:32 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 27587
[2] 27657
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 28114
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 47.482u 0.823s 1:08.95 70.0%	0+0k 0+0io 0pf+0w
     node020(665) 47.190u 0.830s 1:04.06 74.9%	0+0k 0+0io 0pf+0w
     node020(1) 0.336u 0.008s 0:00.36 91.6%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=95.008	 wallclock=133.37
95.143u 1.863s 1:10.12 138.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:47:42 ) running LAPWSO in parallel mode
[1] 28408
[2] 28421
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 29588
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 30.041u 1.819s 3:10.98 16.6% 0+0k 0+0io 0pf+0w
      node020 29.371u 1.762s 1:51.77 27.8% 0+0k 0+0io 0pf+0w
      node020 0.061u 0.010s 0:00.07 100.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=59.473	 wallclock=302.82
59.575u 3.860s 3:11.09 33.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:50:53 ) 20.39user 0.76system 0:17.56elapsed 120%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:51:10 ) 5219.18user 9.65system 1:26:36elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:17:48 ) 435.22user 1.55system 3:42.33elapsed 196%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:21:30 ) 0.013u 0.000s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 00:21:31 ) 0.024u 0.012s 0:00.15 20.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0093642
>lapw0      ( 00:21:36 ) starting parallel lapw0 at Thu Jan 30 00:21:37 CST 2014
-------- .machine0 : 2 processors
1.922u 0.098s 0:05.94 33.8%	0+0k 0+0io 13pf+0w
>lapw1      ( 00:21:43 ) starting parallel lapw1 at Thu Jan 30 00:21:43 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 00:21:43 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 32362
[2] 32385
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 453
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 47.959u 0.852s 1:48.19 45.1%	0+0k 0+0io 0pf+0w
     node020(665) 47.907u 0.918s 1:40.12 48.7%	0+0k 0+0io 0pf+0w
     node020(1) 0.348u 0.014s 0:01.44 24.3%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=96.214	 wallclock=209.75
96.351u 1.995s 1:49.47 89.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 00:23:32 ) running LAPWSO in parallel mode
[1] 662
[2] 671
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 1154
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 30.949u 1.757s 1:33.31 35.0% 0+0k 0+0io 0pf+0w
      node020 29.996u 1.725s 1:27.19 36.3% 0+0k 0+0io 0pf+0w
      node020 0.052u 0.010s 0:01.51 3.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=60.997	 wallclock=182.01
61.094u 3.965s 1:33.78 69.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:25:06 ) 20.39user 0.80system 0:16.29elapsed 130%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:25:22 ) 2259.43user 8.22system 37:30.84elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:02:55 ) 428.92user 1.52system 3:41.46elapsed 194%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:06:36 ) 0.013u 0.000s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 01:06:36 ) 0.022u 0.011s 0:00.03 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  4.24699974246e-05
:CHARGE convergence:  0.0083382
>lapw0      ( 01:06:36 ) starting parallel lapw0 at Thu Jan 30 01:06:36 CST 2014
-------- .machine0 : 2 processors
1.925u 0.115s 0:03.14 64.6%	0+0k 0+0io 13pf+0w
>lapw1      ( 01:06:39 ) starting parallel lapw1 at Thu Jan 30 01:06:40 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:06:40 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 2622
[2] 2642
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 2720
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 47.629u 0.812s 0:49.01 98.8%	0+0k 0+0io 0pf+0w
     node020(665) 47.274u 0.795s 0:48.98 98.1%	0+0k 0+0io 0pf+0w
     node020(1) 0.337u 0.008s 0:00.34 97.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=95.24	 wallclock=98.33
95.364u 1.793s 0:53.33 182.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:07:33 ) running LAPWSO in parallel mode
[1] 2860
[2] 2866
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 3024
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 30.323u 1.655s 0:49.94 64.0% 0+0k 0+0io 0pf+0w
      node020 29.575u 1.609s 0:45.61 68.3% 0+0k 0+0io 0pf+0w
      node020 0.050u 0.009s 0:00.06 83.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=59.948	 wallclock=95.61
60.033u 3.647s 0:50.26 126.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:08:23 ) 20.83user 0.90system 0:12.94elapsed 168%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:08:36 ) 2826.44user 8.29system 46:53.57elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:55:30 ) 438.50user 1.44system 3:41.07elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:59:11 ) 0.012u 0.002s 0:01.42 0.7%	0+0k 0+0io 0pf+0w
>mixer      ( 01:59:14 ) 0.025u 0.011s 0:00.09 33.3%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000320439998177
:CHARGE convergence:  0.0015779
>lapw0      ( 01:59:14 ) starting parallel lapw0 at Thu Jan 30 01:59:14 CST 2014
-------- .machine0 : 2 processors
1.898u 0.105s 0:05.02 39.6%	0+0k 0+0io 14pf+0w
>lapw1      ( 01:59:19 ) starting parallel lapw1 at Thu Jan 30 01:59:19 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:59:20 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 6398
[2] 6418
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 7174
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 48.056u 0.892s 1:13.83 66.2%	0+0k 0+0io 0pf+0w
     node020(665) 48.708u 0.882s 1:15.70 65.4%	0+0k 0+0io 0pf+0w
     node020(1) 0.344u 0.008s 0:00.87 39.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=97.108	 wallclock=150.4
97.248u 1.970s 1:19.15 125.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:00:39 ) running LAPWSO in parallel mode
[1] 7326
[2] 7336
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 7577
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 31.228u 1.708s 0:57.30 57.4% 0+0k 0+0io 0pf+0w
      node020 30.338u 1.725s 1:00.71 52.7% 0+0k 0+0io 0pf+0w
      node020 0.054u 0.009s 0:00.06 83.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=61.62	 wallclock=118.07
61.718u 3.855s 1:06.66 98.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:01:45 ) 20.71user 0.91system 0:14.03elapsed 154%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:01:59 ) 2527.28user 7.97system 42:00.69elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:44:00 ) 444.39user 1.47system 3:44.04elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:47:44 ) 0.011u 0.003s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 02:47:44 ) 0.025u 0.011s 0:00.03 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.09099928522e-05
:CHARGE convergence:  0.0014561
>lapw0      ( 02:47:44 ) starting parallel lapw0 at Thu Jan 30 02:47:44 CST 2014
-------- .machine0 : 2 processors
2.054u 0.100s 0:05.76 37.3%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:47:50 ) starting parallel lapw1 at Thu Jan 30 02:47:50 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:47:50 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 10018
[2] 10040
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 10260
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 49.700u 0.875s 1:10.43 71.8%	0+0k 0+0io 0pf+0w
     node020(665) 47.708u 0.852s 1:08.50 70.8%	0+0k 0+0io 0pf+0w
     node020(1) 0.339u 0.014s 0:00.41 82.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=97.747	 wallclock=139.34
97.880u 1.929s 1:14.40 134.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:49:05 ) running LAPWSO in parallel mode
[1] 10402
[2] 10408
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 10870
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 30.590u 1.770s 0:58.47 55.3% 0+0k 0+0io 0pf+0w
      node020 30.041u 1.672s 0:56.49 56.1% 0+0k 0+0io 0pf+0w
      node020 0.049u 0.015s 0:00.07 71.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=60.68	 wallclock=115.03
60.768u 3.858s 1:00.36 107.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:50:05 ) 20.91user 0.99system 0:13.97elapsed 156%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:50:19 ) 2255.51user 7.93system 37:27.33elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:27:47 ) 435.71user 1.63system 3:45.43elapsed 194%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:31:33 ) 0.011u 0.003s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 03:31:33 ) 0.020u 0.021s 0:00.08 50.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000134269997943
:CHARGE convergence:  0.0017558
>lapw0      ( 03:31:33 ) starting parallel lapw0 at Thu Jan 30 03:31:33 CST 2014
-------- .machine0 : 2 processors
2.275u 0.105s 0:03.28 72.2%	0+0k 0+0io 14pf+0w
>lapw1      ( 03:31:36 ) starting parallel lapw1 at Thu Jan 30 03:31:36 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 03:31:36 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 13388
[2] 13407
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 13489
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 50.340u 0.896s 0:51.47 99.5%	0+0k 0+0io 0pf+0w
     node020(665) 50.067u 0.870s 0:52.01 97.9%	0+0k 0+0io 0pf+0w
     node020(1) 0.340u 0.011s 0:00.35 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=100.747	 wallclock=103.83
100.845u 1.993s 0:56.34 182.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:32:33 ) running LAPWSO in parallel mode
[1] 13629
[2] 13636
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 13817
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 31.657u 1.792s 0:55.44 60.3% 0+0k 0+0io 0pf+0w
      node020 31.312u 1.793s 0:53.96 61.3% 0+0k 0+0io 0pf+0w
      node020 0.057u 0.008s 0:00.06 83.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=63.026	 wallclock=109.46
63.114u 4.028s 0:56.80 118.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:33:29 ) 20.55user 0.90system 0:12.86elapsed 166%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:33:42 ) 2716.33user 8.15system 45:06.95elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:18:49 ) 428.32user 1.72system 3:36.13elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:22:25 ) 0.010u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 04:22:26 ) 0.024u 0.014s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  6.93100009812e-05
:CHARGE convergence:  0.000466
>lapw0      ( 04:22:26 ) starting parallel lapw0 at Thu Jan 30 04:22:26 CST 2014
-------- .machine0 : 2 processors
1.921u 0.102s 0:03.10 65.1%	0+0k 0+0io 13pf+0w
>lapw1      ( 04:22:29 ) starting parallel lapw1 at Thu Jan 30 04:22:29 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 04:22:29 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 17203
[2] 17223
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 17301
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 49.912u 0.894s 0:50.94 99.7%	0+0k 0+0io 0pf+0w
     node020(665) 49.128u 0.876s 0:50.39 99.2%	0+0k 0+0io 0pf+0w
     node020(1) 0.344u 0.009s 0:00.40 85.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=99.384	 wallclock=101.73
99.487u 1.979s 0:53.33 190.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:23:22 ) running LAPWSO in parallel mode
[1] 17441
[2] 17447
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 17623
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 29.774u 1.603s 0:53.20 58.9% 0+0k 0+0io 0pf+0w
      node020 30.396u 1.704s 0:52.75 60.8% 0+0k 0+0io 0pf+0w
      node020 0.054u 0.013s 0:01.73 3.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=60.224	 wallclock=107.68
60.324u 3.721s 0:56.17 114.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:24:18 ) 21.20user 1.12system 0:13.73elapsed 162%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:24:32 ) 2692.85user 7.22system 44:42.11elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:09:14 ) 406.47user 1.39system 3:25.02elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 05:12:39 ) 0.011u 0.002s 0:00.24 4.1%	0+0k 0+0io 0pf+0w
>mixer      ( 05:12:42 ) 0.024u 0.013s 0:00.03 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.69995473698e-07
:CHARGE convergence:  0.0004791
