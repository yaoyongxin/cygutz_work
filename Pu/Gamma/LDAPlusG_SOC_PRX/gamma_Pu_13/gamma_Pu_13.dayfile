Calculating gamma_Pu_13 in /scratch/ykent33708/gamma_Pu_13
on node016 with PID 20619




   start        Wed Jan 29 22:46:28 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 22:46:28 2014 1000/0 to go

>lapw0      ( 22:46:28 ) starting parallel lapw0 at Wed Jan 29 22:46:28 CST 2014
-------- .machine0 : 2 processors
2.829u 0.139s 0:06.83 43.1%	0+0k 0+0io 14pf+0w
>lapw1      ( 22:46:35 ) starting parallel lapw1 at Wed Jan 29 22:46:35 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 22:46:35 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 21181
[2] 21317
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 22017
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 99.485u 2.949s 2:05.60 81.5%	0+0k 0+0io 0pf+0w
     node016(665) 99.255u 3.102s 2:09.73 78.8%	0+0k 0+0io 0pf+0w
     node016(1) 0.340u 0.011s 0:00.35 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=199.08	 wallclock=255.68
199.286u 6.331s 2:11.93 155.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:48:47 ) running LAPWSO in parallel mode
[1] 22174
[2] 22190
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 24977
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 79.186u 3.369s 3:44.68 36.7% 0+0k 0+0io 0pf+0w
      node016 79.731u 3.474s 3:41.35 37.5% 0+0k 0+0io 0pf+0w
      node016 0.122u 0.011s 0:00.13 100.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=159.039	 wallclock=446.16
159.208u 7.358s 3:46.85 73.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:52:34 ) 33.48user 1.33system 0:20.95elapsed 166%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:52:55 ) 6109.32user 10.72system 1:41:17elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:34:16 ) 535.00user 1.97system 4:45.56elapsed 188%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:39:01 ) 0.007u 0.005s 0:02.93 0.0%	0+0k 0+0io 0pf+0w
>mixer      ( 00:39:07 ) 0.023u 0.017s 0:00.77 3.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0035532
>lapw0      ( 00:39:08 ) starting parallel lapw0 at Thu Jan 30 00:39:08 CST 2014
-------- .machine0 : 2 processors
2.400u 0.122s 0:03.52 71.5%	0+0k 0+0io 13pf+0w
>lapw1      ( 00:39:12 ) starting parallel lapw1 at Thu Jan 30 00:39:12 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 00:39:17 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 29325
[2] 29352
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 30868
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 98.774u 2.938s 2:37.58 64.5%	0+0k 0+0io 0pf+0w
     node016(665) 98.730u 3.074s 2:40.69 63.3%	0+0k 0+0io 0pf+0w
     node016(1) 0.343u 0.012s 0:02.24 15.6%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=197.847	 wallclock=320.51
198.073u 6.285s 2:50.42 119.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 00:42:02 ) running LAPWSO in parallel mode
[1] 31029
[2] 31081
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 31831
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 80.613u 3.329s 2:23.04 58.6% 0+0k 0+0io 0pf+0w
      node016 81.808u 3.296s 2:31.14 56.2% 0+0k 0+0io 0pf+0w
      node016 0.120u 0.020s 0:00.14 100.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=162.541	 wallclock=294.32
162.700u 7.442s 2:34.39 110.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:44:36 ) 35.99user 1.79system 0:20.56elapsed 183%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:44:57 ) 2632.08user 9.00system 43:38.27elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:28:35 ) 580.93user 2.21system 4:52.77elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:33:28 ) 0.014u 0.001s 0:00.03 33.3%	0+0k 0+0io 0pf+0w
>mixer      ( 01:33:36 ) 0.026u 0.017s 0:00.19 15.7%	0+0k 0+0io 3pf+0w
:ENERGY convergence:  1.98000052478e-05
:CHARGE convergence:  0.0030202
>lapw0      ( 01:33:36 ) starting parallel lapw0 at Thu Jan 30 01:33:36 CST 2014
-------- .machine0 : 2 processors
2.958u 0.124s 0:04.38 70.0%	0+0k 0+0io 13pf+0w
>lapw1      ( 01:33:40 ) starting parallel lapw1 at Thu Jan 30 01:33:47 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:33:47 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 32729
[2] 32748
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 431
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 105.199u 3.330s 1:50.51 98.1%	0+0k 0+0io 0pf+0w
     node016(665) 106.816u 3.586s 1:51.60 98.9%	0+0k 0+0io 0pf+0w
     node016(1) 0.364u 0.014s 0:00.43 86.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=212.379	 wallclock=222.54
212.526u 7.204s 2:01.31 181.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:35:43 ) running LAPWSO in parallel mode
[1] 583
[2] 589
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 975
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 79.334u 3.191s 1:49.55 75.3% 0+0k 0+0io 0pf+0w
      node016 80.958u 3.108s 1:53.79 73.8% 0+0k 0+0io 0pf+0w
      node016 0.128u 0.017s 0:00.14 92.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=160.42	 wallclock=223.48
160.542u 7.056s 1:55.36 145.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:37:38 ) 34.16user 1.27system 0:28.77elapsed 123%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:38:07 ) 2448.73user 8.84system 40:32.24elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:18:39 ) 625.23user 2.32system 5:14.94elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:23:54 ) 0.012u 0.003s 0:00.03 33.3%	0+0k 0+0io 0pf+0w
>mixer      ( 02:23:54 ) 0.025u 0.019s 0:00.31 9.6%	0+0k 0+0io 7pf+0w
:ENERGY convergence:  0.000119629999972
:CHARGE convergence:  0.000341
>lapw0      ( 02:23:55 ) starting parallel lapw0 at Thu Jan 30 02:23:55 CST 2014
-------- .machine0 : 2 processors
2.912u 0.112s 0:03.72 81.1%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:23:58 ) starting parallel lapw1 at Thu Jan 30 02:23:58 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:23:58 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 4980
[2] 4999
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 5153
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 107.140u 3.384s 1:52.36 98.3%	0+0k 0+0io 0pf+0w
     node016(665) 107.975u 3.683s 1:52.51 99.2%	0+0k 0+0io 0pf+0w
     node016(1) 0.355u 0.016s 0:00.37 97.2%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=215.47	 wallclock=225.24
215.618u 7.360s 1:56.56 191.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:25:55 ) running LAPWSO in parallel mode
[1] 5293
[2] 5300
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 5677
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 82.202u 3.213s 2:00.85 70.6% 0+0k 0+0io 0pf+0w
      node016 85.626u 3.123s 2:03.78 71.6% 0+0k 0+0io 0pf+0w
      node016 0.131u 0.016s 0:00.15 93.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=167.959	 wallclock=244.78
168.087u 7.212s 2:05.42 139.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:28:00 ) 36.07user 1.58system 0:24.42elapsed 154%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:28:25 ) 2685.97user 10.04system 44:30.10elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:12:55 ) 575.41user 2.09system 4:53.59elapsed 196%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:17:49 ) 0.011u 0.004s 0:00.03 33.3%	0+0k 0+0io 0pf+0w
>mixer      ( 03:17:49 ) 0.027u 0.018s 0:00.38 7.8%	0+0k 0+0io 2pf+0w
:ENERGY convergence:  1.38999894261e-05
:CHARGE convergence:  0.0006213
>lapw0      ( 03:17:49 ) starting parallel lapw0 at Thu Jan 30 03:17:49 CST 2014
-------- .machine0 : 2 processors
2.889u 0.126s 0:03.63 82.6%	0+0k 0+0io 13pf+0w
>lapw1      ( 03:17:53 ) starting parallel lapw1 at Thu Jan 30 03:17:53 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 03:17:53 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 9547
[2] 9567
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 9717
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 107.205u 3.477s 1:51.10 99.6%	0+0k 0+0io 0pf+0w
     node016(665) 107.377u 3.756s 1:51.64 99.5%	0+0k 0+0io 0pf+0w
     node016(1) 0.360u 0.008s 0:00.37 97.2%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=214.942	 wallclock=223.11
215.112u 7.509s 1:55.56 192.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:19:49 ) running LAPWSO in parallel mode
[1] 9860
[2] 9866
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 10226
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 83.809u 3.334s 1:54.00 76.4% 0+0k 0+0io 0pf+0w
      node016 85.153u 3.319s 1:59.38 74.0% 0+0k 0+0io 0pf+0w
      node016 0.128u 0.013s 0:00.15 86.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=169.09	 wallclock=233.53
169.218u 7.521s 2:01.04 146.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:21:50 ) 36.50user 1.69system 0:22.78elapsed 167%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:22:12 ) 2689.05user 9.66system 44:33.06elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:06:46 ) 608.44user 2.38system 5:06.69elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:11:53 ) 0.012u 0.004s 0:00.04 25.0%	0+0k 0+0io 0pf+0w
>mixer      ( 04:11:53 ) 0.026u 0.015s 0:00.15 20.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000105879997136
:CHARGE convergence:  0.0015506
>lapw0      ( 04:11:53 ) starting parallel lapw0 at Thu Jan 30 04:11:53 CST 2014
-------- .machine0 : 2 processors
2.877u 0.129s 0:03.62 82.5%	0+0k 0+0io 13pf+0w
>lapw1      ( 04:11:57 ) starting parallel lapw1 at Thu Jan 30 04:11:57 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 04:11:57 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 14587
[2] 14606
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 14756
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 106.477u 3.407s 1:51.09 98.9%	0+0k 0+0io 0pf+0w
     node016(665) 106.547u 3.475s 1:50.85 99.2%	0+0k 0+0io 0pf+0w
     node016(1) 0.365u 0.011s 0:00.50 74.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=213.389	 wallclock=222.44
213.538u 7.160s 1:53.56 194.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:13:50 ) running LAPWSO in parallel mode
[1] 14896
[2] 14903
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 15274
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 83.396u 3.137s 1:55.19 75.1% 0+0k 0+0io 0pf+0w
      node016 83.028u 3.174s 1:56.32 74.0% 0+0k 0+0io 0pf+0w
      node016 0.127u 0.013s 0:00.14 92.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=166.551	 wallclock=231.65
166.661u 7.168s 1:58.37 146.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:15:49 ) 36.12user 1.55system 0:24.51elapsed 153%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:16:13 ) 2544.17user 9.72system 42:08.67elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:58:22 ) 589.29user 2.29system 4:56.95elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 05:03:19 ) 0.012u 0.004s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 05:03:19 ) 0.031u 0.013s 0:00.15 26.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  6.69000000926e-05
:CHARGE convergence:  0.0002552
>lapw0      ( 05:03:19 ) starting parallel lapw0 at Thu Jan 30 05:03:19 CST 2014
-------- .machine0 : 2 processors
2.969u 0.136s 0:03.68 83.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 05:03:23 ) starting parallel lapw1 at Thu Jan 30 05:03:23 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 05:03:23 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 19141
[2] 19160
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 19310
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 105.898u 3.423s 1:50.12 99.2%	0+0k 0+0io 0pf+0w
     node016(665) 106.369u 3.683s 1:50.80 99.3%	0+0k 0+0io 0pf+0w
     node016(1) 0.364u 0.012s 0:00.39 94.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=212.631	 wallclock=221.31
212.786u 7.399s 1:53.58 193.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 05:05:17 ) running LAPWSO in parallel mode
[1] 19451
[2] 19457
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 19816
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 82.545u 3.210s 1:57.50 72.9% 0+0k 0+0io 0pf+0w
      node016 84.152u 3.159s 1:58.52 73.6% 0+0k 0+0io 0pf+0w
      node016 0.126u 0.014s 0:00.16 81.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=166.823	 wallclock=236.18
166.941u 7.168s 2:00.35 144.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 05:07:17 ) 35.82user 1.73system 0:21.64elapsed 173%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 05:07:39 ) 3442.77user 10.09system 56:59.89elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:04:39 ) 534.79user 1.80system 4:29.42elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:09:08 ) 0.017u 0.003s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 06:09:08 ) 0.037u 0.013s 0:00.06 66.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.89999991562e-06
:CHARGE convergence:  0.0004829
