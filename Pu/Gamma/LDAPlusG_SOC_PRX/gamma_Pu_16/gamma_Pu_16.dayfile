Calculating gamma_Pu_16 in /scratch/ykent33711/gamma_Pu_16
on node016 with PID 20640




   start        Wed Jan 29 22:46:28 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 22:46:28 2014 1000/0 to go

>lapw0      ( 22:46:28 ) starting parallel lapw0 at Wed Jan 29 22:46:28 CST 2014
-------- .machine0 : 2 processors
2.994u 0.123s 0:06.94 44.8%	0+0k 0+0io 13pf+0w
>lapw1      ( 22:46:35 ) starting parallel lapw1 at Wed Jan 29 22:46:35 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 22:46:35 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 21279
[2] 21336
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 22713
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 120.740u 3.223s 2:40.62 77.1%	0+0k 0+0io 0pf+0w
     node016(665) 120.330u 2.984s 2:44.26 75.0%	0+0k 0+0io 0pf+0w
     node016(1) 0.378u 0.011s 0:00.41 92.6%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=241.448	 wallclock=325.29
241.672u 6.491s 2:46.92 148.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:49:22 ) running LAPWSO in parallel mode
[1] 22892
[2] 22907
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 25715
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 97.591u 4.040s 4:36.79 36.7% 0+0k 0+0io 0pf+0w
      node016 99.356u 4.039s 4:36.84 37.3% 0+0k 0+0io 0pf+0w
      node016 0.147u 0.014s 0:00.16 93.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=197.094	 wallclock=553.79
197.292u 8.729s 4:40.05 73.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:54:02 ) 38.06user 1.54system 0:23.16elapsed 170%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:54:25 ) 5711.32user 11.52system 1:34:46elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:29:12 ) 693.68user 2.27system 5:55.43elapsed 195%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:35:07 ) 0.015u 0.000s 0:00.08 12.5%	0+0k 0+0io 2pf+0w
>mixer      ( 00:35:09 ) 0.026u 0.012s 0:00.28 10.7%	0+0k 0+0io 4pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0016539
>lapw0      ( 00:35:10 ) starting parallel lapw0 at Thu Jan 30 00:35:10 CST 2014
-------- .machine0 : 2 processors
2.718u 0.121s 0:05.91 47.8%	0+0k 0+0io 26pf+0w
>lapw1      ( 00:35:16 ) starting parallel lapw1 at Thu Jan 30 00:35:16 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 00:35:16 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 27291
[2] 27310
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 28138
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 120.278u 3.313s 2:12.26 93.4%	0+0k 0+0io 1pf+0w
     node016(665) 119.955u 3.066s 2:10.92 93.9%	0+0k 0+0io 0pf+0w
     node016(1) 0.373u 0.010s 0:01.08 35.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=240.606	 wallclock=264.26
240.790u 6.612s 2:16.32 181.4%	0+0k 0+0io 18pf+0w
>lapwso     ( 00:37:33 ) running LAPWSO in parallel mode
[1] 28289
[2] 28298
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 30797
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 97.446u 3.887s 4:10.22 40.4% 0+0k 0+0io 1pf+0w
      node016 99.899u 3.854s 4:28.00 38.7% 0+0k 0+0io 0pf+0w
      node016 0.150u 0.016s 0:04.22 3.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=197.495	 wallclock=522.44
197.665u 8.798s 4:31.96 75.9%	0+0k 0+0io 1pf+0w
>dmft1      ( 00:42:05 ) 37.85user 1.52system 0:21.88elapsed 179%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:42:26 ) 3311.71user 7.93system 54:54.43elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:37:21 ) 766.34user 2.51system 6:27.33elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:43:48 ) 0.014u 0.001s 0:00.03 33.3%	0+0k 0+0io 0pf+0w
>mixer      ( 01:43:48 ) 0.026u 0.011s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  8.11999780126e-06
:CHARGE convergence:  0.001165
>lapw0      ( 01:43:49 ) starting parallel lapw0 at Thu Jan 30 01:43:49 CST 2014
-------- .machine0 : 2 processors
3.026u 0.132s 0:03.70 85.1%	0+0k 0+0io 13pf+0w
>lapw1      ( 01:43:52 ) starting parallel lapw1 at Thu Jan 30 01:43:52 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:43:52 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 1884
[2] 1911
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 2575
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 129.107u 3.729s 2:49.30 78.4%	0+0k 0+0io 0pf+0w
     node016(665) 128.788u 3.399s 2:49.11 78.1%	0+0k 0+0io 0pf+0w
     node016(1) 0.377u 0.018s 0:00.39 97.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=258.272	 wallclock=338.8
258.469u 7.465s 2:53.85 152.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:46:46 ) running LAPWSO in parallel mode
[1] 2720
[2] 2726
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 3206
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 103.490u 3.772s 2:23.27 74.8% 0+0k 0+0io 0pf+0w
      node016 103.898u 3.725s 2:24.81 74.3% 0+0k 0+0io 0pf+0w
      node016 0.158u 0.020s 0:00.18 94.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=207.546	 wallclock=288.26
207.676u 8.559s 2:26.56 147.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:49:13 ) 41.35user 1.96system 0:23.42elapsed 184%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:49:36 ) 2954.82user 9.18system 48:57.91elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:38:34 ) 774.40user 2.53system 6:40.70elapsed 193%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:45:15 ) 0.011u 0.003s 0:00.03 33.3%	0+0k 0+0io 0pf+0w
>mixer      ( 02:45:15 ) 0.031u 0.010s 0:00.07 57.1%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.8120004572e-05
:CHARGE convergence:  0.0002873
>lapw0      ( 02:45:15 ) starting parallel lapw0 at Thu Jan 30 02:45:15 CST 2014
-------- .machine0 : 2 processors
3.164u 0.142s 0:03.76 87.7%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:45:19 ) starting parallel lapw1 at Thu Jan 30 02:45:19 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:45:19 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 7137
[2] 7156
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 7344
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 128.179u 3.785s 2:12.97 99.2%	0+0k 0+0io 0pf+0w
     node016(665) 128.633u 3.552s 2:13.77 98.8%	0+0k 0+0io 0pf+0w
     node016(1) 0.391u 0.014s 0:00.41 97.5%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=257.203	 wallclock=267.15
257.374u 7.633s 2:18.03 191.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:47:37 ) running LAPWSO in parallel mode
[1] 7484
[2] 7490
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 7932
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 102.733u 3.950s 2:20.11 76.1% 0+0k 0+0io 0pf+0w
      node016 105.687u 3.888s 2:23.87 76.1% 0+0k 0+0io 0pf+0w
      node016 0.161u 0.017s 0:00.18 94.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=208.581	 wallclock=284.16
208.764u 8.787s 2:25.57 149.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:50:03 ) 41.91user 2.18system 0:24.81elapsed 177%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:50:28 ) 2698.56user 9.96system 44:41.59elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:35:09 ) 751.37user 2.31system 6:18.01elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:41:27 ) 0.010u 0.004s 0:00.04 25.0%	0+0k 0+0io 0pf+0w
>mixer      ( 03:41:28 ) 0.026u 0.016s 0:00.14 21.4%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.17099877773e-05
:CHARGE convergence:  0.0005361
>lapw0      ( 03:41:28 ) starting parallel lapw0 at Thu Jan 30 03:41:28 CST 2014
-------- .machine0 : 2 processors
3.215u 0.135s 0:03.78 88.3%	0+0k 0+0io 13pf+0w
>lapw1      ( 03:41:32 ) starting parallel lapw1 at Thu Jan 30 03:41:32 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 03:41:32 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 11704
[2] 11723
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 11903
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 131.667u 3.782s 2:16.29 99.3%	0+0k 0+0io 0pf+0w
     node016(665) 130.072u 3.491s 2:14.51 99.2%	0+0k 0+0io 0pf+0w
     node016(1) 0.385u 0.017s 0:00.40 97.5%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=262.124	 wallclock=271.2
262.306u 7.576s 2:19.63 193.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:43:51 ) running LAPWSO in parallel mode
[1] 12045
[2] 12051
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 12522
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 101.629u 3.771s 2:27.35 71.5% 0+0k 0+0io 0pf+0w
      node016 106.409u 3.701s 2:31.54 72.6% 0+0k 0+0io 0pf+0w
      node016 0.153u 0.021s 0:00.21 80.9% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=208.191	 wallclock=299.1
208.350u 8.513s 2:33.29 141.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:46:28 ) 41.43user 2.00system 0:24.27elapsed 178%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:46:52 ) 1831.79user 8.23system 30:20.44elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:17:12 ) 779.73user 2.45system 6:32.30elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:23:45 ) 0.012u 0.002s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 04:23:45 ) 0.026u 0.020s 0:00.10 40.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  3.46999877365e-05
:CHARGE convergence:  9.18e-05
>lapw0      ( 04:23:45 ) starting parallel lapw0 at Thu Jan 30 04:23:45 CST 2014
-------- .machine0 : 2 processors
3.064u 0.132s 0:03.69 86.4%	0+0k 0+0io 13pf+0w
>lapw1      ( 04:23:49 ) starting parallel lapw1 at Thu Jan 30 04:23:49 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 04:23:49 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 15672
[2] 15692
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 15868
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 128.006u 3.642s 2:12.76 99.1%	0+0k 0+0io 0pf+0w
     node016(665) 127.742u 3.440s 2:11.92 99.4%	0+0k 0+0io 0pf+0w
     node016(1) 0.385u 0.016s 0:00.41 95.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=256.133	 wallclock=265.09
256.304u 7.383s 2:16.63 192.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:26:05 ) running LAPWSO in parallel mode
[1] 16010
[2] 16016
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 16746
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 102.794u 3.883s 2:19.93 76.2% 0+0k 0+0io 0pf+0w
      node016 101.515u 3.715s 2:21.78 74.2% 0+0k 0+0io 0pf+0w
      node016 0.151u 0.023s 0:00.17 100.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=204.46	 wallclock=281.88
204.618u 8.583s 2:23.49 148.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:28:29 ) 41.29user 2.17system 0:25.43elapsed 170%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:28:54 ) 2360.15user 8.47system 39:07.84elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:08:02 ) 778.73user 2.59system 6:31.74elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 05:14:34 ) 0.013u 0.002s 0:00.03 33.3%	0+0k 0+0io 0pf+0w
>mixer      ( 05:14:34 ) 0.029u 0.017s 0:00.11 27.2%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  4.12999361288e-06
:CHARGE convergence:  0.0004114
