Calculating gamma_Pu_17 in /scratch/ykent33783/gamma_Pu_17
on node019 with PID 23104




   start        Fri Jan 31 12:53:23 2014 with lapw0 (1/100 to go)

   cycle 0 	Fri Jan 31 12:53:23 2014 1000/0 to go

>lapw0      ( 12:53:23 ) starting parallel lapw0 at Fri Jan 31 12:53:23 CST 2014
-------- .machine0 : 2 processors
12.246u 0.127s 0:14.36 86.0%	0+0k 0+0io 13pf+0w
>lapw1      ( 12:53:37 ) starting parallel lapw1 at Fri Jan 31 12:53:37 CST 2014
->  starting parallel LAPW1 jobs at Fri Jan 31 12:53:37 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 23296
[2] 23316
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 23496
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node019(665) 130.927u 4.328s 2:20.44 96.2%	0+0k 0+0io 0pf+0w
     node019(665) 127.211u 3.879s 2:15.59 96.6%	0+0k 0+0io 0pf+0w
     node019(1) 0.378u 0.018s 0:00.39 97.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node019	 k=1331	 user=258.516	 wallclock=276.42
258.702u 8.536s 2:21.60 188.7%	0+0k 0+0io 0pf+0w
>lapwso     ( 12:55:59 ) running LAPWSO in parallel mode
[1] 23637
[2] 23643
[3] 24718
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node019 106.295u 3.791s 4:56.47 37.1% 0+0k 0+0io 0pf+0w
      node019 105.974u 3.736s 5:07.14 35.7% 0+0k 0+0io 0pf+0w
      node019 0.161u 0.016s 0:00.18 94.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node019	 user=212.43	 wallclock=603.79
212.616u 8.046s 5:08.29 71.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 13:01:07 ) 39.14user 1.34system 0:34.67elapsed 116%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 13:01:42 ) 3671.61user 9.88system 1:00:39elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 14:02:21 ) 676.15user 2.09system 5:40.44elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 14:08:02 ) 0.016u 0.005s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 14:08:02 ) 0.023u 0.019s 0:00.06 50.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.001481
>lapw0      ( 14:08:02 ) starting parallel lapw0 at Fri Jan 31 14:08:02 CST 2014
-------- .machine0 : 2 processors
2.897u 0.155s 0:03.62 83.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 14:08:06 ) starting parallel lapw1 at Fri Jan 31 14:08:06 CST 2014
->  starting parallel LAPW1 jobs at Fri Jan 31 14:08:06 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 26723
[2] 26742
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 26920
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node019(665) 130.258u 4.384s 2:17.11 98.1%	0+0k 0+0io 0pf+0w
     node019(665) 126.075u 3.769s 2:10.54 99.4%	0+0k 0+0io 0pf+0w
     node019(1) 0.379u 0.013s 0:00.39 97.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node019	 k=1331	 user=256.712	 wallclock=268.04
256.932u 8.443s 2:18.28 191.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 14:10:24 ) running LAPWSO in parallel mode
[1] 27063
[2] 27070
[2] 27804
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node019 106.106u 3.819s 5:53.87 31.0% 0+0k 0+0io 0pf+0w
      node019 107.582u 3.788s 5:13.13 35.5% 0+0k 0+0io 0pf+0w
      node019 0.167u 0.014s 0:03.21 5.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node019	 user=213.855	 wallclock=670.21
214.037u 8.696s 5:55.51 62.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 14:16:20 ) 40.99user 1.76system 0:52.25elapsed 81%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 14:17:12 ) 2040.80user 8.55system 33:48.29elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 14:51:00 ) 741.56user 2.23system 6:15.75elapsed 197%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 14:57:16 ) 0.013u 0.001s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 14:57:16 ) 0.025u 0.014s 0:00.07 42.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  7.93000799604e-06
:CHARGE convergence:  0.0010224
>lapw0      ( 14:57:16 ) starting parallel lapw0 at Fri Jan 31 14:57:16 CST 2014
-------- .machine0 : 2 processors
3.225u 0.116s 0:03.86 86.2%	0+0k 0+0io 13pf+0w
>lapw1      ( 14:57:20 ) starting parallel lapw1 at Fri Jan 31 14:57:20 CST 2014
->  starting parallel LAPW1 jobs at Fri Jan 31 14:57:20 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 31364
[2] 31383
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 31554
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node019(665) 131.732u 4.579s 2:19.55 97.6%	0+0k 0+0io 0pf+0w
     node019(665) 128.068u 4.071s 2:15.58 97.4%	0+0k 0+0io 0pf+0w
     node019(1) 0.378u 0.013s 0:00.47 80.8%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node019	 k=1331	 user=260.178	 wallclock=275.6
260.376u 8.899s 2:21.28 190.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 14:59:41 ) running LAPWSO in parallel mode
[1] 31697
[2] 31703
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 1080
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node019 108.800u 3.999s 6:21.38 29.5% 0+0k 0+0io 0pf+0w
      node019 108.827u 4.046s 6:39.70 28.2% 0+0k 0+0io 0pf+0w
      node019 0.161u 0.019s 0:01.40 12.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node019	 user=217.788	 wallclock=782.48
217.992u 9.239s 6:41.48 56.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 15:06:23 ) 40.09user 1.81system 0:34.80elapsed 120%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 15:06:58 ) 2315.19user 8.43system 38:16.30elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 15:45:14 ) 726.48user 2.27system 6:05.54elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 15:51:20 ) 0.012u 0.001s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 15:51:20 ) 0.026u 0.015s 0:00.09 33.3%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.90499995369e-05
:CHARGE convergence:  0.000244
>lapw0      ( 15:51:20 ) starting parallel lapw0 at Fri Jan 31 15:51:20 CST 2014
-------- .machine0 : 2 processors
2.999u 0.118s 0:03.66 84.6%	0+0k 0+0io 13pf+0w
>lapw1      ( 15:51:24 ) starting parallel lapw1 at Fri Jan 31 15:51:24 CST 2014
->  starting parallel LAPW1 jobs at Fri Jan 31 15:51:24 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 5217
[2] 5237
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 5599
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node019(665) 131.560u 4.526s 2:54.64 77.9%	0+0k 0+0io 0pf+0w
     node019(665) 131.814u 4.097s 2:54.74 77.7%	0+0k 0+0io 0pf+0w
     node019(1) 0.381u 0.017s 0:00.44 88.6%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node019	 k=1331	 user=263.755	 wallclock=349.82
263.980u 8.892s 2:59.90 151.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 15:54:24 ) running LAPWSO in parallel mode
[1] 5743
[2] 5750
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 7261
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node019 109.110u 3.936s 6:57.52 27.0% 0+0k 0+0io 0pf+0w
      node019 107.599u 3.964s 7:16.37 25.5% 0+0k 0+0io 0pf+0w
      node019 0.159u 0.016s 0:00.20 80.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node019	 user=216.868	 wallclock=854.09
217.064u 9.109s 7:18.13 51.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 16:01:42 ) 39.61user 1.56system 0:33.55elapsed 122%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 16:02:15 ) 2165.20user 9.45system 36:06.89elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 16:38:22 ) 679.12user 2.34system 5:41.97elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 16:44:04 ) 0.013u 0.000s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 16:44:04 ) 0.022u 0.017s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.44600053318e-05
:CHARGE convergence:  0.0005274
>lapw0      ( 16:44:05 ) starting parallel lapw0 at Fri Jan 31 16:44:05 CST 2014
-------- .machine0 : 2 processors
3.395u 0.110s 0:04.43 79.0%	0+0k 0+0io 13pf+0w
>lapw1      ( 16:44:09 ) starting parallel lapw1 at Fri Jan 31 16:44:09 CST 2014
->  starting parallel LAPW1 jobs at Fri Jan 31 16:44:09 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 11046
[2] 11067
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 11431
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node019(665) 127.573u 4.211s 3:02.11 72.3%	0+0k 0+0io 0pf+0w
     node019(665) 127.106u 3.821s 2:53.90 75.2%	0+0k 0+0io 0pf+0w
     node019(1) 0.378u 0.015s 0:02.77 13.7%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node019	 k=1331	 user=255.057	 wallclock=358.78
255.274u 8.324s 3:03.34 143.7%	0+0k 0+0io 0pf+0w
>lapwso     ( 16:47:13 ) running LAPWSO in parallel mode
[1] 11582
[2] 11589
[2] 12739
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node019 107.024u 3.805s 6:36.40 27.9% 0+0k 0+0io 0pf+0w
      node019 106.756u 3.994s 6:05.18 30.3% 0+0k 0+0io 0pf+0w
      node019 0.158u 0.014s 0:00.19 84.2% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node019	 user=213.938	 wallclock=761.77
214.097u 8.978s 6:37.15 56.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 16:53:50 ) 39.31user 1.50system 0:33.99elapsed 120%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 16:54:24 ) 1708.27user 7.23system 28:14.88elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 17:22:39 ) 676.13user 2.06system 5:42.70elapsed 197%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 17:28:22 ) 0.013u 0.001s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 17:28:22 ) 0.027u 0.012s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.62400135398e-05
:CHARGE convergence:  0.0001201
>lapw0      ( 17:28:22 ) starting parallel lapw0 at Fri Jan 31 17:28:22 CST 2014
-------- .machine0 : 2 processors
2.655u 0.110s 0:11.05 24.9%	0+0k 0+0io 14pf+0w
>lapw1      ( 17:28:33 ) starting parallel lapw1 at Fri Jan 31 17:28:33 CST 2014
->  starting parallel LAPW1 jobs at Fri Jan 31 17:28:33 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 15586
[2] 15607
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 15950
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node019(665) 127.716u 4.167s 3:21.07 65.5%	0+0k 0+0io 0pf+0w
     node019(665) 127.269u 3.826s 3:12.72 68.0%	0+0k 0+0io 0pf+0w
     node019(1) 0.372u 0.015s 0:00.39 97.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node019	 k=1331	 user=255.357	 wallclock=394.18
255.578u 8.248s 3:23.80 129.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 17:31:57 ) running LAPWSO in parallel mode
[1] 16102
[2] 16109
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 17366
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node019 106.751u 3.807s 5:59.09 30.7% 0+0k 0+0io 0pf+0w
      node019 106.751u 3.989s 6:21.11 29.0% 0+0k 0+0io 0pf+0w
      node019 0.158u 0.017s 0:00.24 66.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node019	 user=213.66	 wallclock=740.44
213.842u 8.969s 6:24.04 58.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 17:38:21 ) 39.23user 1.50system 0:25.97elapsed 156%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 17:38:47 ) 1673.31user 7.19system 27:38.10elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 18:06:28 ) 675.99user 2.07system 5:40.22elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 18:12:09 ) 0.017u 0.004s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 18:12:09 ) 0.039u 0.016s 0:00.05 80.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.7100101104e-06
:CHARGE convergence:  0.0002881
