Calculating gamma_Pu_2 in /scratch/ykent33697/gamma_Pu_2
on node020 with PID 26794




   start        Wed Jan 29 22:46:28 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 22:46:28 2014 1000/0 to go

>lapw0      ( 22:46:28 ) starting parallel lapw0 at Wed Jan 29 22:46:28 CST 2014
-------- .machine0 : 2 processors
2.086u 0.124s 0:03.24 67.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 22:46:31 ) starting parallel lapw1 at Wed Jan 29 22:46:32 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 22:46:32 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 27350
[2] 27645
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 28086
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 43.601u 0.794s 1:06.12 67.1%	0+0k 0+0io 0pf+0w
     node020(665) 43.678u 0.766s 1:01.00 72.8%	0+0k 0+0io 0pf+0w
     node020(1) 0.340u 0.009s 0:00.35 97.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=87.619	 wallclock=127.47
87.755u 1.796s 1:08.79 130.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:47:40 ) running LAPWSO in parallel mode
[1] 28261
[2] 28273
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 30021
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 26.603u 1.698s 3:06.14 15.1% 0+0k 0+0io 0pf+0w
      node020 25.976u 1.702s 3:19.30 13.8% 0+0k 0+0io 0pf+0w
      node020 0.047u 0.007s 0:00.07 57.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=52.626	 wallclock=385.51
52.770u 3.797s 3:21.44 28.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:51:02 ) 19.16user 0.68system 0:12.42elapsed 159%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:51:14 ) 5205.63user 9.74system 1:26:25elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:17:41 ) 408.99user 1.42system 3:28.21elapsed 197%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:21:09 ) 0.011u 0.003s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 00:21:09 ) 0.015u 0.018s 0:00.03 66.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0093599
>lapw0      ( 00:21:09 ) starting parallel lapw0 at Thu Jan 30 00:21:10 CST 2014
-------- .machine0 : 2 processors
1.892u 0.115s 0:03.13 63.8%	0+0k 0+0io 13pf+0w
>lapw1      ( 00:21:13 ) starting parallel lapw1 at Thu Jan 30 00:21:13 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 00:21:13 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 31858
[2] 31878
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 32587
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 44.326u 0.807s 1:25.98 52.4%	0+0k 0+0io 0pf+0w
     node020(665) 44.592u 0.840s 1:43.32 43.9%	0+0k 0+0io 0pf+0w
     node020(1) 0.345u 0.013s 0:08.53 4.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=89.263	 wallclock=197.83
89.392u 1.864s 1:46.91 85.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 00:23:00 ) running LAPWSO in parallel mode
[1] 32763
[2] 305
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 1023
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 27.552u 1.652s 1:35.39 30.6% 0+0k 0+0io 0pf+0w
      node020 26.619u 1.663s 1:39.20 28.4% 0+0k 0+0io 0pf+0w
      node020 0.048u 0.011s 0:00.06 83.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=54.219	 wallclock=194.65
54.323u 3.742s 1:40.89 57.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:24:41 ) 19.53user 0.89system 0:11.29elapsed 180%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:24:52 ) 2483.47user 7.70system 41:16.64elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:06:09 ) 408.01user 1.47system 3:25.85elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:09:35 ) 0.011u 0.003s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 01:09:35 ) 0.020u 0.013s 0:00.03 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.47200077865e-05
:CHARGE convergence:  0.0081408
>lapw0      ( 01:09:35 ) starting parallel lapw0 at Thu Jan 30 01:09:35 CST 2014
-------- .machine0 : 2 processors
1.924u 0.095s 0:03.12 64.4%	0+0k 0+0io 13pf+0w
>lapw1      ( 01:09:38 ) starting parallel lapw1 at Thu Jan 30 01:09:38 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:09:38 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 3636
[2] 3656
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 4067
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 46.092u 0.821s 1:08.10 68.8%	0+0k 0+0io 0pf+0w
     node020(665) 46.329u 0.884s 1:07.24 70.1%	0+0k 0+0io 0pf+0w
     node020(1) 0.355u 0.007s 0:00.36 97.2%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=92.776	 wallclock=135.7
92.905u 1.927s 1:11.77 132.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:10:50 ) running LAPWSO in parallel mode
[1] 4226
[2] 4235
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 4576
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 27.860u 1.778s 1:12.67 40.7% 0+0k 0+0io 0pf+0w
      node020 27.042u 1.679s 1:08.26 42.0% 0+0k 0+0io 0pf+0w
      node020 0.047u 0.013s 0:00.09 55.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=54.949	 wallclock=141.02
55.053u 3.860s 1:12.99 80.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:12:03 ) 19.44user 0.82system 0:11.61elapsed 174%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:12:15 ) 2577.04user 7.69system 42:47.10elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:55:02 ) 431.94user 1.45system 3:37.81elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:58:40 ) 0.011u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 01:58:40 ) 0.025u 0.010s 0:00.11 27.2%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000258719999692
:CHARGE convergence:  0.0008175
>lapw0      ( 01:58:40 ) starting parallel lapw0 at Thu Jan 30 01:58:40 CST 2014
-------- .machine0 : 2 processors
1.901u 0.087s 0:03.09 64.0%	0+0k 0+0io 13pf+0w
>lapw1      ( 01:58:43 ) starting parallel lapw1 at Thu Jan 30 01:58:43 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:58:43 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 6102
[2] 6121
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 6459
[3]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 45.147u 0.823s 0:46.97 97.8%	0+0k 0+0io 0pf+0w
     node020(665) 45.651u 0.798s 0:47.95 96.8%	0+0k 0+0io 0pf+0w
     node020(1) 0.344u 0.013s 0:00.36 97.2%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=91.142	 wallclock=95.28
91.260u 1.811s 0:50.44 184.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:59:34 ) running LAPWSO in parallel mode
[1] 6603
[2] 6610
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 7097
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 26.890u 1.532s 0:54.46 52.1% 0+0k 0+0io 0pf+0w
      node020 26.423u 1.552s 0:52.15 53.6% 0+0k 0+0io 0pf+0w
      node020 0.049u 0.012s 0:00.09 55.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=53.362	 wallclock=106.7
53.452u 3.479s 0:54.79 103.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:00:28 ) 19.51user 0.99system 0:13.42elapsed 152%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:00:42 ) 2550.59user 7.18system 42:26.74elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:43:10 ) 398.22user 1.37system 3:20.88elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:46:31 ) 0.011u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 02:46:31 ) 0.026u 0.014s 0:00.10 30.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  3.53999930667e-05
:CHARGE convergence:  0.001666
>lapw0      ( 02:46:31 ) starting parallel lapw0 at Thu Jan 30 02:46:31 CST 2014
-------- .machine0 : 2 processors
1.950u 0.107s 0:03.14 65.2%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:46:34 ) starting parallel lapw1 at Thu Jan 30 02:46:34 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:46:34 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 9482
[2] 9501
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 9572
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 43.585u 0.774s 0:44.47 99.7%	0+0k 0+0io 0pf+0w
     node020(665) 43.573u 0.785s 0:46.71 94.9%	0+0k 0+0io 0pf+0w
     node020(1) 0.342u 0.010s 0:00.35 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=87.5	 wallclock=91.53
87.614u 1.739s 0:50.52 176.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:47:25 ) running LAPWSO in parallel mode
[1] 9715
[2] 9721
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 10144
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 26.675u 1.536s 0:54.34 51.8% 0+0k 0+0io 0pf+0w
      node020 26.256u 1.547s 0:51.01 54.4% 0+0k 0+0io 0pf+0w
      node020 0.048u 0.009s 0:00.08 50.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=52.979	 wallclock=105.43
53.057u 3.459s 0:55.20 102.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:48:20 ) 19.77user 0.94system 0:13.88elapsed 149%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:48:34 ) 2237.80user 8.14system 37:09.99elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:25:47 ) 424.96user 1.61system 3:35.40elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:29:23 ) 0.012u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 03:29:23 ) 0.027u 0.011s 0:00.07 42.8%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000131189997774
:CHARGE convergence:  0.0017167
>lapw0      ( 03:29:23 ) starting parallel lapw0 at Thu Jan 30 03:29:23 CST 2014
-------- .machine0 : 2 processors
2.056u 0.106s 0:03.20 67.1%	0+0k 0+0io 13pf+0w
>lapw1      ( 03:29:26 ) starting parallel lapw1 at Thu Jan 30 03:29:26 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 03:29:26 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 12710
[2] 12729
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 12803
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 47.234u 0.841s 0:48.22 99.6%	0+0k 0+0io 0pf+0w
     node020(665) 43.247u 0.809s 0:44.66 98.6%	0+0k 0+0io 0pf+0w
     node020(1) 0.340u 0.012s 0:00.61 57.3%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=90.821	 wallclock=93.49
90.936u 1.861s 0:50.36 184.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:30:17 ) running LAPWSO in parallel mode
[1] 12946
[2] 12952
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 13100
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 27.904u 1.695s 0:49.87 59.3% 0+0k 0+0io 0pf+0w
      node020 27.149u 1.674s 0:50.07 57.5% 0+0k 0+0io 0pf+0w
      node020 0.043u 0.017s 0:00.06 83.3% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=55.096	 wallclock=100
55.188u 3.802s 0:53.19 110.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:31:10 ) 20.46user 1.14system 0:12.68elapsed 170%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:31:22 ) 2700.21user 7.51system 44:51.67elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:16:14 ) 419.00user 1.55system 3:31.39elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:19:46 ) 0.012u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 04:19:46 ) 0.030u 0.015s 0:00.09 44.4%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  7.62499985285e-05
:CHARGE convergence:  0.0007463
>lapw0      ( 04:19:46 ) starting parallel lapw0 at Thu Jan 30 04:19:46 CST 2014
-------- .machine0 : 2 processors
2.059u 0.098s 0:03.16 67.7%	0+0k 0+0io 14pf+0w
>lapw1      ( 04:19:49 ) starting parallel lapw1 at Thu Jan 30 04:19:49 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 04:19:49 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 16526
[2] 16545
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 16623
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node020(665) 46.593u 0.809s 0:48.20 98.3%	0+0k 0+0io 0pf+0w
     node020(665) 46.474u 0.862s 0:47.86 98.8%	0+0k 0+0io 0pf+0w
     node020(1) 0.350u 0.009s 0:00.36 97.2%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node020	 k=1331	 user=93.417	 wallclock=96.42
93.522u 1.873s 0:52.34 182.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:20:41 ) running LAPWSO in parallel mode
[1] 16765
[2] 16771
[3] 16900
[3]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node020 26.155u 1.506s 0:46.95 58.8% 0+0k 0+0io 0pf+0w
      node020 27.063u 1.650s 0:46.39 61.8% 0+0k 0+0io 0pf+0w
      node020 0.049u 0.005s 0:00.07 57.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node020	 user=53.267	 wallclock=93.41
53.344u 3.544s 0:48.50 117.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:21:30 ) 19.67user 0.95system 0:12.64elapsed 163%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:21:43 ) 2214.33user 7.61system 36:47.82elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:58:31 ) 416.37user 1.61system 3:30.08elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 05:02:01 ) 0.012u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 05:02:01 ) 0.030u 0.011s 0:00.04 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  3.68000473827e-06
:CHARGE convergence:  0.0006869
