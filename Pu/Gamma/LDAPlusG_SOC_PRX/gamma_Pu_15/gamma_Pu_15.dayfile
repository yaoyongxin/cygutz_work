Calculating gamma_Pu_15 in /scratch/ykent33710/gamma_Pu_15
on node016 with PID 20630




   start        Wed Jan 29 22:46:28 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 22:46:28 2014 1000/0 to go

>lapw0      ( 22:46:28 ) starting parallel lapw0 at Wed Jan 29 22:46:28 CST 2014
-------- .machine0 : 2 processors
2.540u 0.136s 0:09.65 27.6%	0+0k 0+0io 13pf+0w
>lapw1      ( 22:46:38 ) starting parallel lapw1 at Wed Jan 29 22:46:38 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 22:46:38 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 21479
[2] 21501
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 22502
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 113.373u 3.692s 2:33.50 76.2%	0+0k 0+0io 0pf+0w
     node016(665) 113.241u 2.309s 2:32.07 75.9%	0+0k 0+0io 0pf+0w
     node016(1) 0.359u 0.014s 0:00.42 85.7%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=226.973	 wallclock=305.99
227.188u 6.268s 2:36.26 149.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:49:14 ) running LAPWSO in parallel mode
[1] 22655
[2] 22668
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 25500
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 92.347u 3.737s 4:14.09 37.8% 0+0k 0+0io 0pf+0w
      node016 92.513u 3.797s 4:27.96 35.9% 0+0k 0+0io 0pf+0w
      node016 0.140u 0.013s 0:00.20 75.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=185	 wallclock=522.25
185.191u 8.150s 4:29.12 71.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:53:43 ) 36.24user 1.36system 0:20.67elapsed 181%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:54:04 ) 5730.50user 11.83system 1:35:02elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:29:08 ) 726.55user 2.33system 6:11.17elapsed 196%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:35:19 ) 0.011u 0.003s 0:00.08 12.5%	0+0k 0+0io 0pf+0w
>mixer      ( 00:35:19 ) 0.029u 0.009s 0:00.08 25.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0020861
>lapw0      ( 00:35:19 ) starting parallel lapw0 at Thu Jan 30 00:35:19 CST 2014
-------- .machine0 : 2 processors
2.433u 0.109s 0:04.57 55.3%	0+0k 0+0io 13pf+0w
>lapw1      ( 00:35:24 ) starting parallel lapw1 at Thu Jan 30 00:35:26 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 00:35:26 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 27555
[2] 27575
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 28315
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 113.158u 3.870s 2:09.08 90.6%	0+0k 0+0io 0pf+0w
     node016(665) 112.705u 2.400s 2:09.91 88.5%	0+0k 0+0io 0pf+0w
     node016(1) 0.359u 0.014s 0:00.57 63.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=226.222	 wallclock=259.56
226.401u 6.506s 2:13.25 174.7%	0+0k 0+0io 0pf+0w
>lapwso     ( 00:37:39 ) running LAPWSO in parallel mode
[1] 28468
[2] 28478
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 30601
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 92.718u 3.577s 3:43.87 43.0% 0+0k 0+0io 0pf+0w
      node016 92.846u 3.640s 3:47.75 42.3% 0+0k 0+0io 0pf+0w
      node016 0.146u 0.017s 0:00.20 75.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=185.71	 wallclock=451.82
185.885u 8.178s 3:49.89 84.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:41:29 ) 36.30user 1.38system 0:22.73elapsed 165%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:41:52 ) 4148.03user 8.79system 1:08:44elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:50:37 ) 691.43user 2.08system 5:48.29elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:56:25 ) 0.013u 0.002s 0:00.04 25.0%	0+0k 0+0io 0pf+0w
>mixer      ( 01:56:25 ) 0.024u 0.017s 0:00.09 33.3%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.10800028779e-05
:CHARGE convergence:  0.0015673
>lapw0      ( 01:56:25 ) starting parallel lapw0 at Thu Jan 30 01:56:25 CST 2014
-------- .machine0 : 2 processors
2.958u 0.127s 0:03.65 84.1%	0+0k 0+0io 14pf+0w
>lapw1      ( 01:56:29 ) starting parallel lapw1 at Thu Jan 30 01:56:29 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:56:29 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 3597
[2] 3617
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 3796
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 124.885u 4.701s 2:10.41 99.3%	0+0k 0+0io 0pf+0w
     node016(665) 119.850u 2.654s 2:03.03 99.5%	0+0k 0+0io 0pf+0w
     node016(1) 0.380u 0.011s 0:00.40 97.5%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=245.115	 wallclock=253.84
245.287u 7.644s 2:11.56 192.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:58:41 ) running LAPWSO in parallel mode
[1] 3946
[2] 3952
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 4410
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 97.744u 3.594s 2:19.02 72.8% 0+0k 0+0io 0pf+0w
      node016 96.465u 3.517s 2:18.23 72.3% 0+0k 0+0io 0pf+0w
      node016 0.148u 0.019s 0:00.68 22.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=194.357	 wallclock=277.93
194.481u 8.103s 2:23.05 141.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:01:04 ) 38.85user 1.81system 0:23.32elapsed 174%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:01:27 ) 2683.08user 10.15system 44:26.50elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:45:54 ) 753.26user 2.90system 6:19.18elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:52:13 ) 0.013u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 02:52:13 ) 0.027u 0.015s 0:00.06 50.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  4.39799914602e-05
:CHARGE convergence:  0.0003641
>lapw0      ( 02:52:13 ) starting parallel lapw0 at Thu Jan 30 02:52:13 CST 2014
-------- .machine0 : 2 processors
2.984u 0.123s 0:03.65 84.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:52:17 ) starting parallel lapw1 at Thu Jan 30 02:52:17 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:52:17 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 8245
[2] 8264
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 8435
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 122.490u 4.877s 2:07.52 99.8%	0+0k 0+0io 0pf+0w
     node016(665) 124.061u 2.648s 2:07.54 99.3%	0+0k 0+0io 0pf+0w
     node016(1) 0.370u 0.015s 0:00.38 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=246.921	 wallclock=255.44
247.081u 7.844s 2:11.78 193.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:54:29 ) running LAPWSO in parallel mode
[1] 8576
[2] 8582
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 8992
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 96.136u 3.548s 2:10.56 76.3% 0+0k 0+0io 0pf+0w
      node016 99.691u 3.449s 2:15.72 75.9% 0+0k 0+0io 0pf+0w
      node016 0.147u 0.015s 0:00.29 51.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=195.974	 wallclock=266.57
196.108u 7.976s 2:17.45 148.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:56:46 ) 38.75user 1.73system 0:23.09elapsed 175%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:57:09 ) 2952.23user 10.36system 48:59.80elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:46:09 ) 766.46user 2.50system 6:25.57elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:52:35 ) 0.013u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 03:52:35 ) 0.032u 0.010s 0:00.10 40.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.78399966192e-05
:CHARGE convergence:  0.0005538
>lapw0      ( 03:52:35 ) starting parallel lapw0 at Thu Jan 30 03:52:35 CST 2014
-------- .machine0 : 2 processors
3.375u 0.150s 0:03.88 90.7%	0+0k 0+0io 13pf+0w
>lapw1      ( 03:52:39 ) starting parallel lapw1 at Thu Jan 30 03:52:39 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 03:52:39 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 12881
[2] 12901
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 13072
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 123.104u 4.584s 2:08.32 99.5%	0+0k 0+0io 0pf+0w
     node016(665) 124.235u 2.674s 2:07.93 99.1%	0+0k 0+0io 0pf+0w
     node016(1) 0.372u 0.017s 0:00.39 97.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=247.711	 wallclock=256.64
247.900u 7.543s 2:12.77 192.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:54:52 ) running LAPWSO in parallel mode
[1] 13214
[2] 13220
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 13645
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 97.744u 3.628s 2:18.33 73.2% 0+0k 0+0io 0pf+0w
      node016 97.276u 3.597s 2:13.55 75.5% 0+0k 0+0io 0pf+0w
      node016 0.139u 0.020s 0:00.16 93.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=195.159	 wallclock=272.04
195.315u 8.237s 2:19.07 146.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:57:14 ) 38.99user 1.74system 0:21.97elapsed 185%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:57:36 ) 2391.26user 9.73system 39:37.77elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:37:14 ) 739.75user 2.31system 6:12.36elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:43:26 ) 0.011u 0.004s 0:00.06 16.6%	0+0k 0+0io 0pf+0w
>mixer      ( 04:43:47 ) 0.030u 0.013s 0:00.11 36.3%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  5.6359989685e-05
:CHARGE convergence:  0.0003664
>lapw0      ( 04:43:47 ) starting parallel lapw0 at Thu Jan 30 04:43:48 CST 2014
-------- .machine0 : 2 processors
2.891u 0.114s 0:03.63 82.6%	0+0k 0+0io 13pf+0w
>lapw1      ( 04:43:51 ) starting parallel lapw1 at Thu Jan 30 04:43:54 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 04:43:54 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 17918
[2] 17938
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 18107
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 121.686u 4.450s 2:06.91 99.3%	0+0k 0+0io 0pf+0w
     node016(665) 121.175u 2.692s 2:04.73 99.3%	0+0k 0+0io 0pf+0w
     node016(1) 0.371u 0.015s 0:00.40 95.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=243.232	 wallclock=252.04
243.395u 7.450s 2:10.61 192.0%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:46:05 ) running LAPWSO in parallel mode
[1] 18249
[2] 18255
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 18659
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 96.237u 3.542s 2:13.50 74.7% 0+0k 0+0io 0pf+0w
      node016 98.201u 3.513s 2:16.18 74.6% 0+0k 0+0io 0pf+0w
      node016 0.151u 0.022s 0:00.18 94.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=194.589	 wallclock=269.86
194.705u 8.014s 2:17.90 146.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:48:23 ) 38.15user 1.60system 0:21.67elapsed 183%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:48:44 ) 2781.42user 10.41system 46:04.90elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:34:49 ) 728.39user 2.41system 6:06.57elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 05:40:56 ) 0.013u 0.001s 0:00.03 33.3%	0+0k 0+0io 0pf+0w
>mixer      ( 05:40:56 ) 0.030u 0.016s 0:00.15 26.6%	0+0k 0+0io 1pf+0w
:ENERGY convergence:  2.3720000172e-05
:CHARGE convergence:  0.0003861
>lapw0      ( 05:40:56 ) starting parallel lapw0 at Thu Jan 30 05:40:56 CST 2014
-------- .machine0 : 2 processors
2.727u 0.125s 0:03.54 80.2%	0+0k 0+0io 13pf+0w
>lapw1      ( 05:41:00 ) starting parallel lapw1 at Thu Jan 30 05:41:00 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 05:41:00 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 21646
[2] 21665
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 21831
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 118.349u 4.283s 2:03.50 99.2%	0+0k 0+0io 0pf+0w
     node016(665) 117.963u 2.543s 2:01.68 99.0%	0+0k 0+0io 0pf+0w
     node016(1) 0.377u 0.010s 0:00.40 95.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=236.689	 wallclock=245.58
236.851u 7.108s 2:07.59 191.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 05:43:08 ) running LAPWSO in parallel mode
[1] 21973
[2] 21979
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 22405
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 96.313u 3.631s 2:13.04 75.1% 0+0k 0+0io 0pf+0w
      node016 96.427u 3.663s 2:11.19 76.2% 0+0k 0+0io 0pf+0w
      node016 0.146u 0.015s 0:00.16 93.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=192.886	 wallclock=264.39
193.044u 8.299s 2:15.62 148.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 05:45:26 ) 38.88user 1.91system 0:31.53elapsed 129%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 05:45:58 ) 1762.01user 8.09system 29:06.80elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:15:05 ) 669.14user 1.81system 5:36.58elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:20:41 ) 0.018u 0.004s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 06:20:44 ) 0.039u 0.015s 0:00.05 80.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.1090003429e-05
:CHARGE convergence:  0.0002085
>lapw0      ( 06:20:45 ) starting parallel lapw0 at Thu Jan 30 06:20:45 CST 2014
-------- .machine0 : 2 processors
2.322u 0.128s 0:03.33 73.2%	0+0k 0+0io 13pf+0w
>lapw1      ( 06:20:48 ) starting parallel lapw1 at Thu Jan 30 06:20:48 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 06:20:48 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 23453
[2] 23473
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 23627
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(665) 111.315u 3.542s 1:55.89 99.1%	0+0k 0+0io 0pf+0w
     node016(665) 110.714u 2.145s 1:53.30 99.6%	0+0k 0+0io 0pf+0w
     node016(1) 0.365u 0.009s 0:00.37 97.2%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=1331	 user=222.394	 wallclock=229.56
222.604u 5.974s 1:58.60 192.7%	0+0k 0+0io 0pf+0w
>lapwso     ( 06:22:47 ) running LAPWSO in parallel mode
[1] 23769
[2] 23775
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 24186
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 90.852u 3.539s 2:09.59 72.8% 0+0k 0+0io 0pf+0w
      node016 90.867u 3.573s 2:11.62 71.7% 0+0k 0+0io 0pf+0w
      node016 0.149u 0.012s 0:00.16 93.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=181.868	 wallclock=261.37
181.994u 8.085s 2:13.37 142.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 06:25:00 ) 36.16user 1.35system 0:20.02elapsed 187%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 06:25:20 ) 1381.34user 6.72system 22:45.19elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 06:48:06 ) 664.56user 1.88system 5:36.86elapsed 197%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 06:53:43 ) 0.017u 0.003s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 06:53:43 ) 0.035u 0.016s 0:00.05 80.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.35000334214e-06
:CHARGE convergence:  0.0004224
