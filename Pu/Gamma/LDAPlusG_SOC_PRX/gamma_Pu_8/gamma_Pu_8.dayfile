Calculating gamma_Pu_8 in /scratch/ykent33703/gamma_Pu_8
on node018 with PID 20141




   start        Wed Jan 29 22:46:30 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 22:46:30 2014 1000/0 to go

>lapw0      ( 22:46:30 ) starting parallel lapw0 at Wed Jan 29 22:46:36 CST 2014
-------- .machine0 : 2 processors
2.389u 0.128s 0:07.23 34.5%	0+0k 0+0io 13pf+0w
>lapw1      ( 22:46:43 ) starting parallel lapw1 at Wed Jan 29 22:46:43 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 22:46:43 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 20942
[2] 21001
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 22120
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 69.927u 1.096s 2:20.03 50.7%	0+0k 0+0io 0pf+0w
     node018(665) 70.548u 1.097s 2:17.42 52.1%	0+0k 0+0io 0pf+0w
     node018(1) 0.339u 0.016s 0:00.35 97.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=140.814	 wallclock=277.8
141.014u 2.458s 2:25.07 98.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 22:49:08 ) running LAPWSO in parallel mode
[1] 22293
[2] 22300
[3] 23435
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 51.198u 2.487s 2:52.96 31.0% 0+0k 0+0io 0pf+0w
      node018 51.377u 2.645s 3:55.59 22.9% 0+0k 0+0io 0pf+0w
      node018 0.094u 0.012s 0:00.10 100.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=102.669	 wallclock=408.65
102.760u 5.477s 4:02.02 44.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 22:53:10 ) 26.62user 0.97system 0:43.39elapsed 63%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 22:53:54 ) 5733.38user 10.15system 1:35:07elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 00:29:07 ) 437.31user 1.63system 3:41.57elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 00:32:49 ) 0.011u 0.002s 0:02.47 0.4%	0+0k 0+0io 0pf+0w
>mixer      ( 00:32:52 ) 0.020u 0.014s 0:00.57 5.2%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0079043
>lapw0      ( 00:32:55 ) starting parallel lapw0 at Thu Jan 30 00:32:56 CST 2014
-------- .machine0 : 2 processors
1.920u 0.094s 0:05.91 34.0%	0+0k 0+0io 13pf+0w
>lapw1      ( 00:33:01 ) starting parallel lapw1 at Thu Jan 30 00:33:02 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 00:33:02 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 26134
[2] 26205
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 27241
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 69.772u 1.203s 2:51.97 41.2%	0+0k 0+0io 0pf+0w
     node018(665) 70.220u 1.181s 2:39.80 44.6%	0+0k 0+0io 0pf+0w
     node018(1) 0.330u 0.006s 0:05.89 5.6%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=140.322	 wallclock=337.66
140.534u 2.629s 2:53.11 82.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 00:35:56 ) running LAPWSO in parallel mode
[1] 27442
[2] 27452
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 28240
[3]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 53.137u 2.474s 2:38.60 35.0% 0+0k 0+0io 0pf+0w
      node018 52.885u 2.565s 2:39.90 34.6% 0+0k 0+0io 0pf+0w
      node018 0.085u 0.011s 0:04.15 2.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=106.107	 wallclock=322.65
106.248u 5.653s 2:44.65 67.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 00:38:43 ) 27.39user 1.22system 0:22.84elapsed 125%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 00:39:06 ) 2378.62user 8.75system 39:28.34elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 01:18:34 ) 455.27user 1.77system 3:50.57elapsed 198%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 01:22:25 ) 0.012u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 01:22:25 ) 0.025u 0.013s 0:00.05 60.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  3.72999929823e-05
:CHARGE convergence:  0.0071684
>lapw0      ( 01:22:26 ) starting parallel lapw0 at Thu Jan 30 01:22:26 CST 2014
-------- .machine0 : 2 processors
2.292u 0.120s 0:05.01 48.1%	0+0k 0+0io 14pf+0w
>lapw1      ( 01:22:31 ) starting parallel lapw1 at Thu Jan 30 01:22:31 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 01:22:31 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 30755
[2] 30774
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 30890
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 73.420u 1.148s 1:21.74 91.2%	0+0k 0+0io 0pf+0w
     node018(665) 71.204u 1.122s 1:17.12 93.7%	0+0k 0+0io 0pf+0w
     node018(1) 0.337u 0.009s 0:01.24 26.6%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=144.961	 wallclock=160.1
145.106u 2.469s 1:23.22 177.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 01:23:54 ) running LAPWSO in parallel mode
[1] 31032
[2] 31038
[3] 31303
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 53.221u 2.384s 1:43.78 53.5% 0+0k 0+0io 0pf+0w
      node018 53.875u 2.453s 1:48.65 51.8% 0+0k 0+0io 0pf+0w
      node018 0.082u 0.019s 0:00.10 90.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=107.178	 wallclock=212.53
107.281u 5.455s 1:50.10 102.3%	0+0k 0+0io 0pf+0w
>dmft1      ( 01:25:44 ) 28.57user 1.58system 0:17.29elapsed 174%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 01:26:01 ) 2726.90user 9.59system 45:13.68elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:11:15 ) 477.73user 2.07system 4:01.06elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 02:15:16 ) 0.012u 0.001s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 02:15:16 ) 0.025u 0.012s 0:00.09 33.3%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.000374299997929
:CHARGE convergence:  0.0017843
>lapw0      ( 02:15:16 ) starting parallel lapw0 at Thu Jan 30 02:15:17 CST 2014
-------- .machine0 : 2 processors
2.256u 0.106s 0:05.80 40.5%	0+0k 0+0io 13pf+0w
>lapw1      ( 02:15:22 ) starting parallel lapw1 at Thu Jan 30 02:15:22 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 02:15:22 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 1068
[2] 1091
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 1485
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 73.884u 1.147s 1:59.03 63.0%	0+0k 0+0io 0pf+0w
     node018(665) 74.448u 1.143s 2:02.15 61.8%	0+0k 0+0io 0pf+0w
     node018(1) 0.335u 0.011s 0:00.34 100.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=148.667	 wallclock=241.52
148.815u 2.570s 2:04.83 121.2%	0+0k 0+0io 0pf+0w
>lapwso     ( 02:17:27 ) running LAPWSO in parallel mode
[1] 1628
[2] 1634
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 1914
[3]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 53.797u 2.488s 1:27.69 64.1% 0+0k 0+0io 0pf+0w
      node018 53.540u 2.490s 1:31.04 61.5% 0+0k 0+0io 0pf+0w
      node018 0.084u 0.013s 0:00.10 90.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=107.421	 wallclock=178.83
107.538u 5.602s 1:32.52 122.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 02:19:00 ) 28.52user 1.50system 0:16.85elapsed 178%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 02:19:17 ) 2329.46user 8.55system 38:39.33elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 02:57:56 ) 487.99user 2.35system 4:06.23elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:02:02 ) 0.012u 0.003s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 03:02:02 ) 0.026u 0.014s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  4.95099957334e-05
:CHARGE convergence:  0.0009017
>lapw0      ( 03:02:02 ) starting parallel lapw0 at Thu Jan 30 03:02:03 CST 2014
-------- .machine0 : 2 processors
2.338u 0.105s 0:03.33 72.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 03:02:06 ) starting parallel lapw1 at Thu Jan 30 03:02:06 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 03:02:06 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 4272
[2] 4291
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 4410
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 74.260u 1.135s 1:17.01 97.8%	0+0k 0+0io 0pf+0w
     node018(665) 75.664u 1.223s 1:17.61 99.0%	0+0k 0+0io 0pf+0w
     node018(1) 0.335u 0.018s 0:00.39 87.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=150.259	 wallclock=155.01
150.381u 2.632s 1:20.76 189.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:03:27 ) running LAPWSO in parallel mode
[1] 4551
[2] 4557
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 4805
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 54.555u 2.513s 1:32.21 61.8% 0+0k 0+0io 0pf+0w
      node018 54.631u 2.546s 1:25.80 66.6% 0+0k 0+0io 0pf+0w
      node018 0.090u 0.006s 0:00.10 90.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=109.276	 wallclock=178.11
109.388u 5.701s 1:33.11 123.5%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:05:00 ) 28.56user 1.53system 0:16.35elapsed 184%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:05:16 ) 2178.77user 8.33system 36:07.02elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 03:41:23 ) 488.86user 1.89system 4:06.48elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 03:45:30 ) 0.012u 0.002s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 03:45:30 ) 0.029u 0.012s 0:00.09 33.3%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  9.26200009417e-05
:CHARGE convergence:  0.0013427
>lapw0      ( 03:45:30 ) starting parallel lapw0 at Thu Jan 30 03:45:30 CST 2014
-------- .machine0 : 2 processors
2.415u 0.121s 0:03.37 75.0%	0+0k 0+0io 13pf+0w
>lapw1      ( 03:45:33 ) starting parallel lapw1 at Thu Jan 30 03:45:34 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 03:45:34 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 7028
[2] 7047
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 7168
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 73.313u 1.173s 1:19.13 94.1%	0+0k 0+0io 0pf+0w
     node018(665) 73.810u 1.155s 1:18.91 94.9%	0+0k 0+0io 0pf+0w
     node018(1) 0.341u 0.013s 0:00.39 89.7%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=147.464	 wallclock=158.43
147.600u 2.580s 1:23.22 180.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 03:46:57 ) running LAPWSO in parallel mode
[1] 7309
[2] 7315
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1] 7603
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 53.862u 2.538s 1:53.82 49.5% 0+0k 0+0io 0pf+0w
      node018 53.795u 2.456s 1:51.86 50.2% 0+0k 0+0io 0pf+0w
      node018 0.086u 0.009s 0:00.10 80.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=107.743	 wallclock=225.78
107.850u 5.640s 1:56.24 97.6%	0+0k 0+0io 0pf+0w
>dmft1      ( 03:48:53 ) 27.05user 1.18system 0:16.76elapsed 168%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 03:49:10 ) 2509.88user 7.40system 41:36.66elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 04:30:46 ) 465.28user 1.85system 3:54.70elapsed 199%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 04:34:41 ) 0.009u 0.006s 0:00.01 0.0%	0+0k 0+0io 0pf+0w
>mixer      ( 04:34:44 ) 0.026u 0.015s 0:00.04 75.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  3.92499932786e-05
:CHARGE convergence:  0.0001845
>lapw0      ( 04:34:44 ) starting parallel lapw0 at Thu Jan 30 04:34:44 CST 2014
-------- .machine0 : 2 processors
2.392u 0.126s 0:03.35 74.9%	0+0k 0+0io 13pf+0w
>lapw1      ( 04:34:48 ) starting parallel lapw1 at Thu Jan 30 04:34:48 CST 2014
->  starting parallel LAPW1 jobs at Thu Jan 30 04:34:48 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 11160
[2] 11179
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[3] 11299
[3]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(665) 76.333u 1.137s 1:19.65 97.2%	0+0k 0+0io 0pf+0w
     node018(665) 75.476u 1.198s 1:20.30 95.4%	0+0k 0+0io 0pf+0w
     node018(1) 0.333u 0.013s 0:00.35 97.1%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=1331	 user=152.142	 wallclock=160.3
152.266u 2.607s 1:23.94 184.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 04:36:12 ) running LAPWSO in parallel mode
[1] 11441
[2] 11448
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2] 11741
[2]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 54.103u 2.469s 1:44.79 53.9% 0+0k 0+0io 0pf+0w
      node018 54.258u 2.513s 1:40.49 56.4% 0+0k 0+0io 0pf+0w
      node018 0.083u 0.011s 0:00.10 90.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=108.444	 wallclock=205.38
108.574u 5.642s 1:45.27 108.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 04:37:57 ) 28.54user 1.49system 0:20.59elapsed 145%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 04:38:18 ) 3171.89user 9.57system 52:34.70elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 05:30:52 ) 477.23user 1.66system 4:09.55elapsed 191%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 05:35:02 ) 0.017u 0.004s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
>mixer      ( 05:35:02 ) 0.023u 0.022s 0:00.06 66.6%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.97999940813e-06
:CHARGE convergence:  9.81e-05
