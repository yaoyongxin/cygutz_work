Calculating epsilon_Pu_14 in /scratch/ykent33668/epsilon_Pu_14
on node016 with PID 2725




   start        Wed Jan 29 14:34:11 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 14:34:11 2014 1000/0 to go

>lapw0      ( 14:34:11 ) starting parallel lapw0 at Wed Jan 29 14:34:11 CST 2014
-------- .machine0 : 2 processors
0.896u 0.108s 0:08.11 12.2%	0+0k 0+0io 13pf+0w
>lapw1      ( 14:34:19 ) starting parallel lapw1 at Wed Jan 29 14:34:19 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 14:34:19 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 3535
[2] 3622
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(143) 5.937u 0.136s 0:07.74 78.2%	0+0k 0+0io 0pf+0w
     node016(143) 6.008u 0.152s 0:08.48 72.5%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=286	 user=11.945	 wallclock=16.22
12.025u 0.480s 0:11.48 108.8%	0+0k 0+0io 0pf+0w
>lapwso     ( 14:34:31 ) running LAPWSO in parallel mode
[1] 4145
[2] 4185
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 3.240u 0.307s 0:03.55 99.7% 0+0k 0+0io 0pf+0w
      node016 3.242u 0.305s 0:03.59 98.6% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=6.482	 wallclock=7.14
6.539u 0.713s 0:04.73 153.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 14:34:35 ) 2.82user 0.16system 0:02.78elapsed 107%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 14:34:38 ) 5671.20user 11.58system 1:35:33elapsed 99%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 16:10:11 ) 19.37user 0.14system 0:11.72elapsed 166%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 16:10:23 ) 0.008u 0.004s 0:01.28 0.0%	0+0k 0+0io 0pf+0w
>mixer      ( 16:10:26 ) 0.010u 0.011s 0:00.06 33.3%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0038022
>lapw0      ( 16:10:26 ) starting parallel lapw0 at Wed Jan 29 16:10:27 CST 2014
-------- .machine0 : 2 processors
0.997u 0.089s 0:07.68 13.9%	0+0k 0+0io 9pf+0w
>lapw1      ( 16:10:34 ) starting parallel lapw1 at Wed Jan 29 16:10:35 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 16:10:35 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 6246
[2] 6265
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(143) 5.952u 0.137s 0:06.11 99.5%	0+0k 0+0io 0pf+0w
     node016(143) 6.024u 0.139s 0:07.84 78.4%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=286	 user=11.976	 wallclock=13.95
12.037u 0.420s 0:10.17 122.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 16:10:45 ) running LAPWSO in parallel mode
[1] 6398
[2] 6404
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 3.563u 0.270s 0:05.20 73.6% 0+0k 0+0io 0pf+0w
      node016 3.433u 0.300s 0:05.15 72.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=6.996	 wallclock=10.35
7.041u 0.683s 0:06.29 122.7%	0+0k 0+0io 0pf+0w
>dmft1      ( 16:10:51 ) 2.92user 0.18system 0:07.91elapsed 39%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 16:10:59 ) 2400.01user 7.64system 40:16.60elapsed 99%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 16:51:16 ) 19.59user 0.16system 0:10.94elapsed 180%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 16:51:27 ) 0.009u 0.002s 0:00.01 0.0%	0+0k 0+0io 0pf+0w
>mixer      ( 16:51:27 ) 0.009u 0.009s 0:00.06 0.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  5.60000626137e-06
:CHARGE convergence:  0.0033495
>lapw0      ( 16:51:27 ) starting parallel lapw0 at Wed Jan 29 16:51:27 CST 2014
-------- .machine0 : 2 processors
0.922u 0.079s 0:02.58 38.3%	0+0k 0+0io 9pf+0w
>lapw1      ( 16:51:30 ) starting parallel lapw1 at Wed Jan 29 16:51:30 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 16:51:30 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 8957
[2] 8976
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(143) 6.265u 0.149s 0:06.46 99.0%	0+0k 0+0io 0pf+0w
     node016(143) 6.425u 0.149s 0:06.63 98.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=286	 user=12.69	 wallclock=13.09
12.745u 0.447s 0:10.17 129.5%	0+0k 0+0io 0pf+0w
>lapwso     ( 16:51:40 ) running LAPWSO in parallel mode
[1] 9109
[2] 9115
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 3.432u 0.256s 0:03.70 99.4% 0+0k 0+0io 0pf+0w
      node016 3.380u 0.273s 0:03.66 99.7% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=6.812	 wallclock=7.36
6.853u 0.649s 0:04.80 156.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 16:51:45 ) 3.28user 0.22system 0:03.01elapsed 116%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 16:51:48 ) 2658.04user 8.24system 44:22.80elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 17:36:10 ) 20.21user 0.18system 0:11.28elapsed 180%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 17:36:22 ) 0.008u 0.003s 0:00.01 0.0%	0+0k 0+0io 0pf+0w
>mixer      ( 17:36:22 ) 0.007u 0.014s 0:00.02 50.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  6.86299972585e-05
:CHARGE convergence:  0.0008594
>lapw0      ( 17:36:22 ) starting parallel lapw0 at Wed Jan 29 17:36:22 CST 2014
-------- .machine0 : 2 processors
1.043u 0.108s 0:02.68 42.5%	0+0k 0+0io 9pf+0w
>lapw1      ( 17:36:25 ) starting parallel lapw1 at Wed Jan 29 17:36:25 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 17:36:25 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 10393
[2] 10412
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node016(143) 6.245u 0.157s 0:06.63 96.3%	0+0k 0+0io 0pf+0w
     node016(143) 6.378u 0.147s 0:06.58 98.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node016	 k=286	 user=12.623	 wallclock=13.21
12.682u 0.471s 0:10.18 129.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 17:36:35 ) running LAPWSO in parallel mode
[1] 10545
[2] 10551
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node016 3.438u 0.289s 0:03.78 98.1% 0+0k 0+0io 0pf+0w
      node016 3.391u 0.291s 0:03.68 100.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node016	 user=6.829	 wallclock=7.46
6.871u 0.697s 0:04.82 156.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 17:36:40 ) 2.92user 0.20system 0:04.13elapsed 75%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 17:36:44 ) 2020.89user 7.81system 33:45.67elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 18:10:30 ) 19.51user 0.16system 0:10.92elapsed 180%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 18:10:41 ) 0.008u 0.003s 0:00.01 0.0%	0+0k 0+0io 0pf+0w
>mixer      ( 18:10:41 ) 0.014u 0.008s 0:00.07 14.2%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  6.10999995843e-06
:CHARGE convergence:  0.0006864
