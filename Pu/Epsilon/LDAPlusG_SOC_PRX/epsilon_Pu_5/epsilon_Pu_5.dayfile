Calculating epsilon_Pu_5 in /scratch/ykent33659/epsilon_Pu_5
on node018 with PID 1356




   start        Wed Jan 29 14:34:03 2014 with lapw0 (1/100 to go)

   cycle 0 	Wed Jan 29 14:34:03 2014 1000/0 to go

>lapw0      ( 14:34:03 ) starting parallel lapw0 at Wed Jan 29 14:34:06 CST 2014
-------- .machine0 : 2 processors
0.862u 0.127s 0:10.11 9.6%	0+0k 0+0io 85pf+0w
>lapw1      ( 14:34:15 ) starting parallel lapw1 at Wed Jan 29 14:34:15 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 14:34:15 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 2146
[2] 2210
[2]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(143) 4.022u 0.116s 0:06.64 62.1%	0+0k 0+0io 6pf+0w
     node018(143) 3.901u 0.098s 0:04.95 80.6%	0+0k 0+0io 6pf+0w
   Summary of lapw1para:
   node018	 k=286	 user=7.923	 wallclock=11.59
7.989u 0.408s 0:10.22 81.9%	0+0k 0+0io 15pf+0w
>lapwso     ( 14:34:26 ) running LAPWSO in parallel mode
[1] 2372
[2] 2748
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 1.437u 0.186s 0:07.05 22.8% 0+0k 0+0io 1pf+0w
      node018 1.412u 0.186s 0:18.49 8.5% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=2.849	 wallclock=25.54
2.898u 0.482s 0:19.62 17.1%	0+0k 0+0io 1pf+0w
>dmft1      ( 14:34:45 ) 1.99user 0.14system 1:07.96elapsed 3%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 14:35:53 ) 6059.51user 10.79system 1:41:23elapsed 99%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 16:17:19 ) 16.36user 0.10system 0:28.63elapsed 57%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 16:17:48 ) 0.010u 0.001s 0:00.39 2.5%	0+0k 0+0io 0pf+0w
>mixer      ( 16:17:53 ) 0.013u 0.009s 0:04.68 0.2%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.0
:CHARGE convergence:  0.0103318
>lapw0      ( 16:18:04 ) starting parallel lapw0 at Wed Jan 29 16:18:04 CST 2014
-------- .machine0 : 2 processors
0.778u 0.081s 0:21.08 4.0%	0+0k 0+0io 9pf+0w
>lapw1      ( 16:18:25 ) starting parallel lapw1 at Wed Jan 29 16:18:27 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 16:18:27 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 4999
[2] 5018
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(143) 4.175u 0.100s 0:07.34 58.1%	0+0k 0+0io 0pf+0w
     node018(143) 4.076u 0.104s 0:06.23 66.9%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=286	 user=8.251	 wallclock=13.57
8.316u 0.351s 0:10.83 79.9%	0+0k 0+0io 0pf+0w
>lapwso     ( 16:18:37 ) running LAPWSO in parallel mode
[1] 5191
[2] 5198
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[1]  + Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 1.566u 0.187s 0:02.91 59.7% 0+0k 0+0io 0pf+0w
      node018 1.547u 0.193s 0:01.94 89.1% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=3.113	 wallclock=4.85
3.162u 0.485s 0:04.55 80.0%	0+0k 0+0io 0pf+0w
>dmft1      ( 16:18:43 ) 2.03user 0.15system 0:08.55elapsed 25%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 16:18:52 ) 2368.35user 7.87system 39:40.29elapsed 99%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 16:58:32 ) 17.76user 0.14system 0:10.02elapsed 178%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 16:58:42 ) 0.009u 0.002s 0:00.01 0.0%	0+0k 0+0io 0pf+0w
>mixer      ( 16:58:42 ) 0.012u 0.008s 0:00.07 14.2%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  1.8849998014e-05
:CHARGE convergence:  0.0093209
>lapw0      ( 16:58:42 ) starting parallel lapw0 at Wed Jan 29 16:58:42 CST 2014
-------- .machine0 : 2 processors
0.866u 0.085s 0:02.55 36.8%	0+0k 0+0io 9pf+0w
>lapw1      ( 16:58:45 ) starting parallel lapw1 at Wed Jan 29 16:58:45 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 16:58:45 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 7246
[2] 7265
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(143) 4.125u 0.108s 0:04.26 99.0%	0+0k 0+0io 0pf+0w
     node018(143) 4.074u 0.111s 0:04.22 99.0%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=286	 user=8.199	 wallclock=8.48
8.262u 0.365s 0:07.16 120.3%	0+0k 0+0io 0pf+0w
>lapwso     ( 16:58:52 ) running LAPWSO in parallel mode
[1] 7394
[2] 7400
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 1.580u 0.184s 0:01.80 97.7% 0+0k 0+0io 0pf+0w
      node018 1.579u 0.194s 0:01.77 99.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=3.159	 wallclock=3.57
3.191u 0.497s 0:02.90 126.8%	0+0k 0+0io 0pf+0w
>dmft1      ( 16:58:55 ) 2.08user 0.16system 0:06.40elapsed 35%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 16:59:02 ) 2941.53user 8.40system 49:07.50elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 17:48:09 ) 17.10user 0.14system 0:09.71elapsed 177%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 17:48:19 ) 0.013u 0.000s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 17:48:19 ) 0.009u 0.014s 0:00.07 14.2%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  0.00015975000133
:CHARGE convergence:  0.0025307
>lapw0      ( 17:48:19 ) starting parallel lapw0 at Wed Jan 29 17:48:19 CST 2014
-------- .machine0 : 2 processors
0.847u 0.098s 0:02.56 36.3%	0+0k 0+0io 9pf+0w
>lapw1      ( 17:48:22 ) starting parallel lapw1 at Wed Jan 29 17:48:22 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 17:48:22 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 9177
[2] 9196
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(143) 4.197u 0.105s 0:04.35 98.6%	0+0k 0+0io 0pf+0w
     node018(143) 4.088u 0.106s 0:04.24 98.5%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=286	 user=8.285	 wallclock=8.59
8.343u 0.377s 0:07.17 121.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 17:48:29 ) running LAPWSO in parallel mode
[1] 9325
[2] 9332
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 1.535u 0.182s 0:01.76 97.1% 0+0k 0+0io 0pf+0w
      node018 1.603u 0.179s 0:01.79 98.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=3.138	 wallclock=3.55
3.180u 0.481s 0:02.93 124.9%	0+0k 0+0io 0pf+0w
>dmft1      ( 17:48:32 ) 2.08user 0.12system 0:05.01elapsed 44%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 17:48:37 ) 3281.05user 9.08system 54:47.26elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 18:43:24 ) 17.66user 0.13system 0:12.98elapsed 137%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 18:43:37 ) 0.011u 0.001s 0:00.01 100.0%	0+0k 0+0io 0pf+0w
>mixer      ( 18:43:37 ) 0.010u 0.013s 0:00.02 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.24399991566e-05
:CHARGE convergence:  0.0011607
>lapw0      ( 18:43:37 ) starting parallel lapw0 at Wed Jan 29 18:43:37 CST 2014
-------- .machine0 : 2 processors
0.893u 0.088s 0:02.58 37.5%	0+0k 0+0io 9pf+0w
>lapw1      ( 18:43:40 ) starting parallel lapw1 at Wed Jan 29 18:43:40 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 18:43:40 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 12501
[2] 12520
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(143) 4.195u 0.103s 0:04.38 97.9%	0+0k 0+0io 0pf+0w
     node018(143) 4.086u 0.107s 0:04.19 99.7%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=286	 user=8.281	 wallclock=8.57
8.339u 0.382s 0:07.17 121.4%	0+0k 0+0io 0pf+0w
>lapwso     ( 18:43:47 ) running LAPWSO in parallel mode
[1] 12649
[2] 12655
[1]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 1.547u 0.173s 0:02.11 81.0% 0+0k 0+0io 0pf+0w
      node018 1.523u 0.177s 0:02.56 66.0% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=3.07	 wallclock=4.67
3.115u 0.468s 0:03.71 96.2%	0+0k 0+0io 0pf+0w
>dmft1      ( 18:43:51 ) 2.07user 0.16system 0:02.21elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 18:43:53 ) 2386.61user 8.24system 39:53.96elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 19:23:47 ) 17.08user 0.13system 0:09.69elapsed 177%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 19:23:57 ) 0.009u 0.004s 0:00.01 0.0%	0+0k 0+0io 0pf+0w
>mixer      ( 19:23:57 ) 0.017u 0.008s 0:00.07 14.2%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  4.94199994137e-05
:CHARGE convergence:  0.0014073
>lapw0      ( 19:23:57 ) starting parallel lapw0 at Wed Jan 29 19:23:57 CST 2014
-------- .machine0 : 2 processors
0.848u 0.088s 0:02.57 35.7%	0+0k 0+0io 9pf+0w
>lapw1      ( 19:24:00 ) starting parallel lapw1 at Wed Jan 29 19:24:00 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 19:24:00 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 13878
[2] 13906
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(143) 4.181u 0.103s 0:04.29 99.7%	0+0k 0+0io 0pf+0w
     node018(143) 4.092u 0.108s 0:04.21 99.5%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=286	 user=8.273	 wallclock=8.5
8.343u 0.350s 0:07.17 121.1%	0+0k 0+0io 0pf+0w
>lapwso     ( 19:24:07 ) running LAPWSO in parallel mode
[1] 14036
[2] 14042
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 1.550u 0.163s 0:01.76 97.1% 0+0k 0+0io 0pf+0w
      node018 1.505u 0.181s 0:01.70 98.8% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=3.055	 wallclock=3.46
3.095u 0.461s 0:02.83 125.4%	0+0k 0+0io 0pf+0w
>dmft1      ( 19:24:10 ) 2.03user 0.16system 0:02.16elapsed 101%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 19:24:12 ) 2192.22user 7.51system 36:39.60elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 20:00:52 ) 16.86user 0.11system 0:09.57elapsed 177%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 20:01:01 ) 0.008u 0.003s 0:00.01 0.0%	0+0k 0+0io 0pf+0w
>mixer      ( 20:01:01 ) 0.011u 0.011s 0:00.02 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  2.19200010179e-05
:CHARGE convergence:  0.0002392
>lapw0      ( 20:01:02 ) starting parallel lapw0 at Wed Jan 29 20:01:02 CST 2014
-------- .machine0 : 2 processors
0.827u 0.092s 0:02.55 35.6%	0+0k 0+0io 9pf+0w
>lapw1      ( 20:01:04 ) starting parallel lapw1 at Wed Jan 29 20:01:04 CST 2014
->  starting parallel LAPW1 jobs at Wed Jan 29 20:01:04 CST 2014
running LAPW1 in parallel mode (using .machines)
2 number_of_parallel_jobs
[1] 15804
[2] 15823
[1]  - Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]  + Done                          ( cd $PWD; $t $exe ${def}_$loop.def; rm -f .lock_$lockfile[$p] ) >>  ...
     node018(143) 4.164u 0.117s 0:04.28 99.7%	0+0k 0+0io 0pf+0w
     node018(143) 4.046u 0.120s 0:04.22 98.5%	0+0k 0+0io 0pf+0w
   Summary of lapw1para:
   node018	 k=286	 user=8.21	 wallclock=8.5
8.267u 0.380s 0:07.16 120.6%	0+0k 0+0io 0pf+0w
>lapwso     ( 20:01:11 ) running LAPWSO in parallel mode
[1] 15953
[2] 15959
[1]  - Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
[2]    Done                          ( cd $PWD; $t $exe ${def}_${loop}.def; rm -f .lock_$lockfile[$p] ) >>  ...
      node018 1.528u 0.169s 0:01.73 97.1% 0+0k 0+0io 0pf+0w
      node018 1.498u 0.192s 0:01.69 99.4% 0+0k 0+0io 0pf+0w
   Summary of lapwsopara:
   node018	 user=3.026	 wallclock=3.42
3.061u 0.476s 0:02.82 125.1%	0+0k 0+0io 0pf+0w
>dmft1      ( 20:01:14 ) 2.03user 0.14system 0:06.97elapsed 31%CPU (0avgtext+0avgdata 0maxresident)k
>FastGutz   ( 20:01:21 ) 2101.48user 7.75system 35:06.89elapsed 100%CPU (0avgtext+0avgdata 0maxresident)k
>dmft2      ( 20:36:28 ) 16.83user 0.14system 0:09.56elapsed 177%CPU (0avgtext+0avgdata 0maxresident)k
>lcore      ( 20:36:38 ) 0.009u 0.002s 0:00.01 0.0%	0+0k 0+0io 0pf+0w
>mixer      ( 20:36:38 ) 0.011u 0.012s 0:00.02 100.0%	0+0k 0+0io 0pf+0w
:ENERGY convergence:  6.10001734458e-07
:CHARGE convergence:  9.06e-05
